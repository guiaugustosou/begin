<!DOCTYPE html>
<html lang="pt-br">
<head>
    <title>Arquitetura de Computadores</title>
    <meta charset="utf-8"/>
    <meta name="author" content="Guilherme Augusto"/>
    <meta http-equiv="cache-control" content="no-cache"/>
    <style>
        body {margin: 65px 65px 65px 75px; background-color:#FFFFFF;}
        p {text-indent: 30px; text-align: justify; font-family:arial;}
        h1 {font-family:arial; color: #4285F4}
        h2 {font-family:arial; color: #EA4335}
        h4 {font-family:arial; font-style:italic; color: #34A853}
        .center{display: block; margin-left: auto; margin-right: auto;}
        figure {margin-left:auto; margin-right: auto}
        figcaption {text-align: center; font-style:italic; color: #888888}
        ul {list-style-type:disc; text-align: justify; font-family:arial; margin-left:35px}
        ol {list-style-type:lower-alpha; text-align: justify; font-family:arial; margin-left:35px}
        ol.number {list-style-type:decimal; text-align: justify; font-family:arial; margin-left:35px}
        div {border: 1px solid gray; padding: 8px;}
        p.mix {width: 90px; margin: auto; border-style: dotted dashed solid double;}
        p.round {width: 90px; margin: auto; border: 2px dashed; border-radius: 12px; padding: 5px; background-color: azure; text-align:center;text-indent:0px;}
        p.round2 {width: 50px; margin: auto; border: 2px dashed; border-radius: 12px; padding: 5px; background-color: azure; text-align:center;text-indent:0px;}
        p.round3 {width: 100px; margin: auto; border: 2px dashed; border-radius: 12px; padding: 5px; background-color: azure; text-align:center;text-indent:0px;}
        table {text-align: center; font-family:courier}
        tr:nth-child(even) {background-color: rgba(150, 212, 212, 0.4);}
        th:nth-child(even) {background-color: rgba(150, 212, 212, 0.4);}
        th, td {border-radius: 10px; padding: 5px;}
    </style>
</head>
<body>
    <h1>Evolução Histórica dos Computadores</h1>
        <p>Nesta primeira aula, abordaremos os conceitos fundamentais de Arquitetura de Computadores. Apresentaremos a técnica de máquinas multiníveis e a evolução dos computadores, desde a válvula até os circuitos integrados de larga escala, tudo isso dentro do padrão proposto por Von Newmann.</p>
    <h2>1. Computação Primordial</h2>
        <p>Desde a Antiguidade, pode-se observar a necessidade do homem em computar (calcular). Inicialmente ele utilizava seus próprios dedos como forma de contagem, daí a base de nosso sistema de numeração ser decimal. Com o passar dos tempos, os dez dedos não eram mais suficientes, então ele passou a utilizar pedrinhas: "O pastor guardava em um saco uma pedrinha para cada ovelha de seu rebanho, depois associava cada pedrinha a uma ovelha". As evoluções não pararam e o homem aperfeiçoou suas técnicas criando instrumentos de apoio à contagem e computo. Cada vez mais, os números foram crescendo, a necessidade de precisão e a dificuldade em solucionar cálculos mais e mais complexos levou o homem a criar mecanismos com o intuito de simplificar uma tarefa tão árdua. Daí surgiu ferramentas como: ábaco, régua de cálculo, máquina de calcular e o computador.</p>
    <h2>2. Computador</h2>
        <p>O computador é uma máquina capaz de receber, armazenar, tratar e produzir informações de forma automática, com grande rapidez e precisão.<p>
        A evolução dos sistemas de computação teve seu início no século XVI, mas estes somente mostraram-se úteis no século XX, e sua vulgarização se deu graças à recente evolução na microeletrônica
        </p>
    <h4>2.1. Tipos de Computadores Digitais</h4>
        <p>Atualmente, as famílias de computadores podem ser classificadas em cinco grupos distintos:</p>
            <ol>
                <li>os computadores pessoais (PCs);</li> <p>
                <li>os minicomputadores;</li> <p>
                <li>os supermini; </li><p>
                <li>os computadores de grande porte (mainframes); e</li><p>
                <li>os supercomputadores.</li> 
            </ol>
        <p> A tabela a seguir dá um exemplo das máquinas comerciais que se enquadram nesses grupos e as suas aplicações típicas.<p>
                <img src ="tabela1.jpg" alt ="tabela1" title ="tabela1" class="center" style=width:520px>
        </p>
    <h2>3. Modelo de Von Neumann</h2>
        <p>A grande maioria dos computadores existentes atualmente segue um modelo proposto pelo matemático americano Von Neumann, por volta de 1940.<p>
        Nesse modelo, um elemento processador segue as instruções armazenadas em uma memória de programas, para ler canais de entrada, enviar comandos sobre canais de saída e alterar as informações contidas em uma memória de dados.<p>Esse modelo inicial evoluiu para uma estrutura em barramento, que é a base dos computadores modernos. Nessa estrutura, as memórias de dados e de programa são fundidas em uma memória única, e as comunicações entre elementos são efetuadas por meio de uma via comum de alta velocidade.
        </p>
    <h2>4. História e Geração dos Computadores</h2>
        <p>A história dos computadores começou no momento em que o homem sentiu a necessidade de efetuar cálculos complexos de maneira automática.</p>
    <h4>4.1. Precursores (Geração Zero)</h4>
        <p>O primeiro elemento com que o homem contou para fazer seus cálculos foi o conjunto de dedos de suas mãos, daí veio a palavra digital, vindo de dígito, que significa dedo. Com a evolução da humanidade, fez-se necessárias novas invenções para auxiliar os cálculos.
        </p>
    <h4>4.1.1. Ábaco</h4>
        <p>A primeira calculadora de que se tem notícias é o ábaco, de origem chinesa, do século V a.C., capaz de efetuar operações algébricas elementares.
        </p>
    <h4>4.1.2. Calculadoras Mecânicas</h4>
        <p>Anteriormente à década de 1940 já existiam calculadoras mecânicas, dentre elas, pode-se destacar: a <b>calculadora de Charles Babbage</b>.<p>
        Uma das primeiras máquinas <i>processadoras dados</i> data de 1880, quando Hermann Hollerith, funcionário do United States Census Bureau, inventou uma máquina para realizar as operações de <i>recenseamento da população</i>. A máquina "lia" cartões perfurados em código BCD (Binary Coded Decimal) e efetuava contagens da informação referente à perfuração respectiva. O sistema foi patenteado em 1884. As <b>máquinas de Hollerit</b> foram utilizadas no censo de 1890 nos EUA. O tempo gasto nesse recenseamento foi 1/3 do tempo normal.</p>
    <h4>4.1.2.1. IBM</h4>
       <p>Em 1896, Hollerit fundou a <i>Tabulating Machine Company</i>, que construía as tabuladoras e outros dispositivos por ele inventados. Com o crescimento da empresa, ela passou a chamar-se, em 1911, <i>Computing Tabulating and Recording Company</i> e, em 1924, passou a ostentar o nome que tem atualmente, <b>IBM – International Business Machines Corporation</b>.</p> 
    <h4>4.2. Máquinas de 1ª Geração (1930-1958)</h4>
        <p>Foi na década de 1940 que surgiram as primeiras válvulas eletrônicas. O Exército americano necessitava de um equipamento para efetuar <i>cálculos de balística</i>, foi quando se iniciaram os estudos para esse fim.<p>
        <i>Cada válvula era capaz de representar <b>um bit</b> de informação (somente aceitava <b>dois estados, ligada ou desligada</b>). <b>Os bytes eram compostos por oito válvulas</b>.</i>
        </p>
            <figure>
                <img src ="imagem1.jpg" alt ="imagem1" title ="imagem1"; class="center"><figcaption>O ENIAC (Electronic Numerical Integrator and Computer), 1948</figcaption>
            </figure>
    <h4>4.3. Máquinas de 2ª Geração (1955-1965)</h4>
        <p>Foi em 1947 que surgiu o primeiro <b>transistor</b>, produzido pela Bell Telephone Laboratories. Essa descoberta revolucionou a eletrônica, e os circuitos passaram a consumir muitíssimo menos energia, a ocupar menos espaço, isso a um custo bem satisfatório. Os transistores eram e são muito mais confiáveis que as válvulas. São feitos de <b>cristal de silício</b>, o elemento mais abundante na Terra.<p>
        <i>Da mesma forma, os transistores, nos circuitos digitais, foram utilizados para representar os dois estados: ligado/desligado, ou seja, <b>zero/um</b></i>.</p>
            <figure>
                <img src ="imagem2.jpg" alt ="imagem2" title ="imagem2"; class="center"><figcaption>Resistor de Transferência ou Transistor</figcaption>
            </figure>
    <h4>4.3.1. O  Primeiro Computador da Unicamp</h4>
        <p>Nos anos 1960 e 70, por causa do emprego do transistor nos circuitos, se deu a explosão, o boom do uso de computadores. Eles ocupavam menos espaço e tinham um custo satisfatório. Em 1968, chegou o primeiro computador da Unicamp, um IBM 1130, com 16 KB de memória e um disco de 1 MB. Foi um acontecimento, ele trabalhava com cartões perfurados. Rodava programas em ASSEMBLER, Fortran e PL1. Para dar partida, se utilizava console e cartões perfurados especialmente codificados, denominados ?cold start?, funções executadas hoje pela ROM e o BIOS.</p>
    <h4>4.4. Máquinas de 3ª Geração (1965-1980)</h4>
        <p>Nos anos 1960, iniciou-se o encapsulamento de mais de um transistor num mesmo receptáculo. Surgiu assim o Circuito Integrado – CI. Os primeiros contavam com cerca de 8 a 10 transistores por cápsula. Nascem, então, os <b>chips</b>.<p>
        Durante a década de 1970, com a tecnologia da alta escala de integração (<i>LSI – Large Scale of Integration</i>), pôde-se combinar até 65 mil componentes em uma só pastilha de silício (chip).</p>
    <h4>4.4. Máquinas de 4ª Geração (1980-199?)</h4>
        <p>Nos anos 1980, com o <i>grande desenvolvimento da tecnologia de circuitos integrados</i>, o número de transistores podendo ser integrados numa pastilha de silício atingiu a faixa dos milhares e, logo em seguida, dos milhões. Foi assim que surgiram os novos computadores, ainda menores, mais velozes e mais poderosos que aqueles da geração anterior.<p>
        Na segunda metade da década de 1990, houve a passagem da LSI para a VLSI (<i>Very Large Scale of Integration</i> – muito alta escala de integração). 
        </p>
    <h4>4.4.1. Era da Informática Pessoal</h4>
        <p>Desde o início da década de 1980, os preços haviam caído de tal maneira que já começava a ser possível a uma pessoa ter o seu próprio computador — começava então a era da <i>informática pessoal</i>.</p>
    <h4>4.4.1.1. Intel</h4>
        <p>Os computadores pessoais passaram então a ser utilizados de uma maneira relativamente distinta da dos grandes computadores de então. No início dessa geração, nasceu a <i>Intel</i>, que começou a desenvolver <b>o primeiro microprocessador</b>, o Intel 4004 de 4 bits, um circuito integrado com 2250 transistores, equivalente ao ENIAC.<p>
        O 4004 foi seguido pelo Intel 8008 de 8 bits e, mais tarde, pelo Intel 8080. O <b>primeiro microcomputador</b> da história foi o <i>Altair 8800</i>, que usava o chip Intel 8088 e tornou-se padrão mundial da época para os microcomputadores de uso pessoal, abrindo uma nova era na história da informática.</p>
    <h4>4.4.1.2. Apple</h4>
        <p>Stephen Wozniak e Steve Jobs formaram em 1976 uma pequena empresa, a Apple, onde construíram, numa garagem de fundo de quintal, o Apple I. Um ano depois, com um novo e melhor projeto, surgiu o Apple II, <b>primeiro microcomputador com grande sucesso comercial</b> e, mais tarde, o Apple III. Em 1983, entrou no mercado o Lisa e, em 1984, <i>o Macintosh, com tecnologia de 32 bits</i>.</p>
    <h4>4.4.1.3. IBM na Computação Pessoal</h4>
        <p>Em 1981, a IBM entrou no mercado de micros, introduzindo o <b>PC</b>, um microcomputador com tecnologia de <i>16 bits (Intel 8088)</i>, que em pouco tempo se tornou um padrão.</p>
    <h4>4.4.1.4. Pentium</h4>
        <p>Em 1993, chegou ao mercado o Pentium, cuja versão <i>Pentium III possui cerca de nove milhões de transistores</i>. O Pentium trouxe um novo fôlego às chamadas <b>estações de trabalho</b> (microcomputadores poderosos usados em tarefas pesadas, como computação gráfica e aplicações científicas).<p>
        Uma das novidades dele é que possibilita a <b>simulação de dois processadores</b>, ou seja, um <i>princípio de paralelização</i>, antes possível apenas em supercomputadores e que agora está ao alcance dos usuários de microcomputadores.</p>
    <h4>4.5. Máquinas de 5ª Geração (Década de 90)</h4>
        <p>A evolução das <b>aplicações de multimídia</b>, envolvendo gráficos, imagens e sons, tornou uma necessidade a implementação de <i>instruções</i> que facilitassem sua execução.</p>
    <h4>4.5.1. Pentium P55C ou MMX</h4>
        <p>Assim, a Intel adicionou ao Pentium 57 <i>novas instruções</i> voltadas para esse tipo de processamento, que são as chamadas <b>instruções MMX</b>, ou seja, <i>Multimedia Extentions</i>. São instruções que englobam várias instruções comuns, e são executadas por hardware, facilitando aos produtores de software a criação de seus programas, já se valendo dessas novas instruções. Tais instruções propiciam um bom <i>ganho em velocidade de processamento</i>.<p>
        O P55C apresenta uma <b>cache interna</b> de 32 kB, o dobro das dos Pentiums P54C. Isso pode se traduzir por uma melhoria de performance da ordem de 10% nos processamentos ditos normais, não envolvendo as funções MMX.</p>
    <h4>4.5.2. Pentium II</h4>
        <p>Engloba o poder de processamento de 32 bits do Pentium PRO, uma melhor performance nos programas de 16 bits e as facilidades do Pentium MMX, operando com clock interno de <i>266 MHz e até 300 MHz</i>. Seu encapsulamento ocorre com uma <b>cache externa ou cache 2</b>, que, <i>contígua ao processador</i>, facilita o gerenciamento da memória e melhora seu desempenho.</p>
    <h4>4.5.3. Pentium II Celeron</h4>
        <p>Semelhante ao Pentium II, é uma opção <i>mais barata</i>, também operando com um <i>clock externo</i> de 66 MHz e um clock interno de 300 MHz, porém <b>sem a cache 2</b> e as vantagens advindas dela.</p>
<h1>Sistemas de Numeração e Conversão de Bases - Decimal e Binário</h1>
    <p>Quando mencionamos sistemas de numeração, estamos nos referindo à utilização de um <i>sistema para representar uma numeração</i>, ou seja, uma <b>quantidade</b>. Sistematizar algo seria organizar, colocar em ordem, submeter a determinadas regras. Um sistema de numeração seria uma forma de <i>organizar a representação de um número</i>. <p>Exemplo: quando contamos algo ou expressamos algum valor, utilizamos, no dia a dia, um sistema de numeração que é o <b>sistema decimal</b>. Para isso, seguimos a organização dos números, pois eles obedecem a certa ordem, e uma das regras é utilizar <i>somente os caracteres 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 combinados</i>, obedecendo à ordenação, para formar os números.<p>O exemplo de um sistema de numeração diferente seria utilizar os seguintes caracteres: 0, 1, 2, 3, C, %,} para representar os números. Ordenando esses caracteres do mesmo modo que o sistema decimal, a contagem nesse sistema seria feita na seguinte ordem: 1, 2, 3, C, %,}, 10, 11, 12, 13, 1C, 1%... O equivalente ao número 10 no sistema decimal seria representado pelo número 13 nesse sistema, o número 11 seria 1C, e assim por diante.<p>Quando desejamos registrar um valor de tensão igual a trinta e quatro vírgula cinquenta e dois volts, usamos os caracteres 3, 4, 5, e 2 dispostos numa certa ordem: 34,52 volts. Essa representação é conhecida como <b>notação posicional do valor observado</b>, em que a importância de cada caractere <i>depende da sua posição em relação aos demais caracteres</i>. Os caracteres têm maior significação no sentido da direita para a esquerda. No caso, os caracteres 3 e 2 são, respectivamente, o de maior e menor significação.
    </p>
<h2>1. Base</h2>
    <p>Os sistemas de numeração foram criados pelo homem com o objetivo de quantificar as grandezas relacionadas às suas observações. Tais sistemas foram desenvolvidos por meio de símbolos, caracteres e do estabelecimento de <i>regras para a sua representação gráfica</i>. <b>O conjunto desses símbolos ou caracteres chamamos de <i>base ou raiz do sistema, "r"</i></b>.<p><i>A base de um sistema de numeração é o número decimal que um sistema de numeração utiliza para indicar uma <b>quantidade</b></i> e, geralmente, <b>é o número de caracteres diferentes utilizados para compor o sistema</b>.</p>
<h4>1.1. Base do Sistema Decimal</h4>
     <p><i>O sistema <b>decimal</b> é dito de <b>base 10</b> por utilizar <b>somente 10 caracteres diferentes</b> para representar os números (os dígitos de 0 a 9)</i>, e a quantidade real representada pelos números tem como base o valor 10. <p>Por exemplo, na contagem do sistema decimal, após o número 9 já utilizamos todos os caracteres diferentes disponíveis, que são 10 (observe que o caractere "0" também está incluído), e um número maior que 9 é representado utilizando uma convenção que atribui um significado numérico quantitativo à posição ou lugar ocupado por um dígito. Cada posição ocupada por um caractere no número possui um "peso" diferente, como no exemplo abaixo: <p>3004 = 3 × <b>10³</b> + 0 × <b>10²</b> + 0 × <b>10¹</b> + 4 × <b>10⁰</b><p>O mesmo artifício é utilizado em outros sistemas de numeração, ou seja, cada caractere que compõe um número possui um <b>"peso" de potências do valor da base que variam de acordo com a posição ocupada pelo caractere</b> no número – no caso do sistema decimal, potências de 10. </p> 
<h4>1.2. Base de Qualquer Sistema</h4>
    <p>No exemplo com o sistema 0, 1, 2, 3, C, %, }, o <b>valor da base é 7</b>, porque 0, 1, 2, 3, C, %,} são um conjunto de <b>sete caracteres diferentes</b> que posso utilizar para compor um número nesse sistema, e a quantidade que os números representam são expressas com base no valor 7. <p>O número <i>31} C</i> representa uma quantidade igual a que número no sistema decimal? Para descobrimos, primeiro, fazemos a potenciação dos caracteres no sistema original₇, para descobrimos suas bases e expoentes:<p> 3 × <b>7³</b> + 1 × <b>7²</b> + } × <b>7¹</b> + C × <b>7⁰</b>.<p> Depois, fazemos a equivalência no sistema decimal₁₀, para evidenciarmos os fatores que se multiplicarão às bases do sistema original₇. Como 3₇ (sistema original) = 3₁₀ (sistema decimal), concluímos que:<p> 1₇ = <b>1</b>₁₀<p> }₇ = <b>6</b>₁₀ <p>C₇ = <b>4</b>₁₀ <br>(repare que zero no sistema decimal também equivale a zero na ordem de quantidade, ou seja, embora a contagem comece do caracter zero, também começaremos do zero na ordem de contagem e não do um, como é usual).<p> Então, basta utilizar o respectivo fator decimal₁₀ junto à base exponenciada original₇.<p>
    Assim: <p>
    31}C = 3 × 7³ + 1 × 7² + 6 × 7¹ + 4 × 7⁰<p>
    31}C = 3 × 343 + 1 × 49 + 6 × 7 + 4 × 1<p>
    31}C = 1029 + 49 + 42 + 4<p>
    31}C₇ = 1.124₁₀<p>
    Quando utilizamos sistemas de numeração diferentes, procuramos adotar uma convenção para a identificação de números com bases de numeração diferentes. Exemplo: 11100₂ = 28₁₀. O número 11100₂ no sistema de base 2 é igual ao número 28₁₀ no sistema decimal.
    </p>
<h2>2. Sistema Decimal</h2>
    <p>Os números decimais são os mais utilizados atualmente de nosso conhecimento. Uma representação posicional no sistema decimal pode ser desenvolvida numa forma polinomial que envolve um somatório de potências de 10. Como exemplo, o número três mil e quatro:<p>
    3004 = 3 × 10³ + 0 × 10² + 0 × 10¹ + 4 × 10⁰<p>
    3004 = 3 × 1000 + 0 × 100 + 0 × 10 + 4 × 1<p>
    3004 = 3000 + 0 + 0 + 4<p>
    3004 = 3004<p>
    É comum utilizarmos um índice (base 2, 10 ou 16) à direita do dígito menos significativo na representação posicional, para identificar a base de representação.
    No caso da base decimal, esse índice pode ser omitido. Os circuitos ditos analógicos processam informações usando o sistema decimal.
    </p>
<h2>3. Sistema Binário</h2>
    <p>O sistema de numeração de base 2 é chamado de sistema binário₂, pois utiliza somente dois dígitos: 0 e 1. Todos os números são representados conforme o posicionamento e a quantidade desses dois dígitos. A contagem segue o mesmo raciocínio utilizado no sistema decimal: após o último dígito, incrementa-se uma posição à esquerda, e a posição à direita é zerada, repetindo-se toda a sequência de números anterior:<p>
    1, 10, 11, 100, 101, 110...<p>
    Para evitar confusão com o sistema de numeração decimal, lemos dígito por dígito no sistema binário:<p>
    10 = hum, zero<p>
    1101 = hum, hum, zero, hum<p> 
    Podemos expressar um número fracionário no sistema binário utilizando a vírgula binária: <p>
    1,1001; 0,0001; 1101,0101...<p>
    Esse sistema pode ser utilizado para representar dois estados de um elemento: uma lâmpada (acesa ou apagada), uma chave (aberta ou fechada), uma fita magnética (variação ou não na magnetização), na genética (presença ou ausência de genes), pois, nos cálculos teóricos, o sistema binário é o mais utilizado para facilitar a manipulação dos dados. <p>Qualquer algarismo ou dígito de número binário é denominado de bit (binary digit). Exemplo: 111011 ? 6 bits
    </p>
<h2>4. Binário para Decimal</h2>
    <p>Uma representação posicional no sistema binário pode ser desenvolvida numa forma polinomial, que envolve um somatório de potências de dois. <p>Assim, o equivalente decimal do número binário é obtido da representação polinomial do número na base dois, por meio do processamento da soma decimal. <p>Exemplo 1: Conversão do número binário 110010 para decimal: <p>
    1- O primeiro dígito da direita para a esquerda do número binário multiplica a potência de 2⁰, o segundo dígito da direita para a esquerda multiplica 2¹, o terceiro dígito à direita multiplica 2², e assim por diante:<p>
    0₂ × 2⁰ = 0 × 1 = 0₁₀<p>
    1₂ × 2¹ = 1 × 2 = 2₁₀<p>
    0₂ × 2² = 0 × 4 = 0₁₀<p>
    0₂ × 2³ = 0 × 8 = 0₁₀<p>
    1₂ × 2⁴ = 1 × 16 = 16₁₀<p>
    1₂ × 2⁵ = 1 × 32 = 32₁₀<p>
    2- A soma dessas multiplicações resulta no número decimal₁₀:<p>
    0 + 2 + 0 + 0 + 16 + 32 = 50₁₀:<p>
    Assim:<p>
    110010₂ = 50₁₀<p>
    Exemplo 2: <p>10101110101001₂ = 
    1 × 2¹³ + <p>
    0 × 2¹² + <p>
    1 × 2¹¹ + <p>
    0 × 2¹⁰ + <p>
    1 × 2⁹ + <p>
    1 × 2⁸ + <p>
    1 × 2⁷ + <p>
    0 × 2⁶ + <p>
    1 × 2⁵ + <p>
    0 × 2⁴ + <p>
    1 × 2³ + <p>
    0 × 2² + <p>
    0 × 2¹ + <p>
    1 × 2⁰<p>
10101110101001₂ = 8192 + 0+2048 + 0 + 512 + 256 + 128 + 0 + 32 + 0 + 8 + 0 + 0 +1<p>
10101110101001₂ = 1117710₁₀    
    </p>
<h4>4.1. Binário Fracionário</h4>
    <p>Podemos representar um número decimal fracionário por um número binário, como no exemplo a seguir:<p>
    111,0101₂ = <p>
    1 x 2² + <p>
    1 x 2¹ + <p>
    1 x 2⁰ + <p>
    0 x 2⁻¹ + <p>
    1 x 2⁻² + <p>
    0 x 2⁻³ + <p>
    1 x 2⁻⁴<p>
    111,0101₂ = <p>
    4 + 2 + 1 + 0 + 0,25 + 0 + 0,0625<p>
    111,0101₂ = 7,3125₁₀</p>
<h4>4.2. Binário Negativo</h4>
    <P>Para a representação de números negativos, pode-se utilizar o sinal "-". Outro método utilizado na prática é o acréscimo de <b>um dígito binário à esquerda do número</b> (<i>bit mais signficativo</i> ou <i>MSB</i>) para indicar esse sinal, ou seja, para indicar se o número é negativo ou não. Os números binários compostos dessa maneira são chamados de <i>números binários com sinal</i> ou <i>números de magnitude com sinal</i> pois <b>o primeiro dígito representa o sinal</b> e <b>os dígitos restantes significam a magnitude do número</b>. Geralmente, <i>o dígito 0 indica um número positivo e o 1 indica um número negativo</i>.</P>
<h4>4.2.1. Complemento de Dois</h4>
    <P>Surge um problema relacionado ao sistema binário com sinal; na verdade, uma ambiguidade, porque um mesmo número binário pode se tratar de um número sem sinal e com sinal negativo. P. ex., 1001₂, que equivaleria ao número decimal 9₁₀ (positivo). Pela regra do número de magnitude com sinal, como o MSB é 1, teoricamente, equivaleria a um número decimal negativo. Mas qual? Não pode equivaler a -9, pois 1001 já representa o número 9 positivo. Daí surge a teoria do complemento de dois ou formato complemento de dois, que é variante do sistema binário.<p>
    A teoria por trás dele é muito simples, para obter a representação negativa de um número, você deve: a) inverter o valor de todos os bits (complemento de um); e b) somar 1 no bit de menor relevância (LSB). <p>
        <figure class=center>
            <img src="complemento%20de%20dois.png" alt="complemento de dois" class=center style=width:520px>
            <figcaption>1001₂ equivale a 9₁₀ e a -7₁₀ (complemento de dois)</figcaption>
        </figure><p>
    Seguindo as setas da esquerda para a direita passamos de binário para decimal: vemos que o MSB é 1, então pegamos o valor 1001₂ e invertemos seus bits, obtendo 0110₂. Após isso, somamos 1, tendo assim 0111₂ como resultado final, que convertido para decimal, vale 7. Mas como sabemos que este número é a representação de um valor usando complemento de dois, sabemos que seu valor é negativo, portanto, -7.<p>
    E ainda dá pra fazer o caminho contrário! Se formos da direita para a esquerda temos o seguinte: temos o número -7 e queremos representá-lo em binário no formato de complemento de dois. Convertemos o número 7 em binário, obtendo 0111₂ e subtraímos 1, o que nos retorna 0110₂. Invertemos os bits, o que resulta em 1001₂. Veja que chegamos em um número com o MSB valendo 1, o que nos sinaliza que é um número negativo.<p>
        <img src="complemento%20de%20dois2.png" alt="complemento de dois 2" class=center style=width:520px;><p>
    Mais sobre complemento de dois será abordado na soma e subtração em <i>Introdução aos Processos de Aritimética</i>.
    </P>
<h2>5. Decimal para Binário</h2>
    <P>Efetua-se uma operação aproximadamente inversa à conversão de binário para decimal utilizando o <b>método das divisões sucessivas</b>: divide-se sucessivamente o número decimal por dois até resultar em um <i>número menor que dois</i>, e os restos dessas divisões com o último resultado formarão o número binário. <b>Esse mesmo método pode ser usado para outros sistemas de numeração de base diferente de 2, como o sistema hexadecimal, cuja base é 16</b>.<p>
    Exemplo 1: Conversão do número decimal <i>1029₁₀</i> para o sistema binário.<p>
        Divide-se o número por dois, que é a base do sistema binário. <i>O resto dessa divisão será o último dígito do número binário</i>:<p>
        <img src="divis%C3%A3o1.jpg" alt="divisão1" class=center><p>
    O resultado dessa divisão é dividido novamente por 2, e <i>o resto será o penúltimo dígito do número binário</i>. O resultado é dividido sucessivas vezes por 2, até a última divisão, em que <i>o resultado for 0 ou 1</i>. O resultado da última divisão será o primeiro dígito do número binário.
        <figure style=margin-left:0px>
            <img src="divis%C3%A3o2.jpg" alt="divisão2" style=width:520px  class=center>
            <figcaption>Repare que o número binário decanta numa ordem invertida, de trás para frente</figcaption>
        </figure><p>
    O número binário é formado pelos restos e pelo resultado da divisão final, sendo este o primeiro número e o primeiro resto, o último número binário. Ou seja:<p>
    1029₁₀ = 10000000101₂<p>
    Exemplo 2: Conversão do número <i>28374₁₀</i> decimal para binário.<p>
        <figure>
            <img src="divis%C3%A3o3.jpg" alt="divisão3" style=width:520px  class=center>
            <figcaption>28374₁₀ = 110111011010110₂</figcaption>
        </figure>
    </P>
<h1>Sistemas Octal e Hexadecimal</h1>
<h2>1. Sistema Octal</h2>
    <P>O sistema de numeração de base 8 que utiliza os <i>caracteres de 0 a 7 do sistema de numeração decimal</i>, na respectiva ordem, é chamado de sistema octal. Esse sistema era mais utilizado antigamente, pois é uma simplificação do sistema binário: <i>3 dígitos binários eram substituídos por 1 dígito no sistema octal, porque o valor máximo de um número de 3 dígitos binários é 111 (3bits), ou seja, 7, que é o número máximo de caracteres diferentes utilizados pelo sistema octal (base 8)</i>. Atualmente, o sistema octal entrou em desuso pela utilização cada vez maior da informática e de circuitos eletrônicos digitais, que empregam somente números binários. Em substituição ao sistema octal, é utilizado o <b>sistema hexadecimal</b>.
        <p>
            0₁₀ = 0₈<p>
            1₁₀ = 1₈<p>
            2₁₀ = 2₈<p>
            3₁₀ = 3₈<p>
            4₁₀ = 4₈<p>
            5₁₀ = 5₈<p>
            6₁₀ = 6₈<p>
            7₁₀ = 7₈<p>
            8₁₀ = 10₈<p>
            9₁₀ = 11₈<p>
            10₁₀ = 12₈<p>
            etc...
    </P>
<h2>2. Sistema Hexadecimal</h2>
    <P>O sistema hexadecimal de numeração pode representar 4 bits do sistema binário por cada dígito (o número máximo obtido com quatro dígitos binários é 16₁₀, que é a base do sistema hexadecimal) utilizando os <i>dígitos de 0 a 9 do sistema decimal e representando os números de 10 a 15 pelos caracteres A, B, C, D, E, F</i>. A contagem no sistema hexadecimal se processa da seguinte forma: 0,1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 1A, 1B...<p>
        A₁₆ = 10₁₀<p>
        99F₁₆ = 2463₁₀<p>
        BBC₁₆ = 3004₁₀<p>
    </P>
<h2>3. Hexadecimal para Decimal</h2>
    <P>Uma representação posicional no sistema hexadecimal pode ser desenvolvida numa forma polinomial que envolve um somatório de <b>potências de 16</b>. Executa-se um processo <i>semelhante à conversão dos números binários para decimal</i>. 
        <p>
    Exemplo 1: Conversão do número <i>A01₁₆</i> hexadecimal para decimal. O primeiro dígito da direita para a esquerda do número hexadecimal multiplica a potência de 16⁰, o segundo dígito da direita para a esquerda multiplica 16¹, o terceiro dígito à direita multiplica 16², e assim por diante. Caso exista um dígito maior que 9, deve-se convertê-lo para decimal e multiplicar normalmente:<p>
        1 × 16⁰ = 1 × 1 = 1₁₀ <p>
        0 × 16¹ = 0 × 16 = 0₁₀<p>
        A × 16² = A × 256 = 10 × 256 = 2560₁₀<p>
    A soma dessas multiplicações resulta no número decimal:<p>
    1 + 0 + 2560 = 2561₁₀<p>
    Assim: <p>A01₁₆ = 2561₁₀<p>
    Exemplo 2:<p>
    BF20₁₆ = B × 16³ + F × 16² + 2 × 16¹ + 0 × 16⁰<p>
    BF20₁₆ = 11 × 4096 + 15 × 256 + 2 × 16 + 0 × 1<p>
    BF20₁₆ = 45056 + 3840 + 32 + 0<p>
    BF20₁₆ = 48928₁₀<p>
    Exemplo 3:<p>
    600CD₁₆ = 6 × 16⁴ + 0 × 16³ + 0 x 16² + C × 16¹ + D × 16⁰<p>
    600CD₁₆ = 6 × 65536 + 0 × 4096 + 0 × 256 + 12 × 16 + 13 × 1<p>
    600CD₁₆ = 393421₁₀
    </P>
<h2>3. Decimal para Hexadecimal</h2>
    <P>Utiliza-se o <b>método das divisões sucessivas</b>: <i>divide-se sucessivamente o número decimal por 16 até resultar em um número menor que 16</i>, e os restos dessas divisões com o resultado da última divisão formarão o número hexadecimal.<p>
    Exemplo 1: Conversão do número decimal 4096 para hexadecimal.<p>
        <img src="divis%C3%A3o4.jpg" alt="divisão4" class=center><p>
    Assim:<p>
        4096₁₀ = 1000₁₆<p>
    Exemplo 2: Conversão do número 3748 decimal para hexadecimal<p>
        <img src="divis%C3%A3o5.jpg" alt="divisão5" class=center><p>
        Se:<p>
        14₁₀ = E₁₆<p>
        10₁₀ = A₁₆<p>
        Logo:<p>
        3748₁₀ = 14₁₀, 10₁₀ e 4₁₀<p>
        3748₁₀ = EA4₁₆</P>
<h4>3.1. Método da Divisão Inteira pela Base</h4>
    <img src="infogr%C3%A1fico1.png" alt="infográfico1" style=width:520px class=center>
<h4>3.2. Conversões</h4>
    <img src="convers%C3%B5es.jpg" alt="conversões" style=width:520px class=center>
<h1>Bit e Byte</h1>
<h2>1. Binário para Hexadecimal</h2>
    <P>É possível a conversão de informação binária para hexadecimal, convertendo-se primeiro para decimal e em seguida para hexadecimal, conforme os métodos já estudados. Esse método é o de <b>conversão indireta.</b><p>
    Porém, é possível a <b>conversão direta</b> de binário para hexadecimal. É simples: substitui-se quatro dígitos binários por um dígito hexadecimal, porque 4 digitos binários (4bits) alcançam a quantia decimal de máximo 15 (F₁₆), que, por acaso, é a base do sistema hexadecimal. <p>
    Exemplo 1: Conversão do número <i>11101₂</i> em binário para o sistema hexadecimal.<p>
    Obtenho os quatro últimos dígitos do número binário: 1101<p>
    Converto diretamente para hexadecimal: 1101₂= 13₁₀ = D₁₆<p>
    Com isso, obtenho o último dígito do número hexadecimal: D₁₆<p>
    Repito o mesmo método para os dígitos restantes do número binário: 1₂ = 1₁₀= 1₁₆ <p>
    Unindo os dois dígitos, obtenho o número em hexadecimal: 11101₂ = 1D₁₆<p>
    Exemplo 2: Conversão do número <i>100101010₂</i> em binário para o sistema hexadecimal.<p>
    1010₂ = 10₁₀ = A₁₆<p>
    0010₂ = 2₁₀ = 2₁₆<p>
    1₂ = 1₁₀ = 1₁₆<p>
    100101010₂ = 12A₁₆
    </P>
<h2>2. Hexadecimal para Binário</h2>
    <P>Já conversão de hexadecimal para binário pode ser feita de forma direta do modo contrário ao anterior: converte-se em quatro dígitos binários cada dígito hexadecimal. O último dígito do número hexadecimal fornece o valor dos quatro últimos dígitos do número binário.<p> 
    Exemplo 3: Conversão do número <i>CDF </i>hexadecimal para o sistema binário.<p>
    F₁₆ = 15₁₀ = 1111₂<p>
    D₁₆ = 13₁₀ = 1101₂<p>
    C₁₆ = 12₁₀ = 1100₂<p>
    CDF₁₆ = 110011011111₂<p>
    Exemplo 4: Conversão do número <i>1002₁₆</i><p> hexadecimal para o sistema binário.<p>
    2₁₆ = 0010₂<p>
    0₁₆ = 0000₂<p>
    0₁₆ = 0000₂<p>
    1₁₆ = 0001₂<p>
    1002₁₆ = 1000000000010₂</P>
<h2>3. Bit e Byte</h2>
    <P>O computador trabalha com sinais elétricos em dois níveis <i>R 0 e +V</i>  ou <i>0 e RV R</i>, os quais são chamados de <b>estados lógicos</b>. Para definir cada estado lógico, ficou estabelecido que, quando temos <b>0 V (zero volt)</b>, o valor do estado lógico é <b>0 (zero)</b>, e, quando temos <b>+ V ou ? V</b>, o valor do estado lógico é <b>1</b>.<p>
    Assim, com a disponibilidade de <i>apenas dois números</i>, os cientistas criaram uma tabela de combinações desses estados. As tabelas são formadas de uma composição de <b>8 estados lógicos</b>. Essa combinação é chamada de <b>byte</b>, e cada um dos estados lógicos são chamados de <b>bit</b>. Um conjunto de <b>8 bits, portanto, equivale a um byte</b>.<p>
    Para representar a linguagem do usuário, o computador usa a relação da tabela de combinações dos estados lógicos para compor <i>um caractere, o qual se constitui das letras de uma palavra ou de pontuações das frases</i>. <b>Um caractere equivale ao conjunto de 8 bits (1byte)</b>. Uma palavra se forma com a combinação de um conjunto de bytes. Por isso, cada letra, número, pontuação e sinais gráficos se forma no computador pela associação de 8 bits.
    </P>
<h2>4. Tabela ASC II</h2>
    <P>No entanto, para não haver diversidade de tabelas entre os fabricantes, garantindo a interoperabilidade entre eles, padronizou-se o mesmo valor para cada caractere. Instituiu-se a tabela ASCII (American Standard Code for Information Intercharge) como um conjunto de códigos-padrão para o computador representar números, letras, pontuação e outros caracteres. A tabela ASC II mostra no que um valor hexadecimal (decimal) corresponde ao código ASC II, que nada mais é que os nossos caracteres de digitação (ASCII).</P>
<h2>5. KB, MB, GB, TB, PB</h2>
    <P>Os computadores têm suas características de processamento expressas em número de <b>bits (8, 16, 32 ou 64)</b>. Cada instrução enviada para o microprocessador pode ser formada por <i>1 byte, 2 bytes, 3 bytes e 4 bytes</i>. Assim, dependendo da instrução, são necessárias de 1 (Sistema 64bits) a 4 linhas (Sistema 8bits) de memória para armazená-la e cada linha, repita-se, é múltipla de 8 (1024 bytes p. ex., e não 1000 bytes). <p> Já o espaço em disco ou memórias define-se como múltiplos de 1KByte, em que 1KB é igual a 1024 Bytes (2¹⁰). A tabela a seguir mostra os múltiplos do byte.<p>
    <img src="KB,%20MB,%20GB,%20TB.png" alt="KB, MB, GB" style=width:520px class=center>
    </P>
<h1>Introdução aos Processos de Operação Aritimética - Soma</h1>
    <P>Um sistema numérico pode ser usado para realizar duas operações básicas: adição e subtração. Pelo uso de adição e subtração, você pode então realizar multiplicações, divisões e qualquer outra operação numérica. Nesta aula, a aritmética binária (adição, subtração, multiplicação e divisão) será examinada, usando a aritmética decimal como um guia.
    </P>
<h2>1. Adição Decimal</h2>
    <P>A adição binária é realizada como a adição decimal. Se dois números decimais 56719 e 31863 são adicionados, a soma 88582 é obtida. Você pode analisar os detalhes dessa operação da seguinte maneira:<p>
     <img src="soma.jpg" alt="somadecimal" class=center><p>
    Somando a primeira coluna, com os números decimais 9 e 3, o resultado é o dígito 2 com um transporte de 1. O transporte é então somado à próxima coluna. Adicionado à segunda coluna (1 + 1 + 6), o resultado é o número 8, sem transporte. Esse processo continua até que todas as colunas (incluindo os transportes) tenham sido somadas. A soma representa o valor numérico das parcelas.</P>
<h2>2. Adição Binária</h2>
    <P>Quando você soma dois números binários, você realiza a mesma operação para somar. <p>   <img src="soma1.jpg" alt="somabinária1" class=center><p>
    Para ilustrar o processo de adição binária, vamos somar 1101 a 1101:<p>
        <img src="soma2.jpg" alt="somabinária2" class=center><p>
    Na primeira coluna, 1 mais 1 resulta 0 com um transporte de 1 para a segunda coluna. Isso concorda com a regra 4.<p> Na segunda coluna, 0 mais 0 resulta 0 sem transporte. A esse resultado, o transporte da primeira coluna é somado. Assim, 0 mais 1 resulta 1 sem transporte. Essas duas adições na segunda coluna dão uma soma total de 1 com um transporte de 0. As regras 1 e 2 foram usadas para obter a soma.<p>
    Na terceira coluna, 1 mais 1 resulta 0 com um transporte de 1. Nessa soma, o transporte da segunda coluna é somado. Isso resulta uma soma da terceira coluna de 0 com um transporte de 1 para a coluna 4. As regras 4 e 2 foram usadas para obter a soma.<p>
    Na coluna quatro, 1 mais 1 resulta 0 com um transporte de 1. Para essa soma, o transporte da terceira coluna é somado. Isso resulta uma soma da quarta coluna de 1 com um transporte para a quinta coluna. A regra 5 permite somar três 1 binários e obter 1 com um transporte de 1.<p>
    Na quinta coluna, não há parcelas. Portanto, você pode assumir a regra 3 e somar o transporte a 0 para obter a soma 1. Assim, a soma 1101₂ mais 1101₂ é igual a 11010₂
    </P>
<h1>Introdução aos Processos de Operação Aritimética - Subtração</h1>
    <P>Um sistema numérico pode ser usado para realizar duas operações básicas: adição e subtração. Pelo uso de adição e subtração, você pode então realizar multiplicações, divisões e qualquer outra operação numérica. Nesta aula, a aritmética binária (adição, subtração, multiplicação e divisão) será examinada, usando a aritmética decimal como um guia.<p><img src="subtra%C3%A7%C3%A3o.jpg" alt="subtraçãodecimal" class=center><p>
    A subtração binária é realizada exatamente como subtração decimal. Portanto, antes de realizarmos a subtração binária, vamos revisar a subtração decimal. Você sabe que, se 5486 é subtraído de 8303, a diferença 2817 é obtida. <p>
    Como o dígito 6 no subtraendo é maior que o dígito 3 no minuendo, um 1 é emprestado do próximo dígito de maior ordem no minuendo. Se esse dígito é zero, como no nosso exemplo, 1 é emprestado do próximo dígito de ordem maior que contenha um número diferente de zero. Aquele dígito é reduzido de 1 (de 3 para 2 no nosso exemplo), e aos dígitos pulados no minuendo é dado o valor 9. Isso é equivalente a remover 1 de 30 com o resultado de 29, por exemplo.<p>
    No sistema decimal, o dígito emprestado tem o valor de 10. Portanto, o dígito do minuendo agora tem o valor 13, e 6 de 13 resulta 7. Na segunda coluna 8 de 9 resulta 1. Desde que o subtraendo é maior que o minuendo na terceira coluna, 1 é transportado do próximo dígito de ordem superior. Isso suspende o valor do minuendo de 2 para 12, e 4 de 12 resulta 8. <p>Na quarta coluna, o minuendo foi reduzido de 8 para 7 por causa do empréstimo prévio, e 5 de 7 resulta 2. Toda vez que 1 é emprestado de um dígito de ordem superior, o empréstimo é igual, em valor, à base do sistema numérico. Portanto, um empréstimo no sistema numérico decimal é igual a 10, enquanto um empréstimo no sistema numérico binário é igual a 2.
    </P>
<h2>1. Subtração Binária</h2>
    <P>Quando se subtrai um número binário de outro, você usa o mesmo método descrito para subtração decimal.<p>
        <img src="subtra%C3%A7%C3%A3o1.jpg" alt="subtraçãobinária1" class=center><p>
    Para ilustrar o processo da subtração binária, vamos subtrair 1101 de 11011. A linha "empréstimo" nos mostra o valor de cada dígito do minuendo depois da ocorrência de cada transporte. Lembre-se de que o binário 10 é igual ao decimal 2. <p>
        <img src="subtra%C3%A7%C3%A3o2.jpg" alt="subtraçãobinária2" class=center><p>
    Na primeira coluna, 1 de 1 resulta 0 (regra 2). Então, 0 de 1 na segunda coluna resulta 1 (regra 3). Na terceira coluna, 1 de 0 necessita de um empréstimo da quarta coluna. Assim, 1 de 10₂ resulta 1 (regra 4).
    O minuendo na quarta coluna é agora 0, por causa do empréstimo. Portanto, um empréstimo é necessário da quinta coluna, de maneira que 1 de 10₂ na quarta coluna resulta 1 (regra 4). Por causa do empréstimo anterior, o minuendo na quinta coluna é agora 0, e o subtraendo é 0 (não existe), de modo que 0 de 0 resulta 0 (regra 1). O 0 na quinta coluna não é mostrado na diferença, pois não é um bit significativo. Assim, a diferença entre 11011₂ e 1101₂ é 1110₂.
    Pode-se verificar isso convertendo os números binários para decimal. Como exemplo de subtração binária, subtraia 00100101₂ de 11000100₂, como mostrado a seguir.<p>
    Quando um empréstimo ("borrow") é necessário, 1 é obtido do próximo bit de ordem superior que possui 1. Aquele bit, então, torna-se 0 e a todos os bit pulados (bits de valor 0) damos o valor 1. Isso é equivalente a remover 1 de 1000₂.<p>
        <img src="subtra%C3%A7%C3%A3o3.jpg" alt="subtraçãobinária3" class=center><p>
    Como na adição binária, os microprocessadores geralmente realizam subtrações em grupos de números de 8 bits. No exemplo anterior, a resposta contém apenas 6 bits significativos, mas dois 0 foram acrescentados para manter o grupo de 8 bits. Isso será verdade também para o minuendo e o subtraendo.
    </P>
<h2>2. Aritimética do Complemento de Dois</h2>
    <P>Uma característica do sistema de complemento de dois é que tanto os números com sinal quanto os números sem sinal podem ser somados pelo mesmo circuito. Por exemplo, suponha que você deseja somar os números sem sinal 132₁₀ e 14₁₀.<p>
    O microprocessador tem um circuito ALU que pode somar números binários sem sinal. Quando aparece o padrão 10000100₂ em uma entrada e 00001110₂ na outra entrada, resulta 10010010₂ na saída.<p>
     <img src="soma3.jpg" alt="soma3" class=center><p>
    Surge a pergunta: como a ALU sabe que os padrões de bits nas entradas representam número sem sinal e não números em complemento de dois?<p>
    E a resposta é: não sabe. A ALU sempre soma como se as entradas fossem números binários sem sinal. Sempre produzirá o resultado correto, mesmo se as entradas forem números em complemento de dois.<p>
    Observe o exemplo anterior. Se você assumir que as entradas são números com sinal em complemento de dois, então:<p>
    Verifique que os padrões de bits são os mesmos. Apenas o significado mudou.<p>
    Na primeira linha, nós assumimos que o padrão de bits representam números sem sinal e o somador produz o resultado sem sinal conveniente. Na segunda linha, nós assumimos que os padrões de bits representam números com sinal. Novamente, o somador fornece o resultado correto.<p>
        <img src="soma4.jpg" alt="soma4" class=center><p>
    Isso comprova um ponto muito importante. O somador na ALU sempre soma padrões de bits como se eles fossem números binários sem sinal.<p>
    É a nossa interpretação desses padrões que decide se números com ou sem sinal estão sendo indicados. O bom do complemento de dois é que os padrões de bits podem ser interpretados de qualquer maneira. Isso nos permite trabalhar com números com e sem sinal sem requerer diferentes circuitos para cada padrão.<p>
    </P>
<h4>2.1. Subtração em Complemento de Dois</h4>
    <P>Existe outra forma de fazer a subtração em binário. Pode-se obter o resultado da subtração <b>somando-se</b> o complemento de 2 do valor, e ignorando-se o último algarismo (MSB).<p>
        <img src="complemento%20de%20dois3.png" alt="complementodedois3" class=center style=width:520px>
    </P>
<h1>Funções e Portas Lógicas – Tabela Verdade e Expressões Booleanas</h1>
    <P>Em 1854, o matemático inglês George Boole apresentou um sistema matemático de análise lógica conhecido como <b>álgebra de Boole</b>. Somente em 1938, um engenheiro americano utilizou as teorias da álgebra de Boole para a solução de problemas de <i>circuitos de telefonia com relés</i>, tendo publicado um artigo que praticamente introduziu na área tecnológica o campo da <b>eletrônica digital</b>. <p>Os <i>sistemas digitais</i> são formados por <i>circuitos lógicos</i> denominados de <b>portas lógicas</b> que, utilizados de forma conveniente, podem implementar todas as expressões geradas pela álgebra de Boole. <p>Existem três portas básicas (<b>E</b>, <b>OU</b> e <b>NÃO</b>) que podem ser conectadas de várias maneiras, formando sistemas que vão de simples relógios digitais aos computadores de grande porte.
    </P>
<h2>1. Função E (AND)</h2>
    <P>A <b>função E (AND)</b> é aquela que executa a <i>multiplicação de duas ou mais variáveis</i> booleanas. Sua representação algébrica para duas variáveis é S = A × B, em que se lê: S = A e B.
            <p class="round"><b>S = A × B</b></p><p>
    Para compreender a função E (AND) da álgebra booleana, deve-se analisar o circuito da Figura 1, para o qual se adota as seguintes convenções: chave aberta = 0, chave fechada = 1, lâmpada apagada = 0 e lâmpada acesa = 1.<p>
        <img src="sistema.jpg" alt="sistemaelétrico" class=center><p>
    A análise da Figura 1 revela que a lâmpada somente acenderá se ambas as chaves estiverem fechadas e, seguindo a convenção, tem-se: CH A = 1, CH B = 1, que resulta em S = 1.<p>
    Pode-se, dessa forma, escrever todas as possíveis combinações de operação das chaves na chamada <b>tabela da verdade</b>, que é definida como um <i>mapa em que se depositam todas as possíveis situações com seus respectivos resultados</i>. O número de combinações possíveis é igual a 2N, em que <b>N é o número de variáveis de entrada</b>.<p>
        <figure>
            <img src="verdade.jpg" alt="tabelaverdade" class=center>
                <figcaption>Tabela da verdade da função E (AND)</figcaption>
        </figure><p>
    A porta lógica E é um circuito que executa a função E (AND) da álgebra de Boole, sendo representada, na prática, por meio do símbolo visto na Figura 2.<p>
        <img src="sistema1.jpg" alt="sistemaelétrico1" class=center>
    <p style=text-align:end>"<i>A saída da porta E (AND) será 1 somente</i><br> <b>se todas as entradas forem 1.</b>"</p>
    </P>
<h2>2. Função OU ou OR</h2>
    <P>A <b>função OU (OR)</b> é aquela que assume valor 1 quando <i>uma ou mais variáveis de entrada forem iguais a 1</i>, e assume 0 se, e somente se, <b>todas as variáveis de entrada forem iguais a zero</b>. Sua representação algébrica para duas variáveis de entrada é S = A + B, em que se lê: S = A ou B.
          <p class="round"><b>S = A + B</b></p>
    <p>
    Para entender melhor a função OU (OR) da álgebra booleana, analise todas as situações possíveis de operação das chaves do circuito da Figura 3. A convenção é a mesma adotada anteriormente: chave aberta = 0, chave fechada = 1, lâmpada apagada = 0 e lâmpada acesa = 1.<p>
        <img src="sistema2.jpg" alt="sistemaelétrico2" class=center><p>
    O circuito apresentado mostra que a lâmpada acende quando qualquer uma das chaves estiver fechada e permanece apagada se ambas estiverem abertas, ou seja, CH A = 0, CH B = 0, que resulta em S = 0. <p>
    Pode-se, dessa forma, escrever todas as possíveis combinações de operação das chaves na chamada tabela da verdade, que é definida como um mapa em que se depositam todas as possíveis situações com seus respectivos resultados. O número de combinações possíveis é igual a 2N, em que N é o número de variáveis de entrada.
         <figure>
            <img src="verdade1.jpg" alt="tabelaverdade1" class=center>
                <figcaption>Tabela da verdade da função OU (OR)</figcaption>
        </figure><p>
    A figura a seguir ilustra a porta lógica que executa a função OU da álgebra de Boole.<p>         <img src="sistema3.jpg" alt="sistema3" class=center><p style=text-align:end>"<i>"A saída de uma porta OU (OR) será 1</i><br> <b>se uma ou mais entradas forem 1.</b>"</p>
    </P>
<h2>3. Função NÃO (NOT)</h2>
    <P>A <b>função NÃO (NOT)</b> é aquela que inverte ou complementa o estado da variável de entrada, ou seja, se a variável estiver em 0, a saída vai para 1, e, se estiver em 1, a saída vai para 0. É representada algebricamente da seguinte forma: S = Ā, em que se lê: A barra ou NÃO A.
    <p class="round2"><b>S = Ā</b></p>
    <p> A análise do circuito da Figura 5 ajuda a compreender melhor a função NÃO (NOT) da álgebra booleana. Será utilizada a mesma convenção dos casos anteriores.
        <img src="sistema4.jpg" alt="sistemaelétrico4" class=center>
    <p>Observando o circuito da Figura 5, pode-se concluir que a lâmpada estará <i>acesa somente se a chave estiver aberta (CH A = 0, S = 1)</i>; quando a chave fecha, a corrente desvia por ela e a lâmpada apaga (CH A = 1, S = 0). <p>O inversor é o bloco lógico que executa a função NÃO (NOT). Sua representação simbólica é vista na Figura 6.<p> 
        <img src="sistema5.jpg" alt="sistemaelétrico5" class=center>
        <figure>
             <img src="verdade2.jpg" alt="tabelaverdade2" class=center>
            <figcaption>Tabela da verdade da função NÃO (NOT)</figcaption>
        </figure><p>
        <p style=text-align:end>"<i>A saída de uma porta NÃO (NOT) assume o nível lógico 1 somente</i><br> <b>quando sua entrada é 0 e vice-versa.</b>"</p>
    </P>
<h2>4. Função NÃO E (NAND)</h2>
    <P>Essa função é uma composição das funções E (AND) e NÃO (NOT), ou seja, é a função E (AND) invertida. Sua representação algébrica é <img src="https://latex.codecogs.com/svg.image?\inline&space;{S&space;=&space;\overline{A&space;\times&space;B}}" title="https://latex.codecogs.com/svg.image?\inline {S = \overline{A \times B}}" />, em que o traço indica que ocorrerá uma inversão do produto booleano A × B.   
        <p class="round"><img src="https://latex.codecogs.com/svg.image?\inline&space;\mathbf{S&space;=&space;(\overline{A&space;\times&space;B})}" title="https://latex.codecogs.com/svg.image?\inline \mathbf{S = (\overline{A \times B})}" /></p>
    <p>O circuito da Figura 7 esclarece o comportamento da função NE. Observa-se que a lâmpada apaga <i> somente quando ambas as chaves são fechadas</i>, ou seja, <b>CH A = 1, CH B = 1, que implica em S = 0</b>. <p>
        <img src="sistema6.jpg" alt="sistemaelétrico6" class=center><p>
    A Figura 8 ilustra o circuito que executa a função NE da álgebra de Boole.<p>
        <img src="sistema7.jpg" alt="sistemaelétrico7" class=center><p>
        <figure>
             <img src="verdade3.jpg" alt="tabelaverdade3" class=center>
            <figcaption>Tabela da verdade da função NE (NAND)</figcaption>
        </figure><p style=text-align:end>
        "<i>Essa função é o inverso da função E, ou seja, a saída será 0</i> <br><b>somente quando todas as entradas forem 1.</b>"</p>
    </P>
<h2>4. Função NÃO OU (NOR)</h2>
    <P>Analogamente à função NE (NAND), a função NOU (NOR) é a composição da função OU (OR) com a função NÃO (NOT), ou seja, é a função OU (OR) invertida. É representada algebricamente da seguinte forma: <img src="https://latex.codecogs.com/svg.image?\inline&space;\mathit{S&space;=&space;(\overline{A&space;&plus;&space;B})}" title="https://latex.codecogs.com/svg.image?\inline \mathit{S = (\overline{A + B})}" />, em que o traço indica que ocorrerá uma inversão da soma booleana A + B.<p>Para melhor compreender a função NOU (NOR) da álgebra de Boole, pode-se analisar o circuito da figura a seguir, em que se observa que a lâmpada fica acesa <i>somente quando as duas chaves estão abertas</i>. Assim, <b>CH A = 0, CHB = 0, que resulta em S = 1</b>.
        <p class="round"><img src="https://latex.codecogs.com/svg.image?\inline&space;\mathbf{S&space;=&space;(\overline{A&space;&plus;&space;B})}" title="https://latex.codecogs.com/svg.image?\inline \mathbf{S = (\overline{A + B})}" /></p><p>
        <img src="sistema8.jpg" alt="sistemaelétrico8" class=center><p>
    A Figura 10 ilustra o circuito que executa a função NOU (NOR) da álgebra de Boole.<p>
         <img src="sistema9.jpg" alt="sistemaelétrico9" class=center>
        <figure>
             <img src="verdade4.jpg" alt="tabelaverdade4" class=center>
            <figcaption>Tabela da verdade da função NOU (NOR)</figcaption>
        </figure>   
    <p style=text-align:end>
    "<i>Essa função é o inverso da função OU (OR), ou seja, a saída será 0</i><br> <b>se uma ou mais entradas forem 1.</b>"
    </P>
<h2>5. Função OU EXCLUSIVO (XOR)</h2>
    <P>Essa função, como o próprio nome diz, apresenta <b>saída com valor 1 quando as variáveis de entrada forem diferentes entre si</b>. A notação algébrica que representa a função OU EXCLUSIVO (XOR) é <img src="https://latex.codecogs.com/svg.image?\inline&space;S&space;=&space;(A&space;\bigoplus&space;B)" title="https://latex.codecogs.com/svg.image?\inline S = (A \bigoplus B)" />, em que se lê: A OU EXCLUSIVO B. <p>
        <p class="round3"><img src="https://latex.codecogs.com/svg.image?\inline&space;\mathbf{S&space;=&space;(A&space;\bigoplus&space;B)}" title="https://latex.codecogs.com/svg.image?\inline \mathbf{S = (A \bigoplus B)}" /></p><p>
    Para entender melhor a função OU EXCLUSIVO (XOR), analise o circuito da Figura 11. Na condição em que as chaves CH A e CH B ficam abertas (e ficam fechadas), não há caminho para a corrente circular e a lâmpada não acende. A lâmpada continua apagada quando as chaves CH A e CH B estão fechadas, pois CH<img src="https://latex.codecogs.com/svg.image?\inline&space;\overline{A}" title="https://latex.codecogs.com/svg.image?\inline \overline{A}" /> e CH<img src="https://latex.codecogs.com/svg.image?\inline&space;\overline{B}" title="https://latex.codecogs.com/svg.image?\inline \overline{B}" /> estão abertas, interrompendo o fluxo de corrente. Portanto, pode-se concluir que esse bloco <b>só terá nível 1 na saída (lâmpada acesa) quando suas entradas forem diferentes</b>.<p>
    <img src="sistema10.jpg" alt="sistemaelétrico10" class=center><p>
    A Figura 12 simplesmente simboliza o circuito lógico que executa a função OU EXCLUSIVO (XOR). Na verdade, o circuito que efetivamente realiza a função demonstrada na tabela da verdade está ilustrado na Figura 11.<p>
    <img src="sistema11.jpg" alt="sistemaelétrico11" class=center><p>
    A Figura 13 ilustra o símbolo que representa, na prática, a função XOR.<p>
    <img src="sistema12.jpg" alt="sistemaelétrico12" class=center><p>
        <figure>
             <img src="verdade5.jpg" alt="tabelaverdade5" class=center>
            <figcaption>Tabela da verdade da função XOR</figcaption>
        </figure>   
    <p>
    Observação importante: esse bloco lógico OU EXCLUSIVO (XOR) é definido <b>apenas</b> para duas variáveis de entrada.
    </P>
<h2>6. Função COINCIDÊNCIA ou NÃO OU EXCLUSIVO (XNOR)</h2>
    <P>Essa função, como seu próprio nome diz, apresenta saída com valor 1 quando houver uma coincidência nos valores das variáveis de entrada. A notação algébrica que representa a função Coincidência é <img src="https://latex.codecogs.com/svg.image?\inline&space;S&space;=&space;(A&space;\bigodot&space;&space;B)" title="https://latex.codecogs.com/svg.image?\inline S = (A \bigodot B)" />, em que se lê: A Coincidência B.
        <p class="round3"><img src="https://latex.codecogs.com/svg.image?\inline&space;\mathbf{S&space;=&space;(A&space;\bigodot&space;&space;B)}" title="https://latex.codecogs.com/svg.image?\inline \mathbf{S = (A \bigodot B)}" /></p>
    <p>O circuito da Figura 14 ajuda a compreender a operação da função Coincidência. Quando as chaves CH A e CH B estão abertas (CH<img src="https://latex.codecogs.com/svg.image?\inline&space;\overline{A}" title="https://latex.codecogs.com/svg.image?\inline \overline{A}" /> e CH<img src="https://latex.codecogs.com/svg.image?\inline&space;\overline{B}" title="https://latex.codecogs.com/svg.image?\inline \overline{B}" /> estão fechadas) circula corrente pela lâmpada e ela estará acesa. Quando CH A = 1 e CH B = 0 (CH B=1), não circula corrente pela lâmpada, o que implica em lâmpada apagada. Na situação inversa, CH A = 0 (CH = 1) e CH B = 1, ocorre a mesma coisa e a lâmpada não acenderá. Com as duas chaves fechadas, ou seja, CH A = CH B = 1 (CH = CH = 0) circulará corrente pela lâmpada e esta estará acesa. Portanto, pode-se afirmar que <b>a porta Coincidência terá 1 em sua saída (lâmpada acesa) quando as entradas forem idênticas</b>.<p>
        <img src="sistema13.jpg" alt="sistemaelétrico13" class=center><p>
    A Figura 15 simplesmente representa simbolicamente o circuito lógico que executa a função Coincidência. Na verdade, o circuito capaz de realizar essa função é ilustrado na Figura 14.<p>
        <img src="sistema14.jpg" alt="sistemaelétrico14" class=center><p>
    A Figura 16 ilustra o símbolo que representa, na prática, a função XNOR.<p>
        <img src="sistema15.jpg" alt="sistemaelétrico15" class=center>
        <figure>
             <img src="verdade6.jpg" alt="tabelaverdade6" class=center>
            <figcaption>Tabela da verdade da função XNOR</figcaption>
        </figure> <p>
    Observação importante: Assim como ocorre com o bloco lógico OU EXCLUSIVO (XOR), o circuito COINCIDÊNCIA (XNOR) é definido apenas para duas variáveis de entrada.
    </P>
<h2>7. Resumo das Tabelas Verdade</h2>
    <P>
        <figure>
            <img src="verdade.jpg" alt="tabelaverdade" class=center>
                <figcaption>Tabela da verdade da função E (AND)</figcaption>
        </figure>
        <figure>
            <img src="verdade1.jpg" alt="tabelaverdade1" class=center>
                <figcaption>Tabela da verdade da função OU (OR)</figcaption>
        </figure>
        <figure>
             <img src="verdade2.jpg" alt="tabelaverdade2" class=center>
            <figcaption>Tabela da verdade da função NÃO (NOT)</figcaption>
        </figure>
        <figure>
             <img src="verdade3.jpg" alt="tabelaverdade3" class=center>
            <figcaption>Tabela da verdade da função NE (NAND)</figcaption>
        </figure> 
        <figure>
             <img src="verdade4.jpg" alt="tabelaverdade4" class=center>
            <figcaption>Tabela da verdade da função NOU (NOR)</figcaption>
        </figure>
        <figure>
             <img src="verdade5.jpg" alt="tabelaverdade5" class=center>
            <figcaption>Tabela da verdade da função XOR</figcaption>
        </figure>  
        <figure>
             <img src="verdade6.jpg" alt="tabelaverdade6" class=center>
            <figcaption>Tabela da verdade da função XNOR</figcaption>
        </figure>
    <p> Veja também:
        <ul>
            <li>Logic circuit.<br> www.logiccircuit.org/</li><p>
            <li>Redstone circuits.<br> www.minecraftwiki.net/</li><p>
            <li>Simulador de lógica digital.<br> bradwarestudios.com/</li><p>
            <li>Simulador de porta lógica em Adobe Flex. <br>joshblog.net/</li><p>
            <li>Simulador de portas lógicas.<br> www.neuroproductions.be/</li><p>
            <li>Usando portas lógicas <br>knol.google.com/</li>
        </ul>
    </P>
<h1>Funções e portas lógicas - Expressões booleanas obtidas de circuitos lógicos e circuitos lógicos obtidos de expressões booleanas</h1>
<h2>1. Expressões Booleanas Obtidas de Circuitos Lógicos</h2>
    <P>Todo circuito lógico executa uma função booleana e, por mais complexo que seja, é formado pela interligação das portas lógicas básicas. Assim, pode-se obter a expressão booleana que é executada por um circuito lógico qualquer. <p>Para exemplificar, será obtida a expressão que o circuito da Figura 1 executa. O exemplo da Figura 2 visa evidenciar um símbolo de negação muito utilizado e que muitas vezes é esquecido e não considerado. Ele pode ser utilizado na saída de uma porta lógica (?), como na porta NÃO E (NAND) a seguir.<p>
        <img src="sistema16.jpg" alt="sistemaelétrico16" class=center style="width:520px"><p>
        <img src="sistema17.png" alt="sistemaelétrico17" class=center style="width:520px">
    </P>
<h2>2. Circuitos Lógicos Obtidos de Expressões Booleanas</h2>
    <P>Será visto neste tópico que é possível desenhar um circuito lógico que executa uma função booleana qualquer, ou seja, pode-se desenhar um circuito a partir de sua expressão característica.<p> O método para a resolução consiste em se identificar as portas lógicas na expressão e desenhá-las com as respectivas ligações, a partir das variáveis de entrada. Deve-se sempre respeitar a hierarquia das funções da aritmética elementar, ou seja, a solução inicia-se primeiramente pelos parênteses. Para exemplificar, será obtido o circuito que executa a expressão S = (A + B).C.(B + D).<p> Para o primeiro parêntese, tem-se uma soma booleana A + B, logo o circuito que o executa será uma porta OU (OR). Para o segundo, tem-se outra soma booleana B + D, logo o circuito será uma porta OU (OR). Posteriormente, tem-se a multiplicação booleana de dois parênteses com a variável C, sendo o circuito que executa essa multiplicação uma porta E. Para finalizar, unem-se as respectivas ligações obtendo o circuito completo.<p>
        <img src="sistema18.jpg" alt="sistemaelétrico18" class=center style="width:520px">
    </P>
<h1>Circuitos Lógicos, Tabelas Verdade e Expressões Booleanas</h1>
<h2>1. Tabelas da Verdade Obtidas de Expressões Booleanas</h2>
    <P>Uma maneira de se fazer o estudo de uma função booleana é utilizar a tabela da verdade. Para extrair a tabela da verdade de uma expressão, deve-se seguir alguns procedimentos:
        <ol class=number>
            <li>Montar o quadro de possibilidades;</li><p>
            <li>Montar colunas para os vários membros da equação;</li><p>
            <li>Preencher essas colunas com os seus resultados;</li><p>
            <li>Montar uma coluna para o resultado final;</li><p>
            <li>Preencher essa coluna com os resultados finais;</li><p>
        </ol><p>
    Para exemplificar esse processo, utiliza-se a expressão: <img src="https://latex.codecogs.com/svg.image?\inline&space;S&space;=&space;A\overline{B}C&space;&plus;&space;A\overline{D}&space;&plus;&space;\overline{A}BD" title="https://latex.codecogs.com/svg.image?\inline S = A\overline{B}C + A\overline{D} + \overline{A}BD" />. A expressão contém quatro variáveis: A, B, C e D. Logo, existem 2⁴ = 16 possibilidades de combinação de entrada. Dessa forma, monta-se o quadro de possibilidades com <b>quatro variáveis de entrada</b> e <b>três colunas auxiliares, sendo uma para cada membro da expressão e outra para o resultado final</b>.<p>
        <img src=verdade7.jpg alt=tabelaverdade7 class="center" style=width:520px></P>
<h2>2. Expressões Booleanas Obtidas de Tabelas da Verdade</h2>
    <P>Neste item, será estudada a forma de obter expressões e circuitos a partir de tabelas da verdade, sendo esse o caso mais comum de projetos práticos, pois, em geral, é necessário representar situações por meio de tabelas da verdade e, a partir delas, obter a expressão booleana e, consequentemente, o circuito lógico. Para demonstrar esse procedimento, será obtida a expressão da seguinte tabela:<p>
        <img src=verdade8.jpg alt=tabelaverdade8 class="center"><p>
    Na tabela, analisa-se onde S = 1 e monta-se a expressão adequada:<p>
        <ul>
            <li>Em (a), S = 1 se <img src="https://latex.codecogs.com/svg.image?\inline&space;S&space;=&space;\overline{A}BC" title="https://latex.codecogs.com/svg.image?\inline S = \overline{A}BC" /></li>
            <li>Em (b), S = 1 se <img src="https://latex.codecogs.com/svg.image?\inline&space;S&space;=&space;A\overline{B}C" title="https://latex.codecogs.com/svg.image?\inline S = A\overline{B}C" /></li>
            <li>Em (c), S = 1 se <img src="https://latex.codecogs.com/svg.image?\inline&space;S&space;=&space;AB\overline{C}" title="https://latex.codecogs.com/svg.image?\inline S = AB\overline{C}" /></li>
            <li>Em (d), S = 1 se <img src="https://latex.codecogs.com/svg.image?\inline&space;S&space;=&space;ABC" title="https://latex.codecogs.com/svg.image?\inline S = ABC" /></li>
        </ul><p>
    Para se obter a expressão, basta realizar a soma booleana de cada termo citado: <img src="https://latex.codecogs.com/svg.image?\inline&space;S&space;=&space;\overline{A}BC&space;&plus;&space;A\overline{B}C&space;&plus;&space;AB\overline{C}&space;&plus;&space;ABC" title="https://latex.codecogs.com/svg.image?\inline S = \overline{A}BC + A\overline{B}C + AB\overline{C} + ABC" /><p>
    Nota-se que o método permite obter, de qualquer tabela, uma expressão padrão <b>formada sempre pela soma de produtos</b>.
    </P>
<h1>Aplicação de Circuitos Lógicos</h1>
    <P>O projeto de um circuito lógico começa na racionalização do problema, por meio das combinações possíveis, para o entendimento do comportamento de um evento. Feito isso, elabora-se a tabela da verdade que expressa esse comportamento. Da tabela da verdade é possível extrair a expressão algébrica booleana que determina o circuito lógico adequado para comandar o evento desejado (TANENBAUM, 2007).</P>
<h2>Problema 1</h2>
    <P>Uma pessoa deseja projetar um sistema que acione um alarme contra roubo quando alguém forçar a porta de entrada ou janela de sua casa. Por análise, pode-se determinar que a porta e a janela são responsáveis pela sinalização de entrada de dados (A = porta e B = janela), e o alarme é acionado pelo sinal da saída de dados quando alguém tenta entrar na casa. As possíveis situações em que as saídas são perturbadas (acionadas), e consequentemente a saída que se deseja, estão descritas na tabela 1, que se segue: <p>
        <img src=verdade9.jpg alt=tabelaverdade9 class="center"><p>
    Diz-se, então, que a tabela 1 é a tabela da verdade para o problema proposto. Como apenas os casos em que a saída é igual a 1 interessam para a solução do problema, temos que os termos dados por cada saída serão expressos da forma como mostra a tabela 2:<p>
        <img src=verdade10.jpg alt=tabelaverdade10 class="center"><p>
    O termo <img src="https://latex.codecogs.com/svg.image?S&space;=&space;\overline{A}&space;\times&space;B" title="https://latex.codecogs.com/svg.image?S = \overline{A} \times B" /> significa que A deve ser zero (<img src="https://latex.codecogs.com/svg.image?\overline{A}" title="https://latex.codecogs.com/svg.image?\overline{A}" />) e B deve ser 1 (B), ao mesmo tempo (×), para que o alarme seja acionado (S = 1). O termo  <img src="https://latex.codecogs.com/svg.image?S&space;=&space;A&space;\times&space;\overline{B}" title="https://latex.codecogs.com/svg.image?S = A \times \overline{B}" /> significa que A deve ser 1 (A) e B deve ser 0 (<img src="https://latex.codecogs.com/svg.image?\overline{B}" title="https://latex.codecogs.com/svg.image?\overline{B}" />), ao mesmo tempo (×), para que o alarme seja acionado (S = 1). O termo <img src="https://latex.codecogs.com/svg.image?S&space;=&space;A&space;\times&space;B" title="https://latex.codecogs.com/svg.image?S = A \times B" /> significa que A deve ser 1 (A) e B deve ser 1 (B), ao mesmo tempo (×), para que o alarme seja acionado (S = 1). Na tabela 2, na situação em que ocorre uma das possibilidades em que o alarme é acionado (S = 1), o primeiro termo (A = 0 e B = 1) indica que a porta não foi forçada, mas a janela sim. O segundo termo (A = 1 e B = 0) mostra que dessa vez a porta foi aberta e a janela não. O terceiro termo (A = 1 e B = 1) acusa que as duas foram forçadas por alguém.<p>
    Para o acionamento do alarme, portanto, serve qualquer uma das alternativas apontadas. Representa-se, então, essa possibilidade com o sinal + entre os termos. A expressão algébrica booleana que ilustra a solução do problema é dada pela soma dos termos: <img src="https://latex.codecogs.com/svg.image?S&space;=&space;\overline{A}&space;\times&space;&space;B&space;&plus;&space;A&space;\times&space;\overline{B}&space;&plus;&space;A&space;\times&space;B" title="https://latex.codecogs.com/svg.image?S = \overline{A} \times B + A \times \overline{B} + A \times B" />. Para a equação apresentada, cada termo pode ser expresso por uma porta:
        <p>
        <img src=sistema19.jpg alt=sistemaelétrico19 class="center"><p>
    Como mostra a Figura 1, o sinal da entrada A foi combinado com o sinal da entrada B numa porta AND. O sinal (• ou ×) indica o tipo de porta usada para essa combinação.
        <p>
        <img src=sistema20.jpg alt=sistemaelétrico20 class="center"><p>
    Nesse exemplo da Figura 2, o sinal da entrada A foi invertido numa porta NOT antes de ser combinado com B numa porta AND.<p>
        <img src=sistema21.jpg alt=sistemaelétrico21 class="center"><p>
    Dessa vez, na Figura 3, o sinal da entrada B foi invertido por uma porta NOT para depois ser combinado com A numa porta AND. A somatória dos termos configura a composição das portas, conforme mostrado no esquema a seguir.
        <p>
        <img src=sistema22.jpg alt=sistemaelétrico22 class="center"><p>
    Os três termos estão representados pelos seus respectivos conjuntos de portas, dos quais as devidas saídas são ligadas numa porta OR, determinando assim a combinação dos três termos, como mostra a equação 1 com o sinal (+). Para que se possa verificar se o circuito obtido condiz com a expressão proposta pelo problema, procede-se à análise como segue:
        <p>
        <img src=sistema23.jpg alt=sistemaelétrico23 class="center"><p>
    Na saída do circuito, ou seja, na saída da porta OR, o resultado será:
        <img src="https://latex.codecogs.com/svg.image?S&space;=&space;\overline{A}&space;\times&space;&space;B&space;&plus;&space;A&space;\times&space;\overline{B}&space;&plus;&space;A&space;\times&space;B" title="https://latex.codecogs.com/svg.image?S = \overline{A} \times B + A \times \overline{B} + A \times B" />
    </P>
<h1>Conceitos Básicos de Arquitetura e Organização</h1>
    <P>Na literatura, ao se descrever um sistema de computação, é feita uma distinção entre os termos: arquitetura e organização do computador. O <b>termo arquitetura</b> de um computador refere-se aos <i>atributos de um sistema que são visíveis para o programador</i> ou, em outras palavras, aos atributos que têm impacto direto sobre a <i>execução lógica</i> de um programa. Já o <b>termo organização</b> de um computador diz respeito às <i>unidades operacionais e suas interconexões que efetivam as especificações de sua arquitetura</i>, ou seja, como as características da arquitetura são implementadas. <p>Por <b>atributos de arquitetura</b>, podemos entender: o conjunto de <i>instruções, o número de bits usados para representar os tipos de dados, os mecanismos de E/S etc.</i>, enquanto os <b>atributos da organização</b> são <i>transparentes aos usuários e incluem detalhes de hardware</i>, por exemplo: sinais de controle, tecnologia de memória utilizada etc. <p>Especificar se um computador deve ou não ter uma instrução de multiplicação constitui uma decisão de projeto da arquitetura. Por outro lado, definir se essa instrução será implementada por uma unidade específica de multiplicação ou por um mecanismo que utiliza repetidamente sua unidade de soma é uma decisão de projeto de sua organização. Exemplo: todo INTEL da família x86 compartilha a mesma arquitetura básica => compatibilidade. No entanto, a organização difere de uma versão para a outra. Conclusão: uma organização deve ser projetada para implementar uma especificação particular de arquitetura.</P>
<h2>Estrutura x Função</h2>
    <P>Tanto a estrutura quanto as funções de um computador são muito simples. 
    <ul>
        <li><b>Estrutura</b>: é a <i>forma como os componentes se relacionam uns com os outros</i>.</li><p> 
        <li><b>Função</b>: <i>a operação que cada componente individual realiza dentro da organização</i>.</li>
    </ul>
        <p>As funções básicas que um computador pode desempenhar são: <i>processamento de dados, armazenamento de dados, transferência de dados e controle.</i><p>
    <ul>
        <li><b>Unidade central de processamento</b>: <i>controla a operação do computador e desempenha funções de processamento de dados (processador)</i>.</li><p> 
        <li><b>Memória principal</b>: <i>armazena dados e instruções</i>.</li> <p> 
        <li><b>E/S</b>: <i>transfere dados entre o computador e o ambiente externo</i>.</li><p> 
        <li><b>Sistema de interconexão</b>: <i>mecanismos que estabelecem a comunicação entre a CPU, memória principal e os dispositivos de E/S</i>.</li>
    </ul><p>
        <img src=conceitos1.jpg alt:conceitos1 class=center style=width:520px><p>
    Dentre os componentes de um computador, a CPU é o que apresenta uma estrutura mais complexa, sendo seus principais itens:
        <ul>
            <li><b>Unidade de controle (UC)</b>: controla a operação da CPU e, portanto, do computador.</li><p>
            <li><b>Unidade lógica aritmética (ULA)</b>: realiza todo o processamento de dados, por operações lógicas aritméticas.</li><p>
            <li><b>Registradores</b>: oferecem um tipo de armazenamento interno de dados para a CPU.</li><p>
            <li><b>Interconexão da CPU</b>: mecanismo que possibilita a comunicação entre as unidades de controle, a ULA e os registradores. </li>
        </ul><p>
        <img src=conceitos2.jpg alt:conceitos2 class=center style=width:520px>
        <p>
        <img src=conceitos3.jpg alt:conceitos3 class=center style=width:520px><p>
    </P>
<h1>Estrutura Básica do Computador; Busca e Execução de Instruções; Interrupções; Barramentos</h1>
    <P>Os barramentos são <i>portas pelas quais o processador pode comunicar-se com os demais componentes do micro</i>, como a placa de vídeo. Falando em placa de vídeo, você já percebeu que todas as placas de vídeo modernas são conectadas em slots <i>PCI ou AGP</i>? E que placas de som e modems antigos quase sempre usam slots <i>ISA</i>? Isso acontece porque placas de som e modems são periféricos relativamente lentos, para os quais o lento barramento ISA já é suficiente. Porém, as placas de vídeo necessitam de um barramento muito mais rápido, motivo pelo qual utilizam slots PCI ou AGP.</P>
<h2>1. Barramentos Antigos</h2>
    <P>Os processadores 8088, usados nos micros XT, comunicavam-se com os demais periféricos usando palavras binárias de 8 bits. Para o uso em conjunto com esses processadores, foi criado o <i>ISA de 8 bits</i>. Esse barramento funciona usando palavras binárias de 8 bits e opera a uma frequência de <b>8 MHz</b>, permitindo uma passagem de dados a uma velocidade de <b><i>8 megabytes por segundo</i></b>, velocidade muito mais do que suficiente para um processador lento como o 8088.</P>
<h4>1.1. ISA (Industry Standard Architecture)</h4>
    <P>Os processadores 286 se comunicavam com os demais periféricos usando palavras de 16 bits. Para acompanhar essa melhora por parte do processador, foi criada uma extensão para o barramento ISA de 8 bits, formando o <i>ISA de 16 bits</i>. Esse barramento, assim como o processador 286, trabalha com palavras de 16 bits, a uma frequência de <b>8 MHz</b>, permitindo um barramento total <b><i>de 16 MB/s</i></b>. Os periféricos ISA vem sendo usados desde a época do 286, mas, na verdade, esse padrão já existe desde 1981, ou seja, quase 40 anos de idade! <p>O ISA é um bom exemplo de padrão obsoleto que foi ficando, ficando, ficando, mesmo depois de terem sido criados barramentos muito mais rápidos, como o PCI. A verdade é que o ISA durou muito tempo porque o barramento de 16 megabytes por segundo permitido por ele é suficiente para acomodar periféricos lentos como modems e placas de som, fazendo com que os fabricantes desses periféricos se acomodassem, e continuassem produzindo periféricos ISA praticamente até hoje.
    </P>
<h4>1.2. MCA (Micro Channel Architecture)</h4>
    <P>Com o surgimento dos processadores 386, que trabalhavam usando palavras binárias de <i>32 bits</i>, tornou-se necessária a criação de um barramento mais rápido que o ISA para o uso de periféricos rápidos, como placas de vídeo e discos rígidos. A IBM criou então o MCA, que funcionava com palavras de 32 bits e a uma frequência de <b>10 MHz</b>, sendo 2,5 vezes mais rápido que o ISA de 16 bits. Apesar de trazer recursos surpreendentes para a época em que foi lançado, como o bus mastering e suporte ao plug-and-play (foi o primeiro barramento a suportar esses recursos, isso em 1987), o MCA não conseguiu se popularizar por causa de seu alto custo, incompatibilidade com o ISA e, principalmente, por ser uma arquitetura fechada, caindo em desuso com o surgimento do EISA e do VLB.
    </P>
<h4>1.3. EISA (Extended ISA)</h4>
    <P>Esse novo barramento foi uma resposta dos demais fabricantes liderados pela Compac ao MCA, criado e patenteado pela IBM. Com o objetivo de ser <i>compatível com o ISA</i>, o EISA funciona também a <b>8 MHz</b>, porém, trabalha com palavras binárias de <i>32 bits</i>, totalizando <b><i>32 MB/s</i></b> de barramento, sendo duas vezes mais rápido do que seu antecessor. O EISA também oferecia suporte a <i>bus mastering e plug-and-play</i>, com eficiência comparável à do MCA. Uma das grandes preocupações dos fabricantes durante o desenvolvimento do EISA foi manter a compatibilidade com o ISA. O resultado foi um slot com duas linhas de contatos, capaz de acomodar tanto placas EISA quanto placas ISA de 8 ou 16 bits.
    </P>
<h4>1.4. VLB (VESA Local Bus)</h4>
    <P>Lançado em 1993 pela Video Electronics Standards Association, o VLB é muito mais rápido que o EISA ou o MCA, sendo utilizado por placas de vídeo e controladoras de disco, as principais prejudicadas pelos barramentos lentos. Com o VLB, os discos rígidos podiam comunicar-se com o processador usando toda a sua velocidade, e se tornou possível a criação de placas de vídeo muito mais rápidas. Como antes, existiu a preocupação de manter a <i>compatibilidade com o ISA</i>, de modo que os slots VLB são compostos por três conectores. Os dois primeiros são idênticos a um slot ISA comum, podendo ser encaixada neles uma placa ISA, sendo o terceiro destinado às transferências de dados a altas velocidades permitidas pelo VLB. As desvantagens do VLB são a <i>falta de suporte a bus mastering e a plug-and-play</i>, além de uma <i>alta taxa de utilização do processador e limitações elétricas</i>, que permitem um máximo de 2 ou 3 slots VLB por máquina.
    </P>
<h4>1.5. PCMCIA (Personal Computer Memory Card International Association)</h4>
    <P>O PCMCIA é utilizado principalmente em <i>notebooks e handhelds</i> em que, na maioria das vezes, é o único meio de conectar placas de expansão. A principal vantagem desses dispositivos é o <i>tamanho: todos possuem dimensões um pouco menores que as de um cartão de crédito, apenas mais espessos</i>. Atualmente é possível encontrar praticamente qualquer tipo de dispositivo na forma dessas placas: modems, placas de som, placas de rede, placas decodificadoras de DVD, cartões de memórias SRAM e memórias flash e, até mesmo, discos rígidos removíveis
    </P>
<h4>1.6. AMR (Audio Modem Riser)</h4>
    <P>Esse é um padrão de barramento que permite o encaixe de placas de som e modems controlados via software. O slot AMR se parece com um slot AGP, mas tem apenas 1/3 do tamanho deste. O objetivo é permitir a criação de componentes extremamente baratos para serem usados em micros de baixo custo. A vantagem é o <i>preço</i>, já que uma placa de som ou modem AMR não custa mais de 5 ou 7 dólares para o fabricante (um pouco mais para o consumidor final, naturalmente). <i>A desvantagem, por sua vez, é o fato desses componentes serem controlados via software, o que consome recursos do processador principal</i>, tornando o micro mais lento.
    </P>
<h4>1.7. ACR (Advanced Communications Riser)</h4>
    <P>O ACR é um padrão desenvolvido por uma associação de vários fabricantes, que inclui a AMD, Lucent, Motorola, 3Com, Nvidia, Texas Instruments e Via. Os slots ACR se parecem com um slot PCI invertido; na verdade os fabricantes optaram por aproveitar o mesmo encaixe para cortar custos, mas as semelhanças param por aí, já que foram mudadas a posição e a sinalização elétrica do slot. Os slots ACR são risers para a conexão de placas de som e modems de baixo custo, assim como os slots AMR. Muitas placas atuais trazem um slot ACR, mas os fabricantes evitam desenvolver placas com dois ou mais slots ACR para não diminuir o número de slots PCI da placa. A principal vantagem do ACR sobre o AMR é que, enquanto o AMR permite que o riser inclua apenas modem e placa de som, no ACR <i>o riser pode conter praticamente todos os tipos de dispositivo</i>, desde modems e placas de som baratas, controlados via software, até placas de rede, modems ADSL ou ISDN, placas de som e modems controlados via hardware etc.
    </P>
<h4>1.8. AGP (Accelerated Graphics Port)</h4>
    <P>O AGP é um barramento feito sob medida para as placas de vídeo. O AGP foi criado com base nas especificações do PCI 2.1 e opera ao dobro da velocidaden do PCI, ou seja, <b>66 MHz</b>, permitindo transferências de dados a <b><i>266 MB/s</i></b>, contra apenas 133 MB/s possíveis pelo barramento PCI. Além da velocidade, o AGP permite que uma placa de vídeo possa <i>acessar diretamente a memória RAM para armazenar texturas</i>. Esse é um recurso muito utilizado em placas 3D, que usa a memória RAM para armazenar as texturas que são aplicadas sobre os polígonos que compõem a imagem tridimensional.
    </P>
<h2>2. Barramentos Mais Recentes</h2>
    <P>Atualmente, os computadores possuem barramentos mais rápidos capazes de suportar vários equipamentos em uma mesma porta. Os principais barramentos utilizados hoje são os seguintes.</P>
<h4>2.1. PCI (Peripheral Component Interconnect)
</h4>
    <P>Criado pela Intel, o PCI é <i>tão rápido quanto o VLB, porém mais barato e muito mais versátil</i>. Outra vantagem é que, ao contrário do VLB, ele <i>não é controlado pelo processador, e sim por uma controladora dedicada, incluída no chipset</i>. Além de diminuir a utilização do processador, isso permite que o PCI seja <i>empregado com qualquer processador</i>, sem qualquer tipo de modificação. Atualmente, todos os periféricos rápidos, placas de vídeo e controladoras de disco, usam quase obrigatoriamente o barramento PCI. Componentes mais lentos, como placas de som e modems, ainda podem ser encontrados em versões ISA, apesar de cada vez mais acharmos esses componentes em versões PCI.
    </P>
<h4>2.2. USB (Universal Serial Bus)</h4>
    <P>O USB é um padrão para a conexão de periféricos externos. Suas principais armas são a <i>facilidade de uso e a possibilidade de se conectar vários periféricos a uma única porta USB</i>. É o primeiro barramento para micros PC <i>realmente plug-and-play</i>. Podemos conectar periféricos <i>mesmo com o micro ligado</i>, bastando fornecer o driver do dispositivo para que tudo funcione sem ser necessário nem mesmo reinicializar o micro. A controladora USB também é suficientemente <i>inteligente para perceber a desconexão de um periférico</i>. Podemos conectar <b>até 127 periféricos em fila a uma única saída USB</b>, ou seja, conectando o primeiro periférico à saída USB da placa-mãe e conectando os demais a ele. O USB, em sua versão 2.0 (2001 - <i>Hi-Speed</i>), possui uma taxa de transferência que pode chegar a <i>480 Mbps</i>. Porém, os avanços de conectividade da USB foram expressivos e, após 7 gerações, a USB4 (2019 - <i>SuperSpeed+, Thunderbolt3 and 4</i>) alcança incríveis <b><i>40 GBps</i></b>, com bitrate de <i>20Ghz</i>!
    </P>
<h4>2.3. IEEE 1394 (FireWire)</h4>
    <P>O FireWire (também conhecido como i.Link, IEEE 1394 ou High Performance Serial Bus/HPSB) é uma interface serial para computadores pessoais e aparelhos digitais de áudio e vídeo que oferece <i>comunicações de alta velocidade e serviços de dados em tempo real</i>. O FireWire pode ser considerado uma tecnologia sucessora da quase obsoleta interface paralela SCSI. Podemos conectar <b>até 63 periféricos em fila a uma única saída FireWire</b>, ou seja, conectando o primeiro periférico à saída FireWire da placa-mãe e conectando os demais a ele. <p>O FireWire é uma tecnologia de entrada/saída de dados em alta velocidade para conexão de dispositivos digitais, desde camcorders e câmeras digitais, até computadores portáteis e desktops. Amplamente adotado por fabricantes de periféricos digitais como Sony, Canon, JVC e Kodak, o FireWire tornou-se um padrão estabelecido na indústria tanto por consumidores como por profissionais. Desde 1995, um grande número de camcorders digitais modernos inclui essa ligação, assim como os computadores Macintosh e PCs da Sony, para uso profissional ou pessoal de áudio/vídeo. O FireWire também foi usado no iPod da Apple durante algum tempo, o que <i>permitia que as novas músicas pudessem ser carregadas em apenas alguns segundos, recarregando simultaneamente a bateria com a utilização de um único cabo</i>. Os modelos mais recentes, porém, como o iPod nano e o novo iPod de quinta geração, já não utilizam uma conexão FireWire (apenas USB 2.0).
    </P>
<h4>2.4. Pedido de interrupção (IRQ)</h4>
    <P>Nos micros PC, existe um recurso chamado de pedido de interrupção. A função dos pedidos de interrupção é <i>permitir que os vários dispositivos do micro façam solicitações ao processador</i>. Existem 16 canais de interrupção, chamados de IRQ ("interrupt request", ou "pedido de interrupção"), que são como cordas que um dispositivo pode puxar para dizer que tem algo para o processador. <i>Quando solicitado, o processador para tudo o que estiver fazendo para dar atenção ao periférico que está chamando, continuando seu trabalho após atendê-lo</i>. Dois dispositivos não podem compartilhar a mesma interrupção, caso contrário teríamos um conflito de hardware. Isso acontece porque, nesse caso, o processador não saberá qual dispositivo o está chamando, causando os mais diversos tipos de mau funcionamento dos dispositivos envolvidos. Normalmente os endereços IRQ ficam configurados da seguinte maneira:<p>
        <img src=barramento.jpg alt=barramento class=center>
    <p>
    Caso determinado dispositivo não esteja instalado, a interrupção destinada a ele ficará vaga. <i>É possível também mudar os endereços dos periféricos instalados</i>, por exemplo, instalar uma placa de som em outra interrupção disponível e usar a interrupção cinco para outro dispositivo.
    </P>
<h1>Sistema de Armazenamento e Hierarquia de Memória</h1>
    <P>Memória é o dispositivo físico capaz de <i>armazenar algum tipo de conteúdo</i> para uso no computador. Esse conteúdo pode ser:
    <ul>
        <li>Instruções;</li><p>
        <li>Dados;</li><p>
        <li>Resultados de processamento intermediário; ou</li><p>
        <li>Resultados de processamento final (informação).</li>
    </ul>
    <p>Apesar de parecer simples como conceito, a memória de um computador exibe, talvez, a mais vasta gama de tipos, tecnologia, organização, rendimento e custos, dentre todas as especificidades de um sistema de computação. Nenhuma tecnologia pode ser considerada ótima em termos da satisfação dos requisitos de memória de um sistema de computação. <p>Como consequência, o sistema de computação típico está equipado com uma hierarquia de subsistemas de memória, alguns internos ao sistema (diretamente acessíveis ao processador) e outros externos (acessíveis ao processador por meio de um módulo de E/S).
    </P>
<h2>1. Memória Interna e Externa</h2>
    <P>A memória interna (também chamada de primária) é responsável pelo <b>armazenamento temporário</b> de dados utilizados no processamento. É essencial para que ocorra o processamento. Corresponde aos <i>registradores, cache e memória principal</i>. <p>Já a memória externa (secundária) armazena <b>dados não voláteis</b> em dispositivos periféricos acessíveis por meio de controladores de E/S. Alguns exemplos: <i>disco rígido, CD-rom etc</i>. Na base da pirâmide que representa a hierarquia de memória em um sistema de computação encontra-se um tipo de memória com maior capacidade de armazenamento do que os outros tipos já descritos, menor custo por byte armazenado e com tempos de acesso também superiores aos outros tipos:<p>
        <img src=mem%C3%B3ria.png alt=memória class="center" style=width:520px>  
        <img src="tabela2.jpg" alt="tabela2" class=center style=width:520px>
    <p>Essa memória, denominada <b>memória secundária, memória auxiliar ou memória de massa</b>, tem por objetivo garantir um armazenamento mais permanente a toda a estrutura de dados e programas do usuário, razão pela qual deve naturalmente possuir maior capacidade que a memória principal. A memória secundária de um sistema de computação pode ser constituída por diferentes tipos de dispositivos, alguns diretamente ligados ao sistema para acesso imediato (discos rígidos, por exemplo), e outros que podem ser conectados quando desejado (como os disquetes, fitas de armazenamento, CD-ROM etc.), cuja informação armazenada se torna diretamente conectada e disponível para o específico disquete ou fita que estiver inserido no elemento de leitura/escrita (drive ou acionador), enquanto os demais ficam disponíveis (off-line) para acesso manual pelo usuário.
    </P>
<h2>2. Capacidades</h2>
<h4>2.1. Tensões Binárias</h4>
    <P>Por causa da simplicidade de projeto e construção, acarretando a redução de seu custo e maior confiabilidade, <i>os circuitos eletrônicos que formam os computadores digitais atuais são capazes de distinguir apenas <b>dois níveis de tensão</b></i> (computadores digitais binários).<p> Esses sinais elétricos são tensões que assumem dois diferentes valores: um <b>valor positivo</b> (hoje, nos PCs, cerca de <b>+3V</b>) para representar o <b>valor binário 1</b> e um valor aproximado a <b>0V</b> para representar o <b>valor binário 0</b>. Na realidade, esses valores não são absolutos, e sim faixas de valores com uma margem de tolerância (entre + 2,5 e + 3,5 V para 1 e entre 0 e + 0,5 V para 0). <p>A lógica que permite aos computadores operar baseados nesses dois valores é chamada <b>Álgebra de Boole</b>, em homenagem ao matemático inglês George Boole (1815–1864).
    </P>
<h4>2.2. Medidas de Capacidade</h4>
    <P>
    <ul>
        <li><b>BIT</b>: contração de BInary DigiT e representa um dos valores possíveis em binário, 0 ou 1.</li><p>
        <li><b>BYTE</b>: é um grupo de 8 bits (é bom lembrar que 2³ = 8). Em um byte, há 2⁸ = 256 combinações, portanto, pode-se representar 256 diferentes valores, desde 00000000 até 11111111.</li>
    </ul><p>
    Na informática, a expressão kilo (abreviada por k) equivale a 2¹⁰. Dessa forma, 1 kilobit (1 kb) equivale a 2¹⁰ bits (1024 bits) e 1 kilobyte (1 kB) equivale a 2¹⁰ bytes, ou seja, 1024 bytes ou, ainda, 8.192 bits. Da mesma forma, a expressão mega equivale a 2²⁰, ou seja, 2¹⁰ x 2¹⁰ = 1.048.576. Dessa forma, 1 megabit (1 Mb) equivale a 2²⁰ bits, ou seja, 1024 kb ou 1.048.576 bits, e 1 megabyte equivale a 2²⁰ bytes, ou seja, 1.048.576 bytes. Seguem-se 1 giga, equivalente a 2³⁰ ou 1024 megas, 1 tera, equivalente a 2⁴⁰ ou 1.024 gigas, e 1 peta, equivalente a 2⁵⁰ ou 1.024 teras.<p>
        <img src="KB,%20MB,%20GB,%20TB.png" alt="KB, MB, GB" style=width:520px class=center>
    </P>
<h2>3. Unidades de Transferência e Armazenamento</h2>
<h4>3.1. Unidades de  Transferência</h4>
    <P>As unidades de transferência de dados são medidas da seguinte forma:
    <ul>
        <li>Em <b>memórias primárias</b>: é o número de <i>bits</i> que podem ser lidos/escritos de cada vez (<i>palavra</i>).</li><p>
        <li>Em <b>memórias secundárias</b>: é a quantidade de blocos de dados lidos/escritos por vez (<i>célula</i>).</li>
    </ul><p>
    Um termo comumente empregado é a <b>palavra</b>, que representa <i>a unidade de informação da CPU e da memória principal</i>. O conceito mais usado define palavra como sendo a capacidade de manipulação de <i>bits</i> do núcleo do computador (CPU e MP). Pressupõe-se aqui que todos os elementos do núcleo do computador (que incluem o tamanho da ULA, registradores da CPU e o barramento de dados) tenham a mesma largura (processem simultaneamente o mesmo número de <i>bits</i>), <b>o que nem sempre acontece</b>.<p> Muitas vezes encontram-se computadores cujo tamanho da ULA e dos registradores não é o mesmo dos barramentos. Dessa forma, encontram-se especificações de computadores de <b>64 bits, mesmo quando seu barramento de dados é de 32 bits</b>. Concluindo, deve-se analisar caso a caso, porque a simples menção ao tamanho da palavra não é uma terminologia que permita definir de forma conclusiva a arquitetura do computador.</P> 
<h4>3.2. Armazenamento</h4>
    <P>Quanto ao armazenamento, os dados apresentam outra forma. Em geral, o termo <b>célula</b> é usado para definir a <i>unidade de armazenamento</i>, e o termo <b>palavra</b> para definir a <i>unidade de transferência e processamento</i>, significando na prática quantos <i>bits</i> o computador movimenta e processa em cada operação. Não confundir: célula não é sinônimo de palavra, embora em algumas máquinas a palavra seja igual à célula.
    </P>
    <h2>4. Hierarquia de Memórias</h2>
    <P>As restrições no projeto de memória de um computador podem ser sumarizadas em três questões: a) Qual sua <i>capacidade de armazenamento</i>? b) Qual sua <i>velocidade de acesso</i>? c) Qual seu <i>preço por bit</i> armazenado? <p>Existe uma variedade de tecnologias usadas para implementar os sistemas de memória. Nesse espectro de tecnologias, podem ser consideradas as seguintes relações:
    <ul>
        <li>Tempo de acesso mais curto (↓), maior o custo por bit (↑).</li><p>
        <li>Maior capacidade (↑), menor o custo por bit (↓).</li><p>
        <li>Maior capacidade (↑), maior o tempo de acesso (↑).</li><p>
    </ul><p>
    Um projetista gostaria de usar as tecnologias de memória que disponibilizam uma elevada capacidade de memória, tanto porque a capacidade é necessária como pelo baixo custo por bit. Contudo, para atingir os requisitos de rendimento, necessita usar memórias dispendiosas, de relativamente baixa capacidade de armazenamento e baixo tempo de acesso. A solução desse dilema não está dependente de um simples componente de memória ou da tecnologia, mas do emprego de uma <b>hierarquia de memória</b>.
    <ol class="number">
        <li>Redução do custo/bit (↓)</li><p>
        <li>Aumento de capacidade (↑)</li><p>
        <li>Aumento do tempo de acesso (↑)</li><p>
        <li>Redução da frequência dos acessos à memória pelo processador (↓)</li><p>
    </ol><p>
    Para que um dado localizado na memória virtual possa ser utilizado no processamento é preciso que passe por cada nível da hierarquia. A razão principal é que o custo por bit de uma tecnologia de memória é geralmente proporcional à sua velocidade. Memórias rápidas, como SRAM, tendem a ter alto custo por bit, tornando proibitivamente caro construir a memória de um computador totalmente com esses dispositivos.<p> Na hierarquia, os níveis mais próximos ao processador, como a cache, contêm uma quantidade relativamente pequena de memória, que é implementada numa tecnologia de memória rápida, de modo a fornecer um baixo tempo de acesso. <i>O objetivo de uso da hierarquia de memória é manter os <b>dados que serão mais referenciados</b> por um programa nos <b>níveis superiores</b>, de modo que a maioria das solicitações à memória possa ser tratada no(s) nível(is) superior(es)</i>.<p> Por essa razão, o <b>nível mais alto</b> (cache) é geralmente implementado utilizando SRAM, com o emprego de blocos pequenos (normalmente entre 32 e 128 bytes) controlados por hardware. Já a <b>memória principal</b> é geralmente construída com DRAM, com o tamanho de blocos grandes (vários kilobytes) e controle pelo sistema operacional. E, finalmente, a <b>memória virtual</b> é usualmente implementada utilizando discos que contém todos os dados do sistema de memória. <p>Assim, quando uma solicitação de memória é enviada para a hierarquia, o <b>nível mais alto</b> é verificado para ver se contém o endereço. Se for assim, a solicitação é completada. Caso contrário, o <b>próximo nível mais baixo</b> é verificado, com o processo sendo repetido até que o dado seja encontrado ou o nível mais baixo da hierarquia seja atingido, <i>no qual se tem a garantia de que o dado está contido</i>. Com isso, um bloco de posições sequenciais contendo o endereço referido é copiado do primeiro nível que contém aquele endereço para todos os níveis acima dele. As razões para a utilização de blocos são:
    <ul>
        <li>Muitas tecnologias de armazenamento (DRAM modo paginado, discos rígidos) <i>permitem que várias palavras sequenciais de dados sejam lidas e escritas em menos tempo que um número igual de palavras localizadas aleatoriamente</i>, tornando mais rápido transferir um bloco de vários bytes de dados que buscar cada byte individualmente.</li><p>
        <li><i>A maioria dos programas apresenta localidade de referência</i>: as referências à memória que ocorrem próximas no tempo tendem a ter endereços que são próximos uns aos outros, fazendo com que seja provável que outros endereços dentro do bloco sejam referenciados em breve, após um primeiro acesso a um endereço no bloco.</li>
    </ul>
    </P>
<h1>Memória Principal de Semicondutores – Memória Cachê – Memórias Magnéticas e Memórias Ópticas</h1>
    <P>Um componente essencial de todo computador é sua memória. Sem memória não haveria computadores da maneira como atualmente os conhecemos. O fato de o computador armazenar dados consiste em manter um dado em certo local enquanto ele for necessário. O circuito lógico elementar capaz de armazenar um dado é a <b>célula de memória</b>, que é um dispositivo capaz de assumir <i>um dentre dois estados possíveis</i> e manter-se nesse estado <i>até que alguma ação externa venha a alterá-lo</i>. <p> As memórias que estudamos até agora podem ser lidas e escritas. Tais memórias são chamadas <b>RAMs</b> (o nome não é apropriado porque todas as pastilhas de memória são acessíveis randomicamente, mas o termo está bem oficializado). Mas as RAMs não são os únicos tipos de pastilhas de memória. Em muitas aplicações, como brinquedos, eletrodomésticos e carros, o programa e parte dos dados <i>precisam permanecer armazenados <b>mesmo quando a alimentação é desligada</b></i>. Além disso, uma vez instalados, nem o programa nem os dados serão modificados. Esses processos levaram ao desenvolvimento das <b>ROMs</b>, que não podem ser modificadas ou apagadas, intencionalmente ou não.
    </P>
<h2>1. Memória ROM (Ready Only Memory)</h2>
    <P>As ROMs são usadas para guardar instruções e dados que <b>não vão mudar durante o processo de operação do sistema</b> (volatilidade). Uma vez que as ROMs são não voláteis, os dados nelas armazenados não se perdem quando o equipamento é desligado. <p>Para alguns tipos de ROM, os dados que estão armazenados foram gravados durante o processo de fabricação da memória. Para outros tipos, os dados são gravados eletricamente. <i>O processo de gravação de dados é chamado de <b>programação, ou queima</b>, da ROM</i>. Algumas (as mais avançadas) podem apagar e regravar seus dados quantas vezes forem necessárias. <p> Os dados das ROMs são inseridos durante sua fabricação, essencialmente expondo um material fotossensível por meio de uma máscara contendo o padrão desejado de bits e então gravando a superfície exposta. Em princípio, <b>o único modo de trocar o programa em uma ROM é substituir a pastilha</b>. As ROMs são mais baratas que as RAMs quando pedidas em grandes quantidades para custear as despesas de fabricação de máscara. Entretanto, por princípio, elas são inflexíveis, porque não podem ser modificadas após a fabricação, e o tempo gasto entre o pedido e o reconhecimento das ROMs pode ser de muitas semanas. <p>Para facilitar às empresas o desenvolvimento de novos produtos baseados em ROM, foi inventada a <b>PROM</b>. Essa pastilha é como uma ROM, exceto que <i>ela pode ser programada uma única vez no campo, <b>reduzindo grandemente o tempo de retorno</b></i>. O próximo desenvolvimento nessa linha foi a <b>EPOM</b>, que <i>pode não apenas ser programada, como também apagada, no campo</i>. Quando a janela de quartzo de uma <b>EPROM</b> é exposta a uma luz ultravioleta forte de 15 minutos, todos os bits vão para 1.<p>Uma das principais aplicações da ROM é o armazenamento de alguns programas do sistema operacional dos microcomputadores, e também de informações em equipamentos controlados por microprocessadores, como caixas registradoras eletrônicas, sistemas de segurança industrial e diversos aparelhos eletrodomésticos.
    </P>
<h4>1.1. Tipos de Memória ROM</h4>
<h4>1.1.1. PROM (Programmable ROM)</h4>
    <P>Para aplicações mais modestas em termos de quantidades de chips a ser produzidos, a indústria desenvolveu as PROMs a fusível, <b>programáveis pelo usuário</b>, isto é, <i>elas não são programadas durante o processo de fabricação, e sim pelo usuário, de acordo com suas necessidades</i>. Porém, uma vez programada, a PROM torna-se uma <b>MROM</b>, ou seja, <i>não pode ser apagada e novamente programada</i>. O processo de programação de uma PROM com a consequente verificação dos dados gravados pode ser muito tedioso e demorado, se realizado manualmente. Existe no mercado um sem-número de dispositivos programadores de PROMs que permitem a entrada da programação por teclado, para então ser realizada a queima dos fusíveis e verificação dos dados gravados, sem a intervenção do usuário.
    </P>
<h4>1.1.2. EPROM (Erasable PROM)</h4>
    <P>Uma EPROM pode ser programada pelo usuário, podendo, além disso, ser <b>apagada e reprogramada quantas vezes forem necessárias</b>. Uma vez programada, a EPROM comporta-se como memória não volátil que reterá os dados nela armazenados indefinidamente. Uma vez que uma célula da EPROM tenha sido programada, <i>é possível apagá-la expondo-a à radiação ultravioleta, aplicada por meio da janela do chip</i>. Tal processo de apagamento requer uma exposição de 15 a 30 minutos aos raios ultravioletas. Uma vez apagada, a EPROM pode ser reprogramada.
    </P>
<h4>1.1.3. EEPROM (Electrically EPROM)</h4>
    <P>A EEPROM foi desenvolvida no início dos anos 1980, e apresentada ao mercado como um aperfeiçoamento da ideia da PROM. A maior vantagem da EEPROM sobre a EPROM é a <b>possibilidade de apagamento e reprogramação de palavras individuais</b>, em vez da memória toda. Além disso, uma EEPROM pode ser totalmente apagada em 10 minutos, no próprio circuito, contra mais ou menos 30 minutos para uma EPROM que deve ser retirada do circuito para submeter-se à ação da luz ultravioleta.
    </P>
<h4>1.1.4. EAROM (Electrically-Alterable PROM)</h4>
    <P>As memórias EAROM podem ser vistas como um tipo de EEPROM. Sua principal característica é o fato de que <b>os dados gravados podem ser alterados aos poucos</b>, razão pela qual esse tipo é geralmente utilizado em aplicações que exigem apenas <i>reescrita parcial de informações</i>.
    </P>
<h4>1.1.5. Flash</h4>
    <P>As memórias flash também podem ser vistas como um tipo de EEPROM, no entanto, o processo de gravação (e regravação) <b>é muito mais rápido</b>. Além disso, memórias flash são <b>mais duráveis e podem guardar um volume elevado de dados</b>.
    </P>
<h4>1.1.6. CD-ROM, DVD-ROM e afins</h4>
    <P>Essa é uma categoria de <b>discos ópticos</b> em que os dados são <i>gravados apenas uma vez</i>, seja de fábrica, como os CDs de músicas, ou com dados próprios do usuário, quando ele efetua a gravação. Há também uma categoria que pode ser <i>comparada ao tipo EEPROM</i>, pois <b>permite a regravação de dados</b>: CD-RW e DVD-RW e afins.
    </P>
<h2>2. Memória RAM (Random Access Memory)</h2>
    <P>O termo RAM é usado para designar uma <b>memória de acesso randômico</b>, ou seja, uma memória com <i>igual facilidade de acesso a todos os endereços, no qual o tempo de acesso a qualquer um deles é constante</i>. As RAMs são usadas em computadores para <b>armazenamento temporário</b> de programas e dados. A grande desvantagem reside no fato delas serem <b>voláteis</b>. Algumas <b>RAMs CMOS</b> têm a <b>capacidade de operar em standby</b>, consumindo muito pouca energia quando não estão sendo acessadas, além disso, algumas <i>podem ser alimentadas por baterias, mantendo seus dados armazenados na ocorrência de eventuais interrupções de energia</i>.
<h4>2.1. RAMs Estáticas e Dinâmicas</h4>
    <p>Há duas variedades de RAMs: estáticas e dinâmicas. As <b>RAMs estáticas</b> são construídas inteiramente usando <i>circuitos similares ao nosso <b>latch tipo d</b></i>. Essas memórias apresentam a <b>propriedade de ter seus conteúdos retidos enquanto a alimentação é mantida por segundos, minutos, horas ou mesmo dias</b>. <p>As <b>RAMs dinâmicas</b>, ao contrário, não usam circuitos do tipo latch. Em vez disso, uma RAM dinâmica é um <i><b>arranjo de pequenos capacitores</b>, cada um podendo ser carregado ou descarregado, o que permite armazenar 0 ou 1</i>. Como a carga elétrica tende a escoar-se, <b>cada bit na RAM dinâmica precisa ser refrescado por alguns poucos milissegundos para evitar que o dado escape</b>. Como uma lógica externa precisa tomar conta do refrescamento, as RAMs dinâmicas requerem um interfaceamento mais complexo que as estáticas. Entretanto, em muitas aplicações, essa desvantagem é compensada por suas maiores capacidades. Algumas RAMs dinâmicas possuem uma lógica de refrescamento embutida na pastilha, proporcionando tanto alta capacidade quanto interfaceamento simples.
    </P>
<h2>3. Tecnologias de Memórias</h2>
    <P>Várias tecnologias de memórias foram (e são) criadas com o passar do tempo. É graças a isso que, periodicamente, encontramos memórias mais rápidas, com maior capacidade e até memórias que exigem cada vez menos energia. Eis uma breve descrição dos principais tipos de memória RAM.
    </P>
<h4>3.1. FPM (Fast-Page Mode)</h4>
    <P>Uma das primeiras tecnologias de memória RAM. Com o FPM, <i>a primeira leitura da memória tem um tempo de acesso maior que as leituras seguintes</i>. Isso porque são feitos, na verdade, quatro operações de leitura seguidas, em vez de apenas uma, em um esquema do tipo x-y-y-y, por exemplo: 3-2-2-2 ou 6-3-3-3. <b>A primeira leitura acaba sendo mais demorada, mas as três seguintes são mais rápidas</b>. Isso porque o controlador de memória <i>trabalha apenas uma vez com o endereço de uma linha (<b>RAS</b>) e, em seguida, trabalha com uma sequência de quatro colunas (<b>CAS</b>)</i>, no lugar de trabalhar com um sinal de RAS e um de CAS para cada bit. Memórias FPM utilizavam <b>módulos SIMM</b>, tanto de 30 quanto de 72 vias.
    </P>
<h4>3.2. EDO (Extended Data Output)</h4>
    <P>A sucessora da tecnologia FPM é a EDO, que possui como destaque a <b>capacidade de permitir que um endereço da memória seja acessado ao mesmo tempo em que uma solicitação anterior ainda está em andamento</b>. Esse tipo foi aplicado principalmente em módulos SIMM, mas também chegou a ser encontrado em <b>módulos DIMM</b> de 168 vias. Houve também uma tecnologia semelhante, chamada BEDO (Burst EDO), que trabalhava mais rapidamente por ter tempo de acesso menor, mas quase não foi utilizada, pois tinha custo maior por ser de propriedade da empresa Micron. Além disso, foi "ofuscada" pela chegada da tecnologia SDRAM.
    </P>
<h4>3.3. SDRAM (Synchronous Dynamic Random Access Memory)</h4>
    <P>As memórias FPM e EDO são assíncronas, o que significa que não trabalham de forma sincronizada com o processador. O problema é que, com processadores cada vez mais rápidos, isso começou a se tornar um problema, pois muitas vezes o processador tinha que esperar demais para ter acesso aos dados da memória. As memórias SDRAM, por sua vez, <b>trabalham de forma sincronizada com o processador</b>, evitando os problemas de atraso. <i>A partir dessa tecnologia, passou-se a considerar a frequência com a qual a memória trabalha para medida de velocidade</i>. Surgiam então as memórias SDR SDRAM (Single Data Rate SDRAM), que podiam trabalhar com <b>66 MHz, 100 MHz e 133 MHz</b> (também chamadas de PC66, PC100 e PC133, respectivamente). Muitas pessoas se referem a essa memória apenas como "memórias SDRAM" ou, ainda, como "memórias DIMM", por causa de seu módulo. No entanto, a denominação <b>SDR</b> é a mais adequada.
    </P>
<h4>3.4. DDR SDRAM (Double Data Rate SDRAM)</h4>
    <P>As memórias DDR apresentam evolução significativa em relação ao padrão SDR, isso porque elas <b>são capazes de lidar com o dobro de dados em cada ciclo de clock</b> (memórias SDR trabalham apenas com uma operação por ciclo). Assim, uma memória DDR que trabalha à frequência de 100 MHz, por exemplo, acaba dobrando seu desempenho, como se trabalhasse à taxa de 200 MHz. Visualmente, é possível identificá-las facilmente em relação aos módulos SDR, porque este último contém duas divisões na parte inferior, onde estão seus contatos, enquanto as memórias DDR2 possuem apenas uma divisão.</P>
<h4>3.5. DDR2 SDRAM</h4>
    <P>Como o nome indica, as memórias DDR2 são uma evolução das memórias DDR. Sua principal característica é a <b>capacidade de trabalhar com quatro operações por ciclo de clock</b>, portanto, o dobro do padrão anterior. Os módulos DDR2 também contam com apenas uma divisão em sua parte inferior, no entanto, essa abertura é um pouco mais deslocada para o lado.
    </P>
<h4>3.6. DDR3 SDRAM</h4>
    <P>As memórias DDR3 são, obviamente, uma evolução das memórias DDR2. Novamente, aqui <b>se dobra a quantidade de operações por ciclo de clock, desta vez, de oito</b>. Uma novidade aqui é a possibilidade de uso de <b>Triple-Channel</b>.
    </P>
<h4>3.7. Rambus (Rambus DRAM)</h4>
    <P>As memórias Rambus recebem esse nome por ser uma criação da empresa Rambus Inc., e chegaram ao mercado com o apoio da Intel. Elas são diferentes do padrão SDRAM, pois <b>trabalham apenas com 16 bits por vez</b>. Em compensação, memórias Rambus trabalham com frequência de <b>400 MHz e com duas operações por ciclo de clock</b>. Tinham como desvantagens <i>taxas de latência muito altas, aquecimento elevado e maior custo</i>. Memórias Rambus nunca tiveram grande aceitação no mercado, mas também não foram um total fiasco: foram utilizadas, por exemplo, no console de jogos <i>Nintendo 64</i>. Curiosamente, as memórias Rambus trabalham em pares com "módulos vazios" ou "pentes cegos". Isso significa que, para cada módulo Rambus instalado, um "módulo vazio" tem que ser instalado em outro slot. Essa tecnologia acabou perdendo espaço para as memórias DDR.
    </P>
<h2>4. Módulos de Memória</h2>
    <P>Entendemos como módulo ou, ainda, pente, uma <b>pequena placa em que são instalados os encapsulamentos de memória</b>. Essa placa é acoplada na placa-mãe por meio de encaixes (slots) específicos para isso. Eis uma breve descrição dos tipos mais comuns de módulos:
    </P>
<h4>4.1. SIPP (Single In-Line Pins Package)</h4>
    <P>É um dos primeiros tipos de módulos que chegaram ao mercado. É formado por chips com <b>encapsulamento DIP</b>. Em geral, esses módulos <b>eram soldados na placa-mãe</b>.
    </P>
<h4>4.2. SIMM (Single In-Line Memory Module)</h4>
    <P>Módulos deste tipo <b>não eram soldados, mas encaixados na placa-mãe</b>. A primeira versão continha 30 terminais de contato (<b>SIMM de 30 vias</b>) e era formada por um conjunto de 8 chips (ou 9, para paridade). Com isso, podiam transferir <b>um byte por ciclo de clock</b>. Posteriormente, surgiu uma versão com 72 pinos (SIMM de 72 vias), portanto, maior e capaz de transferir <b>32 bits por vez</b>. Módulos SIMM de 30 vias podiam ser encontrados com capacidades que iam de <b>1 MB a 16 MB</b>. Módulos SIMM de 72 vias, por sua vez, eram comumente encontrados com capacidades que iam de <b>4 MB a 64 MB</b>.
    </P>
<h4>4.3. DIMM (Double In-Line Memory Module)</h4>
    <P>Os módulos DIMM levam esse nome por terem <b>terminais de contatos em ambos os lados do pente</b>. São capazes de transmitir <b>64 bits por vez</b>. A primeira versão – aplicada em memória SDR SDRAM – tinha 168 pinos. Em seguida, foram lançados módulos de 184 vias, utilizados em memórias DDR, e módulos de 240 vias, utilizados em módulos DDR2 e DDR3. Existe um padrão DIMM de tamanho reduzido chamado <b>SODIMM</b> (Small Outline DIMM), que é utilizado principalmente em computadores portáteis, como notebooks.
    </P>
<h4>4.4. RIMM (Rambus In-Line Memory Module)</h4>
    <P>Formado por 168 vias, esse módulo é utilizado pelas memórias Rambus. Um fato curioso é que <i>para cada pente de memória Rambus instalado no computador é necessário instalar um módulo "vazio", de 184 vias, chamado de C-RIMM (Continuity-RIMM)</i>.
    </P>
<h2>5. Memórias Cache</h2>
    <P>A memória cache surgiu quando se percebeu que as memórias <i>não eram mais capazes de acompanhar o processador em velocidade</i>, fazendo com que muitas vezes ele tivesse que ficar "esperando" os dados ser liberados pela memória RAM para poder concluir suas tarefas, perdendo muito em desempenho. Se na época do 386 a velocidade das memórias já era um fator limitante, imagine o quanto esse problema não atrapalharia o desempenho dos processadores que temos atualmente. <p><i>Para solucionar esse problema, começou a ser usada a memória cache, um tipo ultrarrápido de memória que serve para <b>armazenar os dados mais frequentemente usados pelo processador, evitando na maioria das vezes que ele tenha que recorrer à comparativamente lenta memória RAM</b></i>. Sem ela, <b>o desempenho do sistema ficaria limitado à velocidade da memória</b>, podendo cair até 95%!<p> São usados dois tipos de cache, chamados de cache primário, ou cache L1 (level 1), e cache secundário, ou cache L2 (level 2). <b>O cache primário é embutido no próprio processador e é rápido o bastante para acompanhá-lo em velocidade</b>. Sempre que um novo processador é desenvolvido, é preciso desenvolver também um tipo mais rápido de memória cache para acompanhá-lo. Como esse tipo de memória é <b>extremamente caro</b> (chega a ser algumas centenas de vezes mais cara que a memória RAM convencional), usamos apenas uma pequena quantidade dela. <b>Para complementar, usamos também um tipo um pouco mais lento de memória cache na forma do cache secundário</b>, que, por ser muito mais barato, permite que seja usada uma quantidade muito maior.
    </P>
<h2>6. Memória Magnética</h2>
    <P>O hard disk (HD) é um sistema de <b>armazenamento permanente de dados</b> destinado a manter arquivos e programas. Composto por <b>discos de armazenamento magnéticos</b>, é um dos recursos mais importantes e largamente utilizados em diversos tipos de computadores. Dentro do disco rígido, os dados são gravados em discos magnéticos, chamados de <b>platters</b>. Os platters são compostos de duas camadas. A primeira é chamada de <b>substrato</b> – um disco metálico feito de ligas de alumínio (recentemente, alguns fabricantes passaram a utilizar também vidro). A segunda camada é composta pela <b>superfície magnética nos dois lados do disco</b>. Como a camada magnética tem apenas alguns mícrons de espessura, ela é recoberta por uma fina camada protetora, que oferece algum isolamento contra pequenos impactos. Essa camada é importante, pois, apesar dos discos serem encapsulados em salas limpas, eles internamente contém ar, com pressão ambiente.<p> Os HDs mais antigos utilizavam motores de <b>3.600 rotações por minuto</b>, enquanto atualmente em PCs são utilizados motores de <b>5.400, 7.200 ou 10.000 RPM</b>. Embora não seja o único, a velocidade de rotação é sem dúvidas o fator que influencia diretamente no desempenho.<p> Para ler e gravar dados no disco, são usadas <b>cabeças de leitura eletromagnéticas (heads)</b> que são presas a um braço móvel, o que permite seu acesso a todo o disco. O <b>braço de leitura</b> é uma peça triangular, também feita de ligas de alumínio, para que seja ao mesmo tempo leve e resistente. O mecanismo que movimenta o braço de leitura é chamado de <b>atuador</b>. <p>Para que o HD possa posicionar a cabeça de leitura sobre a área exata referente à trilha que vai ser lida, existem <b>sinais de feedback gravados na superfícies do disco</b>, que orientam o posicionamento da cabeça de leitura. Eles são sinais magnéticos especiais, gravados durante a fabricação dos discos (a famosa <b>formatação física</b>), que são protegidos por meio de instruções de bloqueio incluídas no firmware do HD contra alteração posterior. Esses sinais eliminam os problemas de desalinhamento que existiam nos primeiros HDs.<p> Ao ler um arquivo, a controladora posiciona a cabeça de leitura sobre a trilha em que está o primeiro setor referente a ele e espera que o disco gire até o setor correto. Esse tempo inicial necessário para iniciar a leitura é chamado de <b>tempo de acesso</b>, e mesmo os HDs atuais de 7.200 RPM usam em torno de 12 milésimos de segundo, o que é uma eternidade em se tratando de tempo computacional. <p>O HD é relativamente rápido ao ler setores sequenciais, mas, ao ler <b>vários pequenos arquivos espalhados pelo HD</b>, o desempenho pode cair assustadoramente. É por isso que existem <b>programas desfragmentadores</b>, que procuram reorganizar a ordem dos arquivos, de forma que eles sejam gravados em <i>setores contínuos</i>. O disco rígido pode trazer impacto no desempenho de um computador. O fato é que o tempo perdido no movimento da cabeça de leitura, na rotação da mídia magnética, entre outros fatores, pode causar a perda de desempenho. Os <b>principais fatores que afetam o desempenho de um disco rígido</b> são:
    <ul>
        <li>velocidade de rotação do disco magnético;</li><p>
        <li>velocidade de deslocamento da cabeça de leitura;</li><p>
        <li>o tempo de busca (seek time): tempo para posicionar o cabeçote na trilha desejada;</li><p>
        <li>o atraso rotacional: tempo para posicionar o cabeçote no início do setor desejado;</li><p>
        <li>o tempo de acesso: tempo de busca + atraso rotacional;</li><p>
        <li>número de setores por trilhas;</li><p>
        <li>a taxa de transferência dos dados;</li><p>
        <li>como os dados estão organizados no disco; e</li><p>
        <li>interface usada (PATA/SATA/SCSI/SAS).</li><p>
    </ul>
    </P>
<h2>7. Memória Óptica</h2>
    <P>Os discos ópticos são tecnologias de armazenamento de dados cuja leitura/escrita é realizada por meio da <b>reflexão de raio laser</b>. Suas características principais são:
    <ul>
        <li>alta capacidade de armazenamento;</li><p>
        <li>o baixo custo por bit armazenado;</li><p>
        <li>durabilidade no armazenamento dos dados.</li>
    </ul><p>
    O <i>compact disc recordable</i> (CD-R) é um dos principais representantes dessa categoria, que funciona a partir de uma <b>superfície reflexível</b>. Variações microscópicas nessa superfície alteram a direção de reflexão do raio ou fazem com que ele não seja refletido, impedindo-o de atingir o sensor. Com isso, reproduz-se uma <b>sequência de estados com/sem luz no sensor</b>, que irá compor a <b>série de "0"s/"1"s do sinal digital</b>. Os discos ópticos podem ser do tipo:
    <ul>
        <li>Somente leitura;</li><p>
        <li>Gravável somente uma vez; e</li><p>
        <li>Regraváveis várias vezes.</li><p>
    </ul>
    </P>
<h2>8. Unidade de Estado Sólido (Solid-State Drive – SSD)</h2>
    <P>Unidade de estado sólido (em inglês: <i>solid-state drive</i>, ou SSD) é um tipo de dispositivo, sem partes móveis, para <b>armazenamento não volátil de dados digitais</b>. São, tipicamente, construídos em torno de um <b>circuito integrado semicondutor</b>, responsável por armazenamento, diferindo de sistemas magnéticos (como os HDDs e fitas LTO) ou óticos (discos como CDs e DVDs). Os dispositivos utilizam <b>memória flash</b> (tecnologia semelhante as utilizadas em cartões de memória e pendrives).<p>
    As taxas de leitura e escrita, na maioria dos modelos, gira em torno dos <b>500 MB/s</b>, <i>aproximadamente 10x a velocidade das taxas de leitura e escrita em um HDD</i>. Em sistemas de alto desempenho, a <b>alta velocidade no acesso é o mais importante</b>, além de reduzir bastante o tempo de boot, mas no caso de dispositivos de baixo consumo de energia, ou baixo custo, o critério da <b>redução do consumo de energia é o mais importante</b>. Para os padrões atuais de mercados e aplicações, os dispositivos SSD ainda tem um <b>custo/gigabyte elevado</b>, comparados aos dispositivos magnéticos. Para resolver este problema, parte das máquinas mais modernas, hoje em dia, conta com <i>um SSD onde é instalado o sistema operacional e programas e um HDD onde são gravados os arquivos de uso e backup</i>. Dessa maneira, os micros podem chegar a ter tempo de boot e abertura de programa até 5x menor do que nas máquinas onde só se usa HD magnéticos.<p>
    A maioria dos fabricantes utilizam SSD de memória flash não volátil para criar dispositivos mais robustos e compactos para o mercado consumidor. Estes SSDs baseados em memória flash são também conhecidos como <b>flash drives</b>. Eles são frequentemente embalados na unidade de disco padrão (1,8 polegadas, 2,5 polegadas, e 3,5 polegadas). <i>SSDs são mais lentos que as DRAM (uma DDR4 SDRAM chega a 25600MB/s) mas alguns modelos chegam a ser até 6X mais rápidos do que o tradicional HDDs em arquivos grandes</i>. Flash SSDs não têm partes móveis e, portanto, procuras e outros atrasos inerentes de discos rígidos, DVDs e Blu-Rays não se aplicam a eles.
    </P>
    <table>
        <tbody>
            <tr>
                <th>Atributo ou Característica</th>
                <th>SSD</th>
                <th>HDD</th>
            </tr>
            <tr>
                <td>Tempo de acesso randômico</td>
                <td>Extremamente baixo, cerca de 0.1 a 0.3 ms pois a memória é sólida.</td>
                <td>Lento, de 5 a 10 ms, precisa mover o leitor até a trilha que contém as informações que deseja-se ler.</td>
            </tr>
            <tr>
                <td>Latência de leitura</td>
                <td>Baixa pois a leitura é direta de qualquer local da memória, o que resulta em menor tempo de boot do sistema e inicialização de aplicativos.</td>
                <td>Alta pois requer o tempo de posicionamento do leitor no local correto.
                </td>
            </tr>
            <tr>
                <td>Desfragmentação</td>
                <td>Não traz grandes benefícios pois a leitura de qualquer local da memória é rápida, gasta ciclos de escrita que são limitados.</td>
                <td>Requer desfragmentação contínua para ter melhor rendimento, pois a leitura de arquivos fragmentados é muito lenta.
                </td>
            </tr>
            <tr>
                <td>Ruído</td>
                <td>Não produz ruído durante o funcionamento.</td>
                <td>As partes que se movimentam durante o funcionamento produzem ruído, em alguns modelos este ruído é perceptível.</td>
            </tr>
            <tr>
                <td>Fatores Externos</td>
                <td>Não é sensível a choque, altitude, vibração, magnetismo.</td>
                <td>Sensível a choque, altitude, vibração e magnetismo (o último pode danificar arquivos).</td>
            </tr>
            <tr>
                <td>Custos</td>
                <td>O preço por GB de espaço é alto, já o consumo de energia é bastante baixo.</td>
                <td>Preço por GB de espaço é baixo, consumo de energia alto.
                </td>
            </tr>
            <tr>
                <td>Capacidade</td>
                <td>A grande maioria dos SSDs comercializados são de 60 GB a 1 TB; existem exemplares com 3 TB de espaço ou mais mas são extremamente caros.</td>
                <td>Capacidade alta é comum, exemplares com 4 TB são comercializados a preços acessíveis.
                </td>
            </tr>
            <tr>
                <td>Longevidade</td>
                <td>Apesar de serem menos suscetíveis a falhas, os SSDs possuem limitação de ciclos de escrita (em geral de 1 a 5 milhões de ciclos dependendo da tecnologia).</td>
                <td>São mais suscetíveis a defeitos mecânicos pois possuem partes móveis, no entanto não possuem limites de escrita, pois o funcionamento de gravação baseia-se em propriedades magnéticas.</td>
            </tr>
        </tbody>
    </table>
<h1>Sistema de entrada e saída (E/S)- Módulos de E/S; tipos de operações de E/S</h1>
<h2>1. Entrada e Saída</h2>
    <P>Outro componente muito importante dentro do sistema computacional é o conjunto de módulos de entrada e saída. Esses módulos estão conectados com o barramento do sistema e são as interfaces com o mundo externo. <b>Sua função principal é permitir a comunicação entre o periférico que ele controla e o barramento</b>. Existem algumas <i>razões para não ligarmos os periféricos diretamente ao barramento do sistema</i>, dentre elas estão:
    <ol>
        <li><b>grande variedade de periféricos</b>. Cada um tem sua lógica de operação e, portanto, seria muito difícil dar a um único componente, como o processador, a missão de controlar cada um deles.</li><p>
        <li>outro problema é o fato dos dispositivos externos apresentarem uma <b>taxa de transferência de dados muito menor</b> que aquela estabelecida entre CPU e MEM. Logo, seria inadequado usar o barramento do sistema para fazer uma comunicação direta entre CPU e periféricos.</li><p>
        <li>o <b>formato dos dados e o tamanho das palavras</b> usados pelos periféricos são diferentes dos utilizados pelo computador.</li>
    </ol><p>
    Portanto, cabe ao módulo de E/S fornecer uma interface com o processador e memória via barramento do sistema por meio de conexões de dados adequadas.
    </P>
<h4>1.1. Classificações de Periféricos</h4>
    <P>Existem diversos tipos de dispositivos externos, e eles <i>podem ser classificados</i> em:
    <ol class=number>
        <li>voltados para a <b>comunicação com o usuário</b>: teclado, vídeo, impressora etc.</li><p>
        <li>voltados para a <b>comunicação com a máquina</b>: discos magnéticos, sensores etc.</li><p>
        <li>voltados para a <b>comunicação com dispositivos remotos</b>: modem, placa de rede.</li>
    </ol>
    </P>    
<h4>1.2. Funções Básicas do Módulo E/S</h4>
        <img src=m%C3%B3duloES.jpg alt="módulo E/S" class=center>
    <P>
    Conforme podemos observar na Figura 1, os dispositivos externos (periféricos) são conectados ao computador por meio de um módulo de E/S que oferece um meio para a troca de dados entre o mundo e o computador. A conexão estabelecida por intermédio do módulo de E/S é usada para: a) <b>transferência de dados</b>, b) <b>informações de controle</b> e c) <b>estado dos periféricos ou da operação</b>.<p>
        <img src=m%C3%B3duloES1.jpg alt="módulo E/S 1" class=center style=width:520px><p>
    Os <b>sinais de controle</b> indicam o tipo da operação (<i>leitura ou escrita</i>) ou <i>alguma operação de controle</i>, como movimentar a cabeça do disco para uma determinada posição. Os <b>dados</b> são bits a serem enviados ou recebidos do módulo de E/S. Já os <b>sinais de estado</b> indicam o estado propriamente dito do dispositivo, como: <i>ready/not-ready</i>. O <b>buffer</b> é uma <i>área de armazenamento temporário</i>, e o <b>transdutor</b> é o responsável por <i>converter dados codificados como sinais elétricos para alguma outra forma de energia</i>.
    </P>
<h4>1.3. Funções Principais do Módulo E/S</h4>
    <P>Após essa introdução, podemos listar as funções mais importantes de um módulo de E/S, que são:
    <ul>
        <li><b>controle</b> e temporização;</li><p>
        <li>comunicação com o <b>processador</b>;</li><p>
        <li>comunicação com <b>dispositivos</b>;</li><p>
        <li><b>armazenamento temporário</b> de dados; e</li><p>
        <li><b>detecção de erros</b>.</li>
    </ul><p>
    As <b>funções de controle</b> e temporização são importantes, pois recursos como barramento e memória são compartilhados para a realização de várias atividades, entre elas E/S de dados. Portanto, é necessário incluir funções de controle e temporização para <i>controlar o fluxo de dados entre o sistema computacional e o meio externo</i>. Na comunicação do dispositivo com o <b>processador</b>, as seguintes etapas estão envolvidas:
    <ul>
        <li>o módulo de E/S é <i>questionado</i> sobre seu <b>estado: ok/not-ok</b>;</li><p>
        <li>o <i>resultado da pergunta</i> é retornado ao processador;</li><p>
        <li><i>se o dispositivo estiver ok</i>, o processador <b>solicita a transferência dos dados</b> enviando um comando para o módulo de E/S;</li><p>
        <li>uma <i>unidade de dados</i> é obtida pela <b>controladora do dispositivo</b>; e</li><p>
        <li>os dados são transferidos para o <b>processador</b>.</li>
    </ul><p>
    Cada interação entre processador e módulo de E/S envolve uma ou mais arbitração do barramento. A <b>detecção de erros</b> é responsável por informar ao processador sobre o <i>mau funcionamento do dispositivo (mecânico ou elétrico)</i>, por exemplo: uma falha em uma trilha do disco ou a falta de papel na impressora.
    </P>
<h2>2. Estrutura do Módulo de E/S</h2>
    <P>A quantidade de dispositivos que um módulo consegue controlar e a complexidade dele podem variar significativamente. Conforme podemos ver na Figura 3, os dados transferidos entre o módulo e o computador são <i>armazenados temporariamente</i> em <b>registradores de dados</b>. Além disso, existem <b>registradores de estado</b> para informar o estado atual do dispositivo. <i>Cada um dos módulos de E/S possui um <b>endereço distinto</b> para ser referenciado pelo processador</i>. Dessa forma, o intuito do módulo de E/S é dar ao processador uma visão simplificada da grande variedade de periféricos.<p>
        <img src=m%C3%B3duloES2.jpg alt="módulo E/S 2" class=center style=width:520px></P>
<h2>2.1. Tipos de Comandos Operacionais de E/S</h2>
    <P>
    Ao executar uma operação de E/S em um programa, o <b>processador</b> envia um <i>comando (instrução ou operação)</i> para o <b>módulo de E/S apropriado</b>, solicitando uma operação específica. Para que uma instrução de E/S seja executada, o processador <b>gera um endereço</b> (dizendo qual é o módulo de E/S solicitado) e <b>transmite via barramento esse endereço</b> com a operação requerida. Os tipos de comandos de E/S são:
    <ul>
        <li><b>controle</b>: <i>ativa um periférico e indica uma ação</i>, por exemplo: eject/dev/cdrom (Linux).</li><p>
        <li><b>teste</b>: verifica as <i>condições de estado</i> do dispositivo associado ao módulo de E/S, por exemplo: ready ou not-ready.</li><p>
        <li><b>leitura</b>: solicita a leitura de <i>itens de dados do periférico</i>. O módulo de E/S os <b>armazena no registrador de dados interno</b> até que o processador solicite a transferência deles para o barramento de dados.</li><p>
        <li><b>gravação</b>: CPU ordena ao módulo de E/S que pegue o dado do barramento de dados e o <b>armazene no periférico</b>.</li>
    </ul>
    </P>
<h2>2.2. Tipos de Técnicas Operacionais de E/S</h2>
    <P>
    Existem três técnicas diferentes que podem ser utilizadas durante a realização de operações de E/S, são elas: a) <b>E/S programada</b>, b) <b>E/S dirigida por interrupção</b> e c) <b>acesso direto à memória (DMA)</b>. A Figura 4 ilustra o esquema de funcionamento de cada uma dessas técnicas.<p>
        <img src=m%C3%B3duloES3.jpg alt="módulo E/S 3" class=center style=width:520px>
    </P>
<h4>2.1. E/S Programada</h4>
    <P>Neste modo de comunicação, o processador, além de executar o programa, possui <b>controle total sobre as operações de E/S</b>. Esse controle inclui a) a detecção do<b> estado do dispositivo</b>, b) o envio de <b>comandos</b> para o módulo de E/S (leitura ou escrita) e a c) <b>transferência de dados</b>. <p>Por isso, toda vez que o programa em execução realiza alguma operação de I/O, <i>o processador tem que interromper sua execução para tratar da operação solicitada</i>. Com isso, <b>a execução do programa fica interrompida até que a operação seja finalizada</b>. Nesse intervalo, o CPU fica testando o estado do módulo de E/S. Como podemos imaginar, ocorrerá um <i>desperdício de processamento, pois o processador é muito mais rápido que o módulo de E/S</i>. A <b>transferência dos dados</b> acontece entre o módulo de E/S e o processador.
    </P>
<h4>2.2. E/S Dirigida Por Interrupção</h4>
    <P>Neste modo de comunicação, o processador <b>não fica esperando que a operação de I/O seja finalizada para continuar a execução do programa</b>, como acontecia no caso da E/S programada. Em vez disso, ele <i>simplesmente emite um sinal para a <b>controladora (módulo de I/O)</b> com a operação solicitada e continua executando outras instruções do programa</i>. Quando a controladora estiver pronta para trocar informações com a CPU, ela envia um <b>sinal de interrupção</b> avisando seu estado de "pronto". <i>Após esse sinal, o processador realiza a transferência dos dados</i>, como acontecia no modo anterior. Para a CPU, a execução acontece do seguinte modo:
    <ul>
        <li><b>processador</b> envia um sinal de leitura para o módulo de E/S <i>e continua com a execução do programa</i>.</li><p>
        <li>sempre <i>ao final de cada ciclo de execução</i>, o processador verifica se existe algum <b>sinal de interrupção</b> de um módulo de E/S pendente. Se existir, o <i>contexto do programa é salvo e a interrupção é processada</i>, fazendo a leitura dos dados da controladora e armazenando-os na <b>memória</b>.</li><p>
        <li><b>é recuperado o contexto do programa e é continuada sua execução normal</b>.</li>
    </ul><p>
    Devemos ressaltar que tanto na E/S programada quanto na dirigida por interrupção, <b>o processador sempre é o responsável por obter dados da memória principal</b> (<i>operação de saída</i> memória ? dispositivo) ou por <b>armazenar dados na memória principal</b> (<i>operação de entrada</i> dispositivo ? memória).
    </P>
<h4>2.2.1. Interrupções</h4>
    <P>A todo sinal sinal ou evento capaz de <i>interromper a sequência normal de execução de instruções</i> damos o nome de interrupção. Os tipos mais comuns de interrupções estão listados a seguir:
    <ul>
        <li><b>interrupção de software</b>: ocasionada por alguma condição resultante da execução de uma instrução, por exemplo um overflow ou uma divisão por zero.</li><p>
        <li><b>interrupção de relógio</b>: gerada pelo clock do processador, destinada a executar <i>operações periódicas</i>.</li><p>
        <li><b>interrupção de E/S</b>: ocasionada por um <b>controlador de E/S</b> para indicar a conclusão de uma operação ou a ocorrência de erros.</li><p>
        <li><b>interrupção de falha de hardware</b>: provocada por falha do hardware, como um erro de paridade em memória ou a queda de energia.</li>
    </ul><p>
        <img src=m%C3%B3duloES4.jpg alt="módulo E/S 4" class=center style=width:520px><p>
    O principal objetivo das interrupções é melhorar o desempenho da CPU ex.: leitura de dado em disco).
    </P>
<h4>2.3. DMA – Acesso Direto à Memória</h4>
    <P>Esta técnica é uma opção mais interessante de realizar as operações de E/S, pois <b>a transferência de dados entre o módulo de E/S e a memória principal é feita diretamente sem a necessidade de envolver o processador</b>. Dentre as principais <i>desvantagens</i> dos métodos anteriores, podemos citar:
    <ul>
        <li><b>a taxa de transferência de E/S é limitada</b> pela velocidade com que o processador pode servir um dispositivo.</li><p>
        <li><b>o processador tem que se ocupar em gerenciar a transferência dos dados</b>.</li><p>
    </ul><p>
    Para evitar esses problemas, desenvolveu-se um <b>módulo adicional</b> que está conectado ao barramento do sistema. Esse módulo é chamado de <b>DMA</b>. Esse controlador <b>é capaz de imitar o processador e transferir dados diretamente de e para a memória por meio do barramento do sistema</b>. Assim, podemos verificar que esse módulo pode disputar o uso do barramento com a CPU.<p>
        <img src=m%C3%B3duloES5.jpg alt="módulo E/S 5" class=center style=width:520px>
    </P>
<h4>2.3.1. Operação da DMA com a CPU</h4>
    <P>As informações trocadas entre o <b>DMA e a CPU</b> quando esta deseja ler ou escrever um conjunto de dados em um periférico podem ser descritas como segue:
    <ul>
        <li>por meio do <b>barramento de controle</b> a CPU indica o <i>tipo de operação</i> ao DMA.</li><p>
        <li>nas <b>linhas de dados</b> é passado o <i>endereço do módulo de E/S</i> correspondente.</li><p>
        <li>o <i>endereço de memória</i> para o DMA armazenar ou ler informações também é passado por meio das <b>linhas de dados</b>.</li><p>
        <li>a <i>quantidade de palavras que serão lidas ou escritas</i> também vai pela <b>linha de dados</b>.</li>
    </ul><p>
    Portanto, <b>o gerenciamento da operação de I/O fica a cargo do DMA</b>. Suponha que um programa solicite uma <i>leitura de um arquivo em disco</i>. O DMA será o responsável por <b>controlar a operação e armazenar os dados lidos do disco direto na memória principal</b>, no endereço transmitido pela CPU durante a solicitação. <i>Ao finalizar a transferência, o DMA emite um sinal de interrupção ao processador</i>, indicando o término da operação. Nesse instante, o processador busca os dados direto na memória, <b>poupando tempo de acesso à controladora do disco</b> e, consequentemente, melhorando o desempenho do sistema computacional. Dessa forma, <b>o processador só se envolve no início e no fim da operação</b>. 
    </P>
<h1>Estrutura da CPU - Organização de registradores - Ciclo de instrução</h1>
    <P>O processador (CPU) é o componente vital de um sistema de computação, responsável pela realização das <b>operações de processamento</b> (cálculos matemáticos, entre outros) e de <b>controle</b> durante a execução de um programa. <p>Um programa, para ser efetivamente executado por um processador, deve ser constituído por uma <b><i>série</i> de instruções</b> (em linguagem de máquina). Essas instruções devem estar armazenadas em <b>posições sucessivas</b> da memória principal. A execução é <i>sequencial</i>, ou seja, se a instrução executada está na <b>posição x</b>, a próxima instrução a ser executada deverá estar na <b>posição x + 1</b>. A <b>sequência de funcionamento</b> de uma CPU é conhecida como <i>ciclo "busca – decodificação – execução" de instruções</i>, e a figura 1 ilustra esse ciclo.
    <p>
        <img src=instru%C3%A7%C3%A3o.jpg alt="instrução" class=center>
    <ul>
        <li>Um elemento dentro do processador denominado <b>contador de instruções</b> (<i>PC – program counter</i>) contém a <b>posição da próxima instrução</b> a ser executada. Quando uma sequência de execução de instruções tem início, a instrução cujo endereço está no <i>contador de instruções</i> é trazida da memória para uma área chamada <b>registrador de instruções (RI)</b>. Esse processo é conhecido como <b>busca da instrução</b>.</li><p>
        <li>A instrução é interpretada por <b>circuitos de decodificação</b>, que fazem com que <b>sinais eletrônicos</b> sejam gerados no processador como <i>resultado do valor do campo de operação</i>, isto é, decodificam a <b>informação</b> correspondente à <b>operação</b> a ser realizada.</li><p>
        <li>Esses <i>sinais resultam na execução da instrução</i>, isto é, ocorre a <i>aplicação da função contida pela operação</i> sobre os <b>operandos</b>. Quando a execução de uma instrução é terminada, <i>o contador de instruções é atualizado para o endereço da memória da próxima instrução (x + 1)</i>.</li>
    </ul>
    <p>
    A <b>sequência de instruções pode mudar</b> como resultado de uma instrução que direciona um <b>desvio</b> (também chamado de <i>salto, jump</i>). Instruções desse tipo contêm, no campo operandos, o endereço da próxima instrução a ser executada. Elas causam mudanças no fluxo do programa como resultado das <b><i>condições</i> dos dados</b>. O <i>desvio condicional</i> representado por uma <b>instrução de alto nível IF</b> traduz-se em algum tipo de <b>instrução de desvio</b>. 
    <p>As atividades realizadas pela CPU podem ser divididas em duas grandes categorias funcionais:
    <ul>
        <li>funções de <b>processamento</b>;</li><p>
        <li>funções de <b>controle</b>.</li><p>
    </ul><p>
    A função de <b>processamento</b> se encarrega de realizar as atividades relacionadas com a <i>efetiva execução de uma operação</i>, ou seja, processar instruções (executar a instrução). O principal componente da CPU que realiza a função de processamento é a <b>ULA (unidade lógica e aritmética)</b>, e a ação dela é complementada pelo uso de registradores de processamento. <p>A função de <b>controle</b> é exercida pelos componentes da CPU que se encarregam de <i>atividades de busca, interpretação e controle da execução das instruções, bem como do controle da ação dos demais componentes do sistema de computação (memória, entrada/saída)</i>. O principal componente da CPU responsável pela função de controle é a <b>UC (unidade de controle)</b>.
        </P>
<h2>1. Componentes</h2>
    <P>As funções de <i>controle e processamento</i> necessitam de componentes, constituídos de <b>circuitos digitais</b>, para sua realização. Esses componentes <b>são interligados interna e externamente por meio de barramentos</b>. A figura no link a seguir ilustra os principais componentes de um processador atual:<p>
        <img src=instru%C3%A7%C3%A3o1.png alt="ïnstrução1" class=center style=width:520px><p>
    <ul>
        <li><b>UAL</b>: unidade lógica e aritmética (ULA), responsável por efetuar <b>operações matemáticas</b> com os dados. Essas operações podem ser, por exemplo, <i>soma, subtração, multiplicação, divisão, operações lógicas AND, OR, XOR, NOT, deslocamento de bits à direita e esquerda, incremento e decremento, comparações</i>;</li><p>
        <li><b>ACC</b>: são registrador(es) <b>auxiliar(es)</b> <i>sobre o(s) qual(is) a ULA realiza suas operações</i>. Quando é único, todas as instruções o utilizam como <i>fonte e destino</i>.</li><p>
        <li><b>CI (PC)</b>: contador de instruções (<i>program counter</i>). Registrador cuja função específica é <i>armazenar o endereço da próxima instrução a ser executada</i>.</li><p>
        <li><b>RDM</b>: <i>registrador de dados da memória</i>.</li><p>
        <li><b>REM</b>: <i>registrador de endereços da memória</i>.</li><p>
        <li><b>MP</b>: memória principal. Local onde ficam <i>dados e instruções já/a serem executadas</i>.</li><p>
        <li><b>RI</b>: registrador de instruções: tem a função específica de <b>armazenar a instrução</b> a ser executada.</li><p>
        <li><b>Relógio</b>: é o dispositivo <i>gerador de pulsos</i>. A quantidade de vezes em que esse pulso básico se repete define a unidade de medida do relógio chamado frequência, usada também para definir <b>velocidade na CPU</b>.</li><p>
        <li><b>UC</b>: unidade de controle. É o dispositivo <i>mais complexo</i> da CPU, pois, além de <b>controlar a ação da ULA</b>, possui a lógica necessária para realizar a <i>movimentação de dados e instruções de e para a CPU</i>, por meio de <b>sinais de controle</b> emitidos em instantes de tempo programados. Os sinais de controle ocorrem em vários instantes durante o período de realização do ciclo de instruções.</li><p>
        <li><b>Decodificador de instruções</b>: é um dispositivo utilizado para <i>identificar as operações a serem realizadas relacionadas à instrução a ser executada</i>.</li><p>
        <li><b>Barramentos</b>: utilizados para a <i>comunicação entre os dispositivos</i>, são de três tipos específicos: <b>dados, endereços e controle</b>.</li><p>
    </ul></P>
<h2>2. Função de Processamento</h2>
    <P>Processar o dado é <b>executar</b> com ele uma <i>ação que produza algum tipo de resultado</i>. Essa é, pois, a atividade-fim do sistema computacional: ele existe para processar dados. Entre as <b>tarefas comuns</b> a essa função, podem ser citadas as que realizam:
    <ul>
        <li><b>Operações aritméticas</b>: somar, subtrair, multiplicar, dividir...</li><p>
        <li><b>Operações lógicas</b>: and, or, xor, not...</li><p>
        <li><b>Movimentação de dados</b>: memória-CPU, CPU-memória, registrador-registrador...</li><p>
        <li><b>Desvios</b>: alteração da sequência de execução das instruções</li><p>
        <li><b>Operações de entrada ou saída</b></li>
    </ul>
    </P>
<h4>2.1. ULA</h4>
    <P>O principal dispositivo da CPU para a realização das atividades de processamento é a ULA. Ela utiliza os registradores de propósitos gerais (ACC) como auxiliares à função de processamento. A ULA (UAL) é um aglomerado de circuitos lógicos e componentes eletrônicos simples que, integrados, realizam as funções acima citadas. Ela pode ser uma pequena parte da pastilha do processador, usada em pequenos sistemas, ou pode compreender um considerável conjunto de componentes lógicos, ocupando mais espaço na pastilha do processador. 
<h4>2.1.1. Tamanho da Palavra</h4>
    <p>A capacidade de processamento de uma CPU é em grande parte determinada pelas facilidades embutidas no hardware da ULA1 para realizar as operações matemáticas projetadas. Um dos elementos fundamentais é a definição do <b>tamanho da palavra</b>. O valor escolhido no projeto de fabricação da CPU irá determinar o tamanho dos elementos ligados à área de processamento (ULA, barramentos internos e registradores). Um tamanho maior ou menor de palavra acarreta, sem dúvida, diferenças fundamentais no desempenho da CPU, e, por conseguinte, do sistema como um todo. <p>Os seguintes componentes possuem influência direta do tamanho da palavra:
    <ul>
        <li>Influência no desempenho por causa de <b>maior ou menor</b> <i>tempo de execução</i> com operações matemáticas na ULA.</li><p>
        <li>Influência no desempenho por causa do <b>tamanho</b> escolhido para o <i>barramento interno e externo</i> da CPU.</li><p>
        <li>Em geral, obtém-se o <b>máximo de desempenho</b> quando a <i>largura (tamanho em bits) do barramento de dados é, no mínimo, igual ao tamanho da palavra (barramento interno)</i>.</li>
    </ul><p>
    O tamanho da palavra tem influência também na implementação física do acesso à <b>memória</b>. Embora atualmente a capacidade das memórias seja medida por bytes (ou conjunto de), <i>o movimento de dados entre CPU e memória é normalmente medido em palavras (barramento externo)</i>.
    </P>
<h2>3. Função de Controle</h2>
    <P>A área de controle de uma CPU é a parte funcional que realiza as atividades de (uma de cada vez, geralmente):
    <ol class="number">
        <li><b>Busca da instrução</b> que será executada, armazenando-a em um <b>registrador (RI)</b> especialmente projetado para essa atividade.</li><p>
        <li><b>Interpretação das ações</b> a serem desencadeadas com a execução da instrução (se é uma soma ou subtração, por exemplo, e como realizá-las).</li><p>
        <li><b>Geração de sinais de controle</b> apropriados para realização das atividades requeridas para a execução propriamente dita da instrução identificada. Esses sinais de controle são enviados aos diversos componentes do sistema, sejam internos da CPU (como ULA) ou externos (como a memória).</li>
    </ol><p>
    A área destinada à função de controle é projetada para <b>entender o que fazer, como fazer e comandar quem vai</b> fazer no momento adequado. Uma analogia pode ser feita com os seres humanos, imaginando que a área de <i>controle é o cérebro</i> que comanda o ato de andar, enquanto a área de <i>processamento são os músculos e ossos</i> das pessoas que realizam efetivamente o ato. Os <i>nervos podem ser relacionados com os barramentos</i> entre os diversos elementos envolvidos. <p>Os dispositivos básicos que fazem parte da área de controle são:
    <ul>
        <li>Unidade de controle (<b>UC</b>).</li><p>
        <li><b>Decodificador</b> de instruções.</li><p>
        <li><b>Registrador</b> de instruções (RI).</li><p>
        <li><b>Contador</b> de instruções (program counter – PC).</li><p>
        <li>Relógio ou <b>clock</b>.</li><p>
        <li>Registrador de <b>endereços</b> da memória (REM).</li><p>
        <li>Registrador de <b>dados</b> da memória (RDM).</li><p>
    </ul>
    </P>
<h4>3.1. UC</h4>
    <P>
    O componente vital para as funções de controle é a <b>Unidade de Controle (UC)</b>. Ela recebe como <b>entrada</b> <i>o valor</i> do <b>registrador de instruções</b> e <i>decodifica-o</i> (por meio do <b>decodificador de instruções</b>). <i>Para cada código de instruções, ele gera uma sequência de sinais diferentes</i>, <b>ativando os circuitos</b> correspondentes para cada uma das tarefas necessárias para a busca e execução da instrução. Cada <b>sinal de controle</b> comanda uma <i>microinstrução</i> (que denota uma tarefa a ser executada para uma operação). Uma microinstrução pode ser responsável pela realização de uma <i>carga em um registrador, uma seleção de um dado para entrada em um determinado componente, uma ativação da memória, a seleção de uma operação da ULA ou a habilitação de um circuito lógico</i>, para citar alguns exemplos.<p> Existem várias formas de implementações (organizações) das unidades de controle. As duas usuais são:
    <ul>
        <li><b>Organização convencional</b>: a unidade de controle é composta por itens digitais como <i>flip-flops, contadores e decodificadores</i>, que geram, sequencialmente e nos instantes de tempo adequados, todos os <i>sinais de controle</i> necessários à ativação da unidade operacional.</li><p>
        <li><b>Organização microprogramada</b>: em uma unidade de controle <b>microprogramada</b>, os sinais de controle estão armazenados numa memória especial chamada <b>memória de controle</b>. Vários <i>sinais de controle</i> são buscados a cada acesso à memória de controle.</li>
    </ul><p>
    </P>
<h2>4. Barramentos Internos</h2>
    <P>Os barramentos internos <i>interligam os componentes do processador para troca de sinais e valores</i>. Assim como no caso da comunicação processador/memória, são três os barramentos internos:
    <ul>
        <li>Barramento Interno de <b>Dados</b>: usado na <i>transferência de dados entre os registradores e entre os registradores e a ULA</i>. <b>A sua largura define o tamanho da palavra da máquina</b>.</li><p>
        <li>Barramento Interno de <b>Endereços</b>: permite a <i>transferência de endereços entre os registradores</i>.</li><p>
        <li>Barramento Interno de <b>Controle</b>: transmite os sinais do bloco de controle que <i>comandam o funcionamento de cada circuito do processador</i>.</li>
    </ul>
    </P>
<h2>5. Ciclo de Instrução</h2>
    <P><b>Busca, decodificação e execução de instruções</b> são tarefas básicas realizadas por um processador. Caracterizam um ciclo, pois as tarefas são executadas repetidamente, sempre e sempre, até que seja decodificada uma instrução que indique parada ao computador. <p>O fluxograma do ciclo de instrução anteriormente mostrado ilustra isso de forma simplificada. Um dos pontos omitidos é o <b>incremento do PC</b>, função indispensável ao funcionamento de qualquer sistema de computação. Outro ponto também apresentado de forma resumida são os <b>acessos à memória</b>. <i>Tanto as instruções como os dados ficam armazenados na memória e, portanto, existem buscas de operandos na memória e cálculo do endereço da próxima instrução a ser executada</i>. A Figura 2 ilustra mais alguns detalhes do ciclo de instrução.<p>
        <img src=instru%C3%A7%C3%A3o2.jpg alt="instrução2" class=center style=width:520px><p>
    Esse ciclo de instrução pode ser descrito em <b>LTR (linguagem de transferência entre registradores)</b>, de modo que consigamos acompanhar sua realização com a movimentação de informações entre os componentes da CPU. O <b>algoritmo</b> a seguir ilustra esse funcionamento:
        <p>
        <img src=instru%C3%A7%C3%A3o3.jpg alt="instrução3" class=center style=width:520px><p>
    Inicialmente, o conteúdo de memória no endereço da próxima instrução a ser executada (<b>PC</b>) tem seu valor transferido para <b>RI</b>. Logo após, o valor de PC é <i>incrementado para o endereço da próxima instrução a ser executada</i>. O <b>decodificador</b> de instruções irá receber os bits referentes ao <b>Código da Operação</b> e decodificá-lo, dando entrada na <b>UC</b> desse valor. A UC gera os <i>sinais</i> necessários para a execução da instrução. <p>Detalhando ainda mais, pode-se elencar uma série de passos a serem realizados em cada parte do ciclo. São eles:<p>
    a) <b>Busca</b>
    <ul>
        <li><i>Copiar</i> o <b>PC</b> para o registrador de endereços da memória (<b>REM</b>)</li><p>
        <li><i>Ler</i> uma instrução da memória</li><p>
        <li><i>Copiar</i> o registrador de dados da memória (<b>RDM</b>) para o registrador de instruções (<b>RI</b>)</li><p>
        <li><i>Atualizar</i> o contador de programa (<b>PC</b>)</li><p>
    </ul><p>
    b) <b>Decodificação</b>
    <ul>
        <li>Nesta fase é determinada <b>qual instrução deve ser executada</b></li><p>
    </ul><p>
    c) <b>Execução</b>
    <ul>
        <li><i>Cálculo</i> de <b>endereço</b> dos operandos (se houver);</li><p>
        <li><i>Busca</i> dos operandos na <b>memória</b> (se houver);</li><p>
        <li><i>Seleção</i> da operação a ser realizada pela <b>ULA</b>;</li><p>
        <li><i>Carga</i> de <b>registradores</b>;</li><p>
        <li><i>Escrita</i> de operandos na <b>memória</b>; e</li><p>
        <li><i>Atualização</i> do <b>PC</b> (somente no caso de as instruções serem desvios).</li>
    </ul><p>
    </P>
<h2>6. Medidas de Desempenho</h2>
    <P>A <b>medida geral</b> de desempenho de um sistema de computação depende fundamentalmente da <i>capacidade e velocidade de seus diferentes componentes</i>, <i>da velocidade com que esses componentes se comunicam entre si</i> e do <i>grau de compatibilidade entre eles</i> (p. ex., se a velocidade da CPU de um sistema é muito maior que a da memória).<p> Considerando a existência de tantos fatores que influenciam o desempenho de um sistema de computação, desenvolveram-se diversos meios de medir seu desempenho, entre os principais relacionados exclusivamente com a CPU destacam-se:
    <ul>
        <li>MIPS</li><p>
        <li>FLOPS</li>
    </ul><p>
    O desempenho dos processadores, em geral, é medido em termos de sua <i>velocidade de trabalho</i>; como o trabalho da CPU é executar instruções, criou-se a unidade <b>MIPS – milhões de instruções por segundo</b>. O MIPS é muito questionado, pois <i>mede apenas a execução de instruções, sendo que existem diferentes instruções, com tempos de execução distintos, por exemplo, multiplicação de números inteiros e multiplicação de números reais (ponto flutuante)</i>. <p>Em contraste com o MIPS, a unidade <b>FLOPS – operações de ponto flutuante por segundo</b> – mede basicamente o <i>desempenho da ULA</i>, analisando<b> apenas as instruções mais complexas (as que envolvem ponto flutuante)</b>. Hoje em dia, os microprocessadores estão na faixa de <i>MFLOPS (milhões de flops), sendo encontradas máquinas com GFLOPS (supercomputadores)</i>. O FLOPS foi inicialmente criado para ser a medida de estações de trabalho e de supercomputadores, mas atualmente também é utilizado em microcomputadores. <p>Quando se trata da <i>recuperação ou escrita de dados na memória</i>, o <b>tempo de acesso</b> é a unidade de medida apropriada, estando relacionada à <i>velocidade de cada componente e a do canal (barramentos) de interligação entre CPU e memória</i>. <b>Tempo de resposta</b> é uma medida ligada ao <i>desempenho global do sistema, e não ao de um ou outro componente</i>. Trata-se do período de tempo gasto entre o instante em que o usuário iniciou uma solicitação e o instante em que o sistema apresentou ao usuário a resposta.
    </P>
<h1>Pipeline, RISC e CISC</h1>
    <P>Abordaremos nesta aula assuntos referentes às arquiteturas RISC e CISC. Esses dois tipos de arquiteturas diferem muito entre si. Porém tanto uma quanto a outra traz consigo vantagens e desvantagens.
    </P>
<h2>1. Reduced Instruction Set Computer - RISC</h2>
    <P><i>Reduced Instruction Set Computer</i> – RISC (computador com um conjunto reduzido de instruções) é uma <i>linha de arquitetura de computadores</i> que favorece um <b>conjunto simples e pequeno de instruções</b> que levam aproximadamente a <i>mesma quantidade de tempo para serem executadas</i>.
    <p> A maioria dos microprocessadores modernos são RISCs, por exemplo DEC Alpha, SPARC, MIPS, e PowerPC. Os processadores baseados na computação de conjunto de instruções reduzido <b>não têm microprogramação</b>, <i>as instruções são executadas diretamente pelo hardware</i>. Como característica, essa arquitetura, além de <b>não ter microcódigo, tem o conjunto de instruções reduzido, bem como baixo nível de complexidade</b>. <p>A ideia foi inspirada pela descoberta de que <i>muitas das características incluídas na arquitetura tradicional de processadores para ganho de desempenho foram ignoradas pelos programas que foram executados neles</i>. Mas o desempenho do processador em relação à memória que ele acessava era crescente. Isso resultou num número de <i>técnicas para otimização do processo dentro do processador, enquanto ao mesmo tempo tentava reduzir o número total de acessos à memória</i>. Caracterização das arquiteturas RISC:
    <ul>
        <li><b>conjunto reduzido e simples de instruções</b>;</li><p>
        <li><b>formatos simples e regulares de instruções</b>;</li><p>
        <li><b>operandos sempre em registros</b>;</li><p>
        <li><b>modos simples de endereçamento à memória</b>;</li><p>
        <li><b>uma operação elementar por ciclo de máquina</b>; e</li><p>
        <li>uso de <b>pipeline</b>.</li>
    </ul><p>
    RISC é também a arquitetura adotada para os processadores dos videogames modernos, que proporcionam um hardware extremamente dedicado somente à execução do jogo, tornando-o muito mais rápido em relação a microcomputadores com mais recursos.
    </P>
<h2>2. Complex Instruction Set Computer – CISC</h2>
    <P><i>Complex Instruction Set Computer</i> – CISC (computador com um conjunto complexo de instruções) é uma <i>linha de arquitetura de processadores</i> capaz de executar <b>centenas de instruções complexas diferentes, sendo, assim, extremamente versátil</b>. Exemplos de processadores CISC são os 386 e os 486 da Intel. Os processadores baseados na computação de conjunto de instruções complexas <b>contêm uma microprogramação</b>, ou seja, um <i>conjunto de códigos de instruções que são gravados neles</i>, permitindo-lhes receber as instruções dos programas e executá-las. Seria como quebrar essas instruções, já em baixo nível, em diversas <b>instruções mais próximas do hardware (as instruções contidas no microcódigo do processador)</b>. Como característica marcante, essa arquitetura contém um <b>conjunto grande de instruções</b>, a maioria delas em um <i>elevado grau de complexidade</i>.<p> Examinando do ponto de vista um pouco mais prático, a vantagem da arquitetura CISC é que já temos muitas das instruções guardadas no próprio processador, o que facilita o <b>trabalho dos programadores de linguagem de máquina</b>, disponibilizando, assim, praticamente todas as instruções que serão usadas em seus programas. <p>Os processadores CISC têm a vantagem de <b>reduzir o tamanho do código executável</b> por já possuirem muito do código comum em vários programas, em forma de uma única instrução. Porém, do ponto de vista da performance, os CISCs têm algumas desvantagens em relação aos RISCs, entre elas a <b>impossibilidade de se alterar alguma instrução composta para se melhorar a performance</b>. O código equivalente às instruções compostas do CISC pode ser escrito nos RISCs da forma desejada, usando um conjunto de instruções simples, da maneira que mais se adequar. Sendo assim, existe uma disputa entre <b>tamanho do código x desempenho</b>.
    </P>
<h2>3. RISC x CISC</h2>
    <P>Sempre houve uma grande polêmica a respeito de qual dessas plataformas é melhor. No começo da década de 1980, a tendência era construir chips com conjuntos de instruções cada vez mais complexos. Alguns fabricantes, porém, resolveram seguir o caminho oposto, criando o padrão RISC. Ao contrário dos complexos CISC, os processadores RISC são capazes de executar apenas algumas poucas instruções simples. A família SPARC, da SUN, possui cerca de 50 instruções, enquanto os VAX-11/780 têm até 303 instruções, e o Intel 80486 foi lançado com 147 instruções de máquina.<p> Com <i>menor quantidade de instruções e com cada uma delas tendo sua execução otimizada</i>, o sistema deve produzir seus resultados com <b>melhor desempenho</b>, mesmo considerando-se que uma menor quantidade de instruções vai conduzir a programas um pouco mais longos. Justamente por isso, os chips baseados nessa arquitetura são <b>mais simples e muito mais baratos</b>. Outra vantagem dos processadores RISC é que, por terem um menor número de circuitos internos, podem trabalhar a <b>frequências mais altas</b>.<p> A ideia principal é que, apesar de um processador CISC ser capaz de executar centenas de instruções diferentes, <i>apenas algumas são usadas frequentemente</i>. Poderíamos então criar um processador otimizado para executar apenas essas instruções simples que são mais usadas. É indiscutível, porém, que em muitas tarefas os processadores CISC saem-se melhor, principalmente pelo seu grande número de recursos. Por isso, em vez da vitória de uma das duas tecnologias, <i>atualmente vemos processadores híbridos</i>, que são essencialmente processadores CISC, mas incorporam muitos recursos encontrados nos processadores RISC ou vice-versa. <p>Apesar de, por questões de marketing, muitos fabricantes ainda venderem "processadores RISC", não existe praticamente nenhum processador nos dias atuais que siga estritamente uma das duas filosofias. Tanto processadores da família x86, como o Pentium II, Pentium III e AMD Athlon, quanto processadores supostamente RISC, como o MIPS R10000 e o HP PA-8000, misturam características das duas arquiteturas, por simples questão de desempenho. <p>Examinando de um ponto de vista um pouco mais prático, a vantagem de uma arquitetura CISC é que <b>já temos muitas das instruções guardadas no próprio processador</b>, o que facilita o trabalho dos programadores, pois ele já dispõe de praticamente todas as instruções que serão usadas em seus programas. No caso de um chip estritamente RISC, o programador já teria um pouco mais de trabalho, pois, como disporia apenas de instruções simples, teria sempre que combinar várias instruções sempre que precisasse executar alguma tarefa mais complexa. Os chips atuais são na verdade misturas das duas arquiteturas. <p>Internamente, o processador executa apenas instruções simples. Essas instruções internas variam de processador para processador. Sobre essas instruções internas, temos um <b>circuito decodificador</b>, que <i>converte as instruções complexas utilizadas pelos programas em várias instruções simples que podem ser entendidas pelo processador</i>. Essas instruções complexas são iguais em todos os processadores usados em micros PC. <i>O conjunto básico de instruções usadas em micros PC é chamado de <b>conjunto x86</b></i>. Esse conjunto é composto por um total de <b>187 instruções</b>, que são as utilizadas por todos os programas. Além desse conjunto principal, alguns processadores trazem também instruções alternativas, que permitem aos programas executar algumas tarefas mais rapidamente do que seria possível usando as instruções x86 padrão. <p>
    Outra característica importante da arquitetura RISC, que a distingue da arquitetura CISC, refere-se ao <i>modo de realizar chamadas de rotinas e passagem de parâmetros</i>. Os estudos sobre comportamento dos programas revelaram que <b>chamadas de funções requerem usualmente poucos dados, mas consomem, na transferência, demorados acessos à memória em leituras e escritas</b>.<p> Nas máquinas <b>CISC</b>, a chamada de funções conduz a operação de leitura/escrita com a memória para passagem de parâmetro e recuperação de dados; nas máquinas com a arquitetura <b>RISC</b>, isso ocorre basicamente no processador, utilizando-se para isso <i>mais registradores que nas máquinas CISC</i>. Os parâmetros e variáveis são manuseados na própria UCP (Unidade Central de Processamento). A possibilidade de colocação de mais registradores na UCP é possível por causa da redução dos circuitos necessários à decodificação e execução de instruções. Com isso, <b>o desempenho total do processador melhora</b>, porque <i>executa mais otimizadamente as chamadas de funções</i> que ocorrem em quantidade apreciável na média dos programas.<p>
    Para facilitar o trabalho dos compiladores, o conjunto de instruções de máquinas CISC tende a possuir <b>modos de endereçamento</b>. Uma simples instrução de soma pode ser realizada com os operandos localizados de diversos modos: podem-se somar valores que estão armazenados em registradores; outra instrução pode realizar a mesma soma, com um operando na memória e outro em um registrador; ou ainda outra instrução pode realizar a operação de soma com os dois operandos armazenados na memória. <p>No caso das máquinas RISC, a busca por soluções mais simples conduziu à criação, de um modo geral, de dois tipos de instruções: <b>LOAD/STORE</b> para <i>acesso à memória utilizando somente o modo direto</i>, e demais operações matemáticas do processador. Essa técnica simplifica consideravelmente o projeto e a implementação das instruções, <i>reduzindo ainda mais os ciclos do relógio necessários à sua realização</i>. <p>
    Projetar processadores que executam várias instruções quase totalmente <b>em paralelo</b> é uma técnica bastante eficaz para acelerar o desempenho dos processadores, <i>reduzindo o tempo de execução das instruções para poucos ciclos</i>. <b>Pipelining</b> é utilizado em larga escala em arquiteturas RISC. O objetivo do projeto do processador RISC tem sido, no que se refere a essa área, completar a execução de uma instrução a cada ciclo de relógio. <p>Há no mercado alguns métodos de medir e divulgar o desempenho de processadores de computação, bem como diversas unidades de medidas decorrentes, os quais, em conjunto, podem confundir o observador, em vez de servir de elemento básico de comparação e auxílio à tomada de decisão em algum procedimento de escolha. Uma das unidades de medida mais conhecidas e também ambíguas é o <b>MIPS – milhões de instruções por segundo</b>. É ambígua porque cada processador executa uma instrução de modo diferente, e ainda porque cada um possui instruções diferentes. MIPS não é uma boa unidade de medida de comparação entre processadores RISC e CISC porque pode iludir o observador com os resultados, por causa do princípio conceitual de ambas as arquiteturas. Como as máquinas RISC possuem instruções mais simples, tendem a consumir mais instruções de máquina em um programa do que os correspondentes processadores CISC, e isso <i>pode mostrar um total de MIPS superior, conduzindo a uma possível conclusão errônea para os processadores RISC</i>. <p>Um resumo das diferenças entre RISC e CISC pode ser visto no quadro a seguir:<p>
    <img src=RISCCISC.jpg alt=RISCCIS class=center style="width:520px">
    </P>
<h2>4. Pipeline</h2>
    <P>Trata-se de uma forma de obter uma alta performance ao <i>"partir" o processamento de uma instrução numa série de estágios</i>, que são ligados como as estações numa linha de montagem. Essa linha de montagem para processamento de instruções tem o nome de <b>pipelining</b>. À medida que as instruções fluem ao longo do pipeline, <i>o hardware em cada estágio realiza algum processamento</i>, até que as instruções que deixam o pipeline são completamente processadas. <b>A alta performance é obtida pelo paralelismo no processamento das várias instruções ao mesmo tempo</b>, cada uma em diferentes estágios do pipeline. <p>Quando é carregada uma nova instrução, ela primeiramente passa pelo <b>primeiro estágio</b>, que trabalha nela durante <i>apenas um ciclo de clock</i>, passando-a adiante para o segundo estágio. A instrução continua então sendo executada sucessivamente pelo <b>segundo, terceiro, quarto e quinto estágios</b> do processador. A vantagem dessa técnica é que <i>o primeiro estágio não precisa ficar esperando a instrução passar por todos os demais para carregar a próxima, e sim carregar uma nova instrução assim que se livra da primeira</i>, ou seja, depois do primeiro pulso de clock. <p>As instruções trafegam dentro do processador na ordem em que são processadas. Mesmo que a instrução já tenha sido processada ao passar pelo primeiro ou segundo estágio, terá que continuar seu caminho e passar por todos os demais. <i>Se por acaso a instrução não for completada mesmo após passar pelos cinco, voltará para o primeiro e será novamente processada, até que tenha sido concluída</i>. Dessa maneira, conseguimos que o processador seja <i>capaz de processar, simultaneamente, em um único ciclo de clock, várias instruções que normalmente demorariam vários ciclos para serem processadas</i>. É, assim, uma técnica fundamental de processamento que, sendo inicialmente introduzida nas arquiteturas RISC, estendeu-se às CISC, estando hoje presente, por exemplo, nos processadores Intel Pentium. Esses processadores possuem a vantagem de rodar código nativo DOS e Windows, mas a desvantagem de uma arquitetura já exausta.
    </P>
<h2>5. Migração de Tecnologia?</h2>
    <P>Os diversos processadores RISC – PowerPC da IBM/Apple/Motorola, R4x00 da MIPS, SPARC da SUN, PA-RISC da HP e Alpha da DEC – estão competindo para se tornar o padrão RISC, e os desenvolvedores de software terão que escolher não só entre RISC e CISC, mas também entre os RISC. Uma questão com que já estão se defrontando muitos usuários do mundo inteiro é: sair ou não da tradicional arquitetura de processamento CISC e migrar para a arquitetura RISC? <p>Uma pesquisa realizada no ano passado apontou que, apesar do RISC ter melhor desempenho, pelo menos 95% dos computadores "desktop" ainda usavam CISC por dois motivos simples: <b>CISC é mais barato e roda a maioria dos softwares que todo mundo quer usar</b>. O primeiro motivo já não é mais verdadeiro, pois o PowerPC 601 já tira uma vantagem de preço sobre o CISC. A decisão de mudança passa por investimentos futuros em novas máquinas, novas arquiteturas de processamento da informação, novos servidores dos sistemas corporativos de informação e também pela escolha de qual será a nova plataforma e ambiente operacional a serem utilizados por esses sistemas nos próximos anos. <p>Existe um número significativo de desenvolvedores de aplicações para os processadores RISC, o que pode ser um sinal seguro da tendência do mercado corporativo, principalmente com servidores de redes pesadas – ou com aplicações críticas; com isso a Intel deverá perder uma fatia do mercado no caso de servidores que vinham sendo atendidos com os processadores 486 DX2 e Pentium. Dessa forma, nos próximos anos o usuário passará a contar com uma oferta mais diversificada de plataformas de hardware poderosas com preços competitivos, além de uma enorme variedade de sistemas operacionais.
    </P>
<h2>6. O Futuro</h2>
    <P>A maior ameaça para as arquiteturas RISC e CISC pode não ser nenhuma delas (por oposição à outra), mas uma nova arquitetura denominada <b>EPIC</b> (<i>Explicit Parallel Instruction Computer</i>). Como se pode depreender da palavra "paralelo", a arquitetura EPIC <i>pode executar várias instruções em paralelo umas com as outras</i>. Essa filosofia foi criada pela Intel e é, de certa forma, a combinação das arquiteturas RISC e CISC. <p>A Intel e a Hewlett Packard estão a desenvolver um processador usando essa filosofia sob o nome <b>MERCED (IA-64)</b>, e a Microsoft já está a desenvolver uma plataforma (<b>WIN64</b>) para ele. O processador MERCED será um processador de <b>64 bits</b>. <p>Se essa arquitetura for bem-sucedida poderá tornar-se a maior ameaça à arquitetura RISC. Todas as grandes marcas de fabricantes de processadores, excetuando a Sun e a Motorola, estão neste momento a comercializar produtos baseados no x86, e alguns estão apenas à espera de que o MERCED venha para o mercado. Por causa do mercado dos x86, não é provável que a arquitetura CISC desapareça num futuro próximo, mas a arquitetura RISC poderá vir a ser uma arquitetura em extinção. O futuro poderá trazer-nos processadores baseados na arquitetura EPIC, bem como mais famílias de processadores CISC, enquanto os processadores baseados em arquiteturas RISC poderão tender a desaparecer do mercado.<p> A princípio, os computadores eram bastante simples, o microprocessador possuía poucas instruções e apenas um ou dois modos de endereçamento. A memória principal era lenta, então era preciso diminuir o número de acessos a essa memória. A saída foi colocar microinstruções no processador. Isso o tornou cada vez mais complexo à medida que aumentava-se o número de microinstruções, o que resultou na máquina CISC. A arquitetura RISC parece ser uma boa saída para diminuir a complexidade dos computadores. Essa máquina possui um pequeno número de microinstruções verticais. O programa é compilado e executado diretamente pelo hardware. <p>Cada vez mais as tecnologias RISC e CISC estão se aproximando: processadores RISC estão aumentando seu conjunto de instruções e os CISC estão adotando técnicas originalmente implementadas no RISC. A simplificação das instruções é um grande mérito, e provavelmente continuará a influenciar futuras arquiteturas. Os princípios RISC e CISC poderão viver harmoniosamente em um único projeto. As memórias cache maiores (que diminuem a dependência dos acessos à memória) e uma melhoria na tecnologia dos compiladores diminuem ainda mais as diferenças apregoadas entre as máquinas RISC e CISC. 
    <p>A diferença entre processadores RISC e CISC já não reside no tamanho nem no tipo do conjunto de instruções, mas sim na arquitetura em si. As nomenclaturas RISC e CISC já não descrevem a realidade das arquiteturas atuais. O que conta atualmente é a velocidade com que o processador consegue executar as instruções que lhe são passadas e a fiabilidade com que consegue correr o software. Hoje em dia os fabricantes de processadores, sejam eles RISC ou CISC, estão a utilizar todos os truques de modo a melhorarem o desempenho e permitir algum avanço em relação aos seus concorrentes. Ambas as arquiteturas têm sobrevivido no mercado por razões diferentes, a arquitetura RISC pelo seu desempenho e a arquitetura CISC pela compatibilidade de software. <p>O futuro poderá não trazer a vitória a nenhum deles, mas sim a sua provável extinção, já que a Intel, que sempre foi a empresa líder na fabricação da arquitetura x86 (arquitetura CISC), vai abandoná-la em favor da arquitetura RISC depois de ter assinado com a HP para o projeto do Merced. A arquitetura EPIC pode então fazer com que as arquiteturas RISC e CISC se tornem obsoletas.
    </P>
<h1>Introdução às Arquiteturas Paralelas e à Taxonomia de Flynn</h1>
    <P>O grande interesse por problemas cada vez mais complexos tem levado à necessidade de computadores cada vez mais potentes para resolvê-los. Entretanto, limitações físicas e econômicas têm restringido o aumento da velocidade dos <i>computadores sequenciais</i>, ou seja, computadores que executam instruções em série, uma após a outra pela CPU. Por outro lado, <i>os problemas computacionais usualmente podem ter algumas de suas partes divididas em pedaços que teriam como ser solucionados ao mesmo tempo ou processadas em paralelo</i>. <p>Processamento paralelo é então uma forma pela qual a demanda computacional é suprida por meio do uso simultâneo de recursos computacionais como processadores para solução de um problema. A <i>computação paralela</i> é caracterizada pelo uso de <b>várias unidades de processamento</b> ou processadores para executar uma computação de forma mais rápida. É baseada no fato de que o processo de resolução de um problema pode ser dividido em tarefas menores, realizadas simultaneamente por meio de algum tipo de coordenação. O conceito foi originalmente introduzido no <b>CDC 6600</b> em 1964 pela CDC (control data corporation). No tópico a seguir, serão descritos os modelos de computação paralela existentes.
    </P>
<h2>1. Taxonomia de Flynn</h2>
    <P>A taxonomia de Flynn abrange quatro classes de arquiteturas de computadores:
    <ul>
        <li><b>SISD</b> (Single Instruction Single Data): fluxo <i>único</i> de instruções sobre um <i>único</i> conjunto de dados.</li><p>
        <li><b>SIMD</b> (Single Instruction Multiple Data): fluxo <i>único</i> de instruções em <u>múltiplos</u> conjuntos de dados.</li><p>
        <li><b>MISD</b> (Multiple Instruction Single Data): fluxo <u>múltiplo</u> de instruções em um <i>único</i> conjunto de dados.</li><p>
        <li><b>MIMD</b> (Multiple Instruction Multiple Data): fluxo <u>múltiplo</u> de instruções sobre <u>múltiplos</u> conjuntos de dados.</li>
    </ul>
    </P>
<h4>1.1. SISD (Single Instruction Single Data)</h4>
    <P>Nesta classe, um <i>único</i> fluxo de instruções opera sobre um <i>único</i> fluxo de dados. Isso corresponde ao processamento sequencial característico da <b>máquina de Von Neumann</b> e que compreende os computadores pessoais e estações de trabalho. Apesar dos programas estarem organizados por meio de <i>instruções sequenciais</i>, elas podem ser executadas de <i>forma sobreposta em diferentes estágios (<b>pipelining</b>)</i>. Arquiteturas SISD caracterizam-se por possuírem uma <i>única</i> unidade de controle, podendo possuir <u>mais de uma unidade funcional</u>. Um exemplo seria seu computador pessoal com um processador convencional.
    </P>
<h4>1.2. SIMD (Single Instruction Stream Multiple Data)</h4>
    <P>Esta classificação corresponde ao processamento de <u>vários dados</u> sob o comando de apenas <i>uma instrução</i>. Em uma arquitetura SIMD, <b>o programa ainda segue uma organização sequencial</b>. Para possibilitar o acesso a <u>múltiplos dados</u> é preciso uma organização de memória em diversos módulos. A <i>unidade de controle é única</i>, e existem diversas unidades funcionais. Nesta classe estão os processadores vetoriais e matriciais. Quanto às facilidades de hardware para armazenamento, essas normalmente são classificadas como:
    <ul>
        <li>Processor <b>Array</b></li><p>
        <li>Vector <b>Pipeline</b></li>
    </ul><p>
    Exemplo de computadores com a arquitetura processor array são as máquinas ILLIAC IV (Universidade de Illinois), Thinking Machine CM- 2 e MASPAR MP-1216. Exemplo de computadores com a arquitetura vector pipeline são as máquinas IBM 9000, Cray X-MP, Y-MP & C90, Fujitsu VP, NEC SX-2, Hitachi S820, ETA10. As GPUs, também, estão sob essa classificação.
    </P>
 <h4>1.3. MISD (Multiple Instruction Stream Single Data Stream)</h4>
    <P>Um <u>conjunto de dados</u> é colocado concorrente em <u>múltiplas unidades de processamento</u>. Cada UP opera de maneira independente via conjuntos independentes de instruções. Algumas utilizações de uma configuração MISD poderiam ser:
    <ul>
        <li><u>Filtros de múltiplas frequências</u> operando <i>um mesmo sinal</i>; e</li><p>
        <li><u>Múltiplos algoritmos de criptografia</u> tentando a quebra de <i>uma mensagem codificada</i>.</li>
    </ul><p>
    Não se tem conhecimento de arquitetura de máquinas comercial com <u>múltiplas instruções</u> trabalhando com um <i>único conjunto de dados concorrente</i>. Em 1971, uma máquina denominada como C.mmp computer foi desenvolvida na Universidade de Carnegie-Mellon.
    </P>
<h4>1.4. MIMD (Multiple Instruction Multiple Data)</h4>
    <P>Esta classe é bastante genérica, envolvendo o processamento de <u>múltiplos dados</u> por parte de <u>múltiplas instruções</u>. Neste caso, várias unidades de controle comandam suas unidades funcionais, as quais têm acesso a vários módulos de memória. Qualquer grupo de máquinas operando como uma unidade (deve haver certo grau de interação entre as máquinas) enquadra-se como MIMD. Alguns representantes desta categoria são os servidores multiprocessados, as redes de estações e as arquiteturas massivamente paralelas.
    </P>
<h2>2. Aplicação do Uso da Arquitetura Paralela</h2>
    <P>Processadores vetoriais ou processamento vetorial é definido como <i>aplicação de operações aritméticas/lógicas sobre vetores</i>, em vez de operações sobre pares de dados ou dados escalares. Ela possui as seguintes características: <b>reduz o custo</b> de manutenção de estruturas de controle para laços de processamento; <b>reduz conflitos</b> de acesso à memória; pode ser empregada com conceitos de <b>pipeline</b>; em geral tem um <b>aumento de desempenho da ordem de 10 a 20 vezes quando comparada com máquinas escalares</b>; <b>aumenta os custos</b> de hardware; <b>aumenta os custos</b> de compilação do código (vetorização).
    </P>
<h2>3. Multiprocessadores Simétricos</h2>
    <P>Estes ambientes são conhecidos como <i>arquiteturas de compartilhamento total</i>, que são caracterizadas por até <u>dezenas de processadores</u> compartilhando os mesmos recursos computacionais e rodando um <i>único sistema operacional</i>. Os processadores são considerados simétricos porque <i>têm os mesmos custos para acesso à memória principal</i>. <p>A utilização de SMP é mais popular do que se imagina. Esse tipo de máquina é encontrado facilmente em grande parte das organizações de hoje, e também vem ganhando espaço em áreas menores, reflexo da redução de custos. Um problema desta arquitetura é sua <b>escalabilidade</b>, pois, com o aumento do número de processadores, a taxa de <i>colisão de acesso à memória</i> também cresce, sendo necessária a utilização de soluções de memórias de cache e globais, que serão vistas à frente.
    </P>
<h2>4. Máquinas Maciçamente Paralelas</h2>
    <P>Como o próprio nome já diz, essas máquinas almejam o alto desempenho por meio da utilização de um <u>grande número de processadores comerciais</u>, os quais, por causa do fator do custo, acabam sendo processadores de baixo ou médio poder computacional. Cada nó possui <i>uma memória local</i> com um espaço de endereçamento próprio. Assim, cada nó só tem acesso à sua própria memória, o que a caracteriza como uma máquina <b>NORMA</b>. Assim, a comunicação entre as máquinas é feita por meio de troca de mensagens.
    </P>
<h2>5. Máquinas com Memória Compartilhada Distribuída</h2>
    <P>São sistemas em que, apesar das memórias estarem fisicamente separadas, todos os processadores podem endereçar as memórias de todos os nós por causa do fato de que foi implementado um <i>espaço único de endereçamento</i> (que pode ter sido feito tanto em hardware como em software).
    </P>
<h2>6. Rede de Estações de Trabalho</h2>
    <P>Basicamente, as máquinas NOW utilizam uma <b>rede local</b> (normalmente Ethernet ou ATM) já existente para a execução de <u>aplicações paralelas</u>. A rede local pode ser vista como uma <u>máquina paralela</u> em que vários processadores, com suas memórias locais (estações de trabalho), são <b>interligados por uma rede</b>, o que a torna uma máquina <b>NORMA de custo quase nulo</b>. A diferença da NOW para as MPP está na <i>hierarquia de barramento</i> utilizada nas estações, por possuir um <b>disco local (DL) nos nós e na rede de interconexão</b>. <p>Essas diferenças vêm do fato de a rede local ter sido planejada para um tipo distinto de aplicações paralelas (compartilhar arquivos e acessar periféricos remotos, como a impressora). Uma das dificuldades encontradas nessa troca de função está na rede de interconexão. Redes como Ethernet e ATM não são otimizadas para aplicações paralelas, que geram uma <b>alta latência nas operações</b>, o que compromete o desempenho da máquina como um todo.
    </P>
<h2>7. Cluster</h2>
    <P>Um cluster, ou aglomerado de computadores, é formado por um conjunto de computadores que se utiliza de um tipo especial de sistema operacional classificado como <b>sistema distribuído</b>. Muitas vezes, é construído a partir de computadores convencionais (personal computers), os quais são <b>ligados em rede</b> e comunicam-se por meio do sistema, trabalhando como se fossem <i>uma única máquina de grande porte</i>. <p>Há diversos tipos de cluster. Um tipo famoso é o cluster da classe Beowulf, constituído por diversos <i>nós escravos gerenciados por um só computador</i>. Ele pode ser definido também como o <i>cruzamento de uma trilha com um setor de um disco formatado</i>. Um HD (hard disc) possui vários clusters que serão utilizados para armazenamento dos dados de um determinado arquivo. Com essa divisão em trilhas e setores, é possível criar um endereçamento que visa <b>facilitar o acesso a dados não contíguos</b>, assim como o endereçamento de uma planilha de cálculos ou, como um exemplo mais simples, o tabuleiro do jogo "batalha naval".
    </P>
<h1>Arquitetura do Conjunto de Instruções (ISA); Características de Instruções de Máquina; Tipos de Operandos</h1>
    <P>O estudo da arquitetura de computadores efetua-se com recurso à abstração. Podemos ver um computador de várias formas.
    <ul>
        <li>Para um utilizador, normalmente, o computador é a aplicação;</li><p>
        <li>Para nós (na disciplina), tem a ver com a arquitetura.</li>
    </ul><p>
        <img src="arquitetura.jpg" alt=arquitetura class=center style="width:520px"><p>
        <img src="arquitetura1.jpg" alt=arquitetura1 class=center style="width:520px">
    </P>
<h2>1. ISA - Instruction Set Architecture</h2>
    <P>A Arquitetura do Conjunto de Instruções (ISA) descreve o <b>funcionamento do processador</b> de um ponto de vista lógico. Especifica <i>como um processador funciona, que instruções executa, quais os modos de endereçamento que são suportados e que tipos de dados são suportados</i>.
    <ul>
        <li>Por exemplo, <b>IA-32</b> (Arquitectura Intel de 32 bits) tem várias implementações, incluindo os processadores Pentium, Celeron e os processadores de alto desempenho Xeon.</li>
    </ul><p>
    Alguns exemplos de especificações ISA:
    <ul>
        <li>MIPS</li><p>
        <li>SPARC</li><p>
        <li>JVM (Java Virtual Machine)</li><p>
        <li>Plataforma .Net Microprocessador virtual</li>
    </ul><p>
    Na <b>JVM</b> e na plataforma <b>.NET</b>, as especificações ISA referem-se a uma <i>camada de software</i>. Do ponto de vista funcional, é como um <i>processador virtual</i> que implementa um processador JAVA ou .NET.<p>
        <img src="arquitetura2.jpg" alt=arquitetura2 class=center style="width:520px"><p>
    Como podem os dados ser acedidos? O modo como se especificam os operandos se chama <b>modos de endereçamento</b>:
    <ul>
        <li><b>Registro</b>, quando o operando é armazenado num registro;</li><p>
        <li><b>Imediato (ou literal)</b>, se o operando é parte da instrução;</li><p>
        <li><b>Direto (ou absoluto)</b>;</li><p>
        <li><b>Registro indireto</b>;</li><p>
        <li><b>Autoincremento</b>;</li><p>
        <li><b>Autodecremento</b>;</li><p>
        <li><b>Deslocamento</b>;</li><p>
        <li><b>Indexado</b>;</li><p>
        <li><b>Indexado escalado indireto</b>;</li><p>
        <li><b>Indexado escalado indireto com deslocamento</b>;</li><p>
        <li><b>Indexado escalado indireto com deslocamento</b>.</li>
    </ul>
    </P>    
<h2>2. Quais as Instruções Podem ser Executadas?</h2>
    <P><b>Instruções de transferência de dados</b> efetuam a transferência de dados de uma posição para outra. Quando existe um espaço separado de I/O, essas instruções também se referem a instruções I/O. Igualmente as instruções de acesso à pilha se incluem nessa categoria.
    <ul>
        <li>Instruções <b>aritméticas e lógicas</b> inteiras – operações aritméticas e lógicas;</li><p>
        <li>Instruções de <b>vírgula flutuante</b>;</li><p>
        <li>Instruções de <b>deslocamento e rotação</b> – efetuam deslocamento e rotações à esquerda e à direita;</li><p>
        <li>Instruções de <b>manipulação de bits</b> – operam especificamente em determinados bits dos operandos. As instruções normalmente incluem condições de teste (que afetam determinadas flags);</li><p>
        <li>Instruções de <b>controle do fluxo do programa</b> – saltos condicionais/incondicionais;</li><p>
        <li>Instruções de <b>controle do sistema</b> – chamadas de rotinas, interrupções, exceções;</li><p>
        <li>Instruções de <b>unidades de funções especiais</b> – instruções proprietárias de unidades funcionais;</li><p>
        <li><b>Instruções configuráveis</b> – específicas de processadores que permitem a customização de instruções.</li>
    </ul><p>
    Ao nível ISA, podemos definir dois tipos:
    <ul>
        <li><b>CISC</b> – Complex Instruction Set Computer; e</li><p>
        <li><b>RISC</b> – Reduced Instruction Set Computer.</li>
    </ul>
    </P>
<h2>3. Linguagem Assembly e linguagem Máquina</h2>
    <ul>
        <li><b>Linguagem de baixo nível</b> especificada por meio de mnemônicas;</li><p>
        <li><b>Linguagem é nativa do processador</b>, por este fato não existe portabilidade;</li><p>
        <li>A linguagem assembly está na relação de <b>1:1 com a linguagem máquina</b>;</li><p>
        <li>Como consequência da linguagem assembly, um <b>programa tende a ser grande, mas bastante eficiente</b>.</li>
    </ul>
<h2>4. Linguagens de Alto Nível</h2>
    <ul>
        <li>São <b>fortemente estruturadas</b>;</li><p>
        <li>Definem estruturas de <b>controle de fluxo de programa</b>;</li><p>
        <li><b>Portabilidade</b>.</li>
    </ul><p>
        <img src="arquitetura3.jpg" alt="arquitetura3" class="center"><p>
        <img src="arquitetura4.jpg" alt="arquitetura4" class="center" style="width:520px"><p>
    A linguagem CLI (<i>Common Language Infrastructure</i>) <i>permite que aplicações escritas em múltiplas linguagens de alto nível possam ser executadas em diferentes ambientes sem ser necessário reescrever o código</i>.<p>
    <img src="arquitetura5.jpg" alt="arquitetura5" class="center" style="width:520px">
<h1>Tipos de Operações - Linguagem de Montagem (Assembly) - Modos de Endereçamento</h1>
    <P>O <b>conjunto de instruções</b> é um dos pontos centrais na arquitetura de um processador. Vários aspectos na definição e implementação da arquitetura são influenciados pelas características do conjunto de instruções. Por exemplo, as operações realizadas pela<i> unidade lógica e aritmética</i>, o número e função dos <i>registradores</i> e a estrutura de <i>interconexão</i> dos componentes da seção de processamento. <p>Além disso, as <i>operações básicas</i> que acontecem dentro da seção de processamento dependem das instruções que devem ser executadas. O conjunto de instrução afeta o projeto da <i>seção de controle</i>. A sua estrutura e a sua complexidade são determinadas diretamente pelas características do conjunto de instruções. Esta aula discute os principais aspectos de um conjunto de instruções, como <b>tipos de operações</b>, <b>operandos</b> e <b>modos de endereçamento</b>.<p>
    <h2>1. Conjunto de Instruções no Contexto de Software</h2><p>
    <figure>
        <img src="instruções.jpg" alt=instruções class=center>
        <figcaption>A Figura 1 situa o conjunto de instruções do processador dentro dos diversos níveis de software existentes em um sistema de computação.</figcaption>
    </figure><p>
    Em geral, os programas são desenvolvidos em uma linguagem de alto nível como FORTRAN, Pascal ou C. O <b>compilador</b> traduz o programa de alto nível em uma sequência de instruções de processador. O resultado dessa tradução é o <b>programa em linguagem de montagem ou linguagem de máquina (assembly language)</b>. A linguagem de montagem é uma forma de representar textualmente as instruções oferecidas pela <b>arquitetura</b>. Cada arquitetura possui uma linguagem de montagem particular.<p> 
    No programa em linguagem de montagem, as instruções são representadas por meio de <b>mnemônicos</b>, que <i>associam o nome da instrução à sua função</i>, por exemplo, ADD ou SUB, isto é, soma e subtração, respectivamente. <b>O programa em linguagem de montagem é convertido para um programa em código objeto pelo montador (assembler)</b>. O montador traduz diretamente uma instrução da <b>forma textual</b> para a forma de <b>código binário</b>. É sob a forma binária que a instrução é carregada na memória e interpretada pelo processador. <p>
    Programas complexos são normalmente estruturados em módulos. <b>Cada módulo é compilado separadamente e submetido ao montador, gerando diversos módulos em código objeto</b>. <i>Esses módulos são reunidos pelo ligador (linker), resultando finalmente no programa executável que é carregado na memória</i>. 
    </P>
<h2>2. Tipos de Instruções e de Operandos</h2>
    <P>O conjunto de instruções de uma arquitetura se distingue por meio de diversas características. As <i>principais características de um conjunto de instruções</i> são: <b>tipos de instruções</b> e <b>operandos</b>, <b>número e localização dos operandos</b> em instruções aritméticas e lógicas, <b>modos de endereçamento</b> para acesso aos dados na memória e o <b>formato dos códigos</b> de instrução. Esses aspectos são analisados a seguir.<p>
    As instruções oferecidas por uma arquitetura podem ser classificadas em categorias, de acordo com o tipo de operação que realizam. Em geral, uma arquitetura fornece <b>pelo menos três categorias de instruções básicas</b>:
    <ul>
        <li>instruções <b>aritméticas e lógicas</b>: são as instruções que realizam operações aritméticas sobre números inteiros (adição, subtração) e operações lógicas bit a bit (AND, OR);</li><p>
        <li>instruções de <b>movimentação de dados</b>: instruções que transferem dados entre os registradores ou entre os registradores e a memória principal.</li><p>
        <li>instruções de <b>transferência de controle</b>: instruções de desvio e de chamada de rotina, que transferem a execução para uma determinada instrução dentro do código do programa.</li>
    </ul><p>
    Várias arquiteturas oferecem <b>outras categorias de instruções</b>, voltadas para operações especializadas. Dentre elas, podemos citar:
    <ul>
        <li>instruções de <b>ponto flutuante</b>: instruções que realizam operações aritméticas sobre números com ponto flutuante.</li><p>
        <li>instruções <b>decimais</b>: instruções que realizam operações aritméticas sobre números decimais codificados em binário (BCD – binary coded decimal).</li><p>
        <li>instruções de <b>manipulação de bits</b>: instruções para testar ou atribuir o valor de um bit.</li><p>
        <li>instruções de <b>manipulação de strings</b>: instruções que realizam operações sobre cadeias de caracteres (strings), como movimentação e comparação, ou ainda procura de um caractere dentro de um string.</li>
    </ul><p>
    Existem muitas diferenças entre as arquiteturas quanto às categorias de instruções oferecidas. Arquiteturas de uso geral oferecem a maioria das categorias relacionadas anteriormente. Arquiteturas destinadas para uma aplicação específica podem oferecer outros tipos de instruções, especializadas para aquela aplicação. Um exemplo seria uma <i>arquitetura voltada para processamento gráfico</i>, que ofereceria instruções para realizar operações sobre pixels.<p> Os tipos de operandos que podem ser diretamente manipulados por uma arquitetura dependem, é claro, dos tipos de instruções oferecidas. A Figura 2 mostra como os <b>principais tipos de dados</b> são normalmente representados em uma arquitetura de uso geral. A Figura 2(a) mostra a representação de <b>números inteiros</b>, neste exemplo particular, inteiros com 32 bits. <p>Números inteiros podem ser representados com ou sem sinal. Em um número inteiro com sinal, o bit mais significativo é reservado para indicar o estado do sinal (positivo ou negativo). Números inteiros sem sinal assumem apenas valores positivos. Algumas arquiteturas oferecem instruções específicas para aritmética com ou sem sinal. Essas instruções diferem no modo como são alterados os <b>bits do registrador de estado associado a ALU</b>. Algumas linguagens de programação tornam visível para o programador essa distinção entre inteiros com ou sem sinal. Na linguagem <b>C</b>, por exemplo, uma variável declarada do <b>tipo int</b> é representada por um inteiro com sinal. Ao contrário, variáveis do tipo <b>unsigned int</b> são representadas por inteiros sem sinal, sendo normalmente usadas para indexar elementos de vetores.<p> A Figura 2(b) mostra a representação de <b>números com ponto flutuante</b>, com precisão simples e dupla. A diferença entre precisões está <b>no número de bits</b> usados para representar a <b>mantissa e o expoente</b>. Atualmente, a maioria das arquiteturas que operam números com ponto flutuante obedece a um padrão, denominado <b>IEEE 754</b>, que define a representação e um conjunto de operações aritméticas e lógicas para números com ponto flutuante.<p>
        <img src="instru%C3%A7%C3%B5es2.jpg" alt=instruções2 class=center style="width:520px"><p>
    A Figura 2(c) mostra a representação de <b>números BCD empacotados</b> (Packed Binary Coded Decimal). Nessa representação, dois dígitos decimais codificados em binário são representados dentro de um byte, cada dígito sendo codificado em quatro bits do byte. Finalmente, a Figura 2(d) mostra a representação de <b>cadeias de caracteres</b>, em que cada byte dentro de uma sequência de bytes codifica um caractere segundo certo padrão (por exemplo, o padrão ASCII).
    </P>
<h2>3. Número e Localização dos Pperandos</h2>       <P>
    Outra característica de um conjunto de instruções é o <b>número de operandos explicitamente indicados em uma instrução aritmética ou lógica</b>. Em algumas arquiteturas, essas instruções referenciam explicitamente <b>três operandos</b>, <b>dois operandos-fonte</b> e <b>um operando-destino</b>, como em: <br><br>
    <b>ADD R1, R2, R3</b>.<p>
    Em que <i>R1 e R2 são os operandos-fonte</i> e <i>R3 é o operando-destino</i>. <p>Em outras arquiteturas, instruções aritméticas/lógicas especificam apenas dois operandos. Nesse caso, <i>um dos operandos-fonte é também o operando-destino</i>. Por exemplo, na instrução:<br><br> 
    <b>ADD R1, R2</b> <p>
    <i>R2 contém um dos operandos-fonte e também é usado como operando-destino</i>.<p> 
    Quanto à localização dos operandos especificados por uma instrução aritmética/lógica, podemos encontrar arquiteturas em que podem ser realizados <i>acessos aos operandos diretamente a partir da memória principal</i>. Por exemplo, nessas arquiteturas podemos ter instruções como:<br><br>
    <b>ADD M1, R1, R2</b><br>
    <b>ADD M1, M2, R1</b><br>
    <b>ADD M1, M2, M3</b><p>
    Em que <i>M1, M2 e M3 são endereços de locações de memória</i>. <p>
    Em outro extremo, existem arquiteturas em que <i>todos os operandos encontram-se apenas em registradores</i>. As instruções aritméticas/lógicas são todas do tipo:<br><br>
    <b>ADD R1, R2, R3</b><br>
    <b>ADD R1, R2</b><p>
    A partir do número de operandos explicitamente referenciados e da localização desses operandos, podemos classificar as arquiteturas nos seguintes tipos:
    <ul>
        <li>arquitetura <b>memória-memória</b>: as instruções aritméticas/lógicas usam <i>três operandos</i> e todos os operandos podem estar na <i>memória</i>.</li><p>
        <li>arquitetura <b>registrador-memória</b>: as instruções aritméticas/lógicas usam <b>dois operandos</b>, e apenas um deles pode residir na <i>memória</i>.</li><p>
        <li>arquitetura <b>registrador-registrador</b>: as instruções aritméticas/lógicas usam <b>três operandos</b>, todos em registradores.</li>
    </ul><p>
    Nesse caso, apenas duas instruções acessam diretamente a memória: <b>LOAD e STORE</b>. A instrução <i>LOAD carrega em um registrador um dado armazenado na memória</i>, e a instrução <i>STORE armazena na memória o conteúdo de um registrador</i>.<p> Arquiteturas <b>memória-memória</b> e <b>registrador-memória</b> apresentam como vantagem um <i>menor número de instruções no código do programa</i>, já que não é necessário carregar previamente em registradores os operandos-fonte de uma instrução aritmética/lógica, como acontece em uma arquitetura <i>registrador-registrador</i>.<p> Por outro lado, a existência de instruções aritméticas/lógicas mais poderosas torna mais complexa a implementação da arquitetura. As arquiteturas Intel 80x86 e Motorola MC680x0 são do tipo registrador-memória. Dentre as arquiteturas memória-memória, podemos citar o DEC VAX 11.
    </P>
<h2>4. Modos de Endereçamento</h2>
    <P>
    Os <b>operandos</b> de uma instrução podem encontrar-se em <i>registradores, na memória principal ou ainda embutidos na própria instrução</i>. O <b>modo de endereçamento</b> refere-se à maneira como uma instrução <i>especifica a localização dos seus operandos</i>. Existem três modos de endereçamento básicos:
    <ul>
        <li>modo <b>registrador</b>: a instrução indica o número de um registrador de dados em que se encontra um operando (fonte ou destino).</li><p>
        <li>modo <b>imediato</b>: a instrução referencia um operando que se encontra <i>dentro do próprio código</i> da instrução.</li><p>
        <li>modo <b>implícito</b>: a localização do operando <i>não está explicitamente indicada na instrução</i>.</li>
    </ul><p>
    Por exemplo, nas chamadas <i>arquiteturas acumulador</i>, um dos operandos-fonte e o operando-destino nas instruções aritméticas/lógicas encontram-se sempre em um registrador especial, o <b>acumulador</b>. Assim, <i>não é necessário que esse registrador seja explicitamente referenciado pela instrução</i>. A Figura 3 mostra exemplos de instruções que usam os modos de endereçamento implícito, registrador e imediato.<p>
        <img src=instru%C3%A7%C3%B5es3.jpg alt=instruções3 class=center><p>
    Os modos de endereçamento citados referenciam apenas operandos que se encontram em <i>registradores ou na instrução</i>. Existem ainda os modos de endereçamento usados para referenciar dados armazenados na <b>memória principal</b>. Entre as diferentes arquiteturas, existe uma enorme variedade de modos de endereçamento referentes à memória principal, e que formam, na realidade, uma classe de <i>modos de endereçamento à parte</i>. <p>Um modo de endereçamento referente à memória indica como deve ser obtido o endereço da locação de memória em que se encontra o dado que será acessado. Esse endereço é chamado <b>endereço efetivo</b>. Apesar da variedade mencionada, é possível identificar alguns modos de endereçamento referentes à memória que são oferecidos pela maioria das arquiteturas. Esses <b>modos de endereçamento mais comuns</b> estão relacionados na Figura 4.<p>
        <img src=instru%C3%A7%C3%B5es4.jpg alt=instruções4 class=center><p>
    No <b>modo direto</b>, o endereço efetivo é um <i>valor imediato contido no código da instrução</i>. Por exemplo, na instrução ADD (100), R1, um dos operandos encontra-se na locação de memória com endereço 100. O modo de endereçamento direto é usado principalmente no acesso às <b>variáveis estáticas</b> de um programa, cujo endereço em memória pode ser determinado durante a compilação do programa. <p>No <b>modo indireto</b>, o endereço efetivo encontra-se <i>em um registrador</i>. Por exemplo, na instrução ADD (R1), R2, um dos operandos encontra-se na locação de memória cujo endereço está no registrador R1. Ou seja, <i>o operando na memória é indicado indiretamente, por meio de um registrador que contém o endereço efetivo</i>. Esse modo de endereçamento é usado no acesso a <b>variáveis dinâmicas</b>, cujo endereço na memória é conhecido apenas durante a execução do programa. O acesso a uma variável dinâmica é realizado por meio de um <i>ponteiro</i>, que nada mais é do que o endereço da variável. Para realizar o acesso à variável dinâmica, <i>o ponteiro é carregado em um registrador, e a instrução que acessa a variável usa esse registrador com o modo de endereçamento indireto</i>. <p>No modo <b>relativo à base</b>, o endereço efetivo <i>é a soma do conteúdo de um registrador, chamado endereço-base, com um valor imediato contido na instrução, chamado deslocamento</i>. Por exemplo, na instrução <b>ADD 100(R1), R2</b>, <i>R1 contém o endereço-base</i> e <i>100 é o deslocamento</i>. O endereço efetivo do operando em memória é a soma do conteúdo de R1 com o valor 100. O modo relativo à base é usado no <b>acesso aos componentes de variáveis dinâmicas estruturadas</b> (por exemplo, <i>record</i> em Pascal ou <i>struct</i> em C. A Figura 4 mostra como é calculado o endereço efetivo no modo de endereçamento relativo à base.
        <p>
        <img src=instru%C3%A7%C3%B5es5.jpg alt=instruções5 class=center style="width:520px"><p>
    A figura mostra a localização na memória de uma estrutura com quatro campos, A, B, C e D. O endereço inicial da estrutura é indicado por um ponteiro, que se torna conhecido apenas durante a execução do programa. No entanto, a posição de cada campo em relação ao início da estrutura é fixo, sendo conhecido durante a compilação. O endereço de um campo é obtido <b>somando-se a posição do campo (o deslocamento) ao ponteiro que indica o início da estrutura (o endereço-base)</b>. Por exemplo, na Figura 5, para somar um valor ao campo C, o compilador pode usar a instrução ADD 2(R1), R2, precedida de uma instrução para carregar em R1 o endereço-base da estrutura.<p> 
    No <b>modo indexado</b>, o endereço efetivo é dado pela <i>soma de um índice com um endereço-base, ambos armazenados em registradores</i>. Por exemplo, na instrução ADD (R1 + R2), R3, <b>R1 contém o endereço-base, e R2 o índice</b>. O modo indexado é normalmente usado no acesso aos <b>elementos de um vetor</b>. A Figura 5 mostra como é calculado o endereço efetivo no modo de endereçamento indexado.
    <p>
        <img src=instru%C3%A7%C3%B5es6.jpg alt=instruções6 class=center style="width:520px"><p>
    A Figura 6 representa a localização na memória de um vetor V. Um ponteiro indica o endereço-base do vetor, em que se encontra o primeiro elemento. <b>O endereço de cada elemento é obtido somando o índice do elemento ao endereço-base</b>. Para realizar o acesso sequencialmente aos elementos do vetor, <i>o índice é inicialmente carregado no registrador com o valor 0. O índice é então incrementado dentro de um loop após o acesso a cada elemento</i>. Por exemplo, para somar um valor em registrador aos elementos do vetor, o compilador pode usar as seguintes instruções em um loop: <br><br>
    <b>ADD R1, (R2 + R3)</b> <br>
    <b>ADD 1, R3</b> <p>
    Em que <i>R1 contém o valor a ser somado</i>, <i>R2 contém o ponteiro para o vetor</i> e <i>R3 é o registrador com o índice, com valor inicial 0</i>.
    </P>
</body>
</html>